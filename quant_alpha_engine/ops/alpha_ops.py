"""
AlphaOps â€” QuantAlpha_Engine ç®—å­åº“
=====================================
æ‰€æœ‰ç®—å­å‡æ”¯æŒ pandas.DataFrame å‘é‡åŒ–è¿ç®—ã€‚
çº¦å®šï¼šDataFrame çš„ Index ä¸ºæ—¶é—´ï¼ŒColumns ä¸ºè‚¡ç¥¨ä»£ç ã€‚

ç®—å­åˆ†ç±»
--------
æ—¶åºç±» (Time-Series)
    Ts_Sum, Ts_Mean, Ts_Max, Ts_Min, Ts_Delta, Ts_Delay,
    Ts_Std, Ts_Rank, Ts_Corr,
    Ts_Skew, Ts_Kurt, Ts_Autocorr, Ts_Hurst

æˆªé¢ç±» (Cross-Sectional)
    Rank, ZScore, Scale

ç‰¹æ®Šç±» (Special)
    Decay_Linear, Neutralize

é‡ä»·å› å­ (Price-Volume)
    VWAP, VWAP_Bias, PVDeviation, Amihud

åŠ¨é‡å› å­ (Momentum)
    RiskAdjMomentum, PricePathQuality, RangeBreakout

æŠ€æœ¯æŒ‡æ ‡ (Technical)
    RSI, KDJ, MACD

ç¼©é‡ç¨³ä»·å› å­ (VolSpike-PriceStable)
    VolSpike, PriceVarShrink, PriceMeanShrink, VolSpikeStablePrice

ç”¨æ³•ç¤ºä¾‹
--------
>>> from quant_alpha_engine.ops import AlphaOps as op
>>> factor = op.Rank(op.Ts_Delta(close, 20))
>>> factor2 = op.Neutralize(op.Rank(op.Ts_Corr(volume, close, 10)), industry)
>>> f_rsi  = op.RSI(close, window=14)
>>> f_macd = op.MACD(close, fast=12, slow=26, signal=9)
>>> # ç¼©é‡ç¨³ä»·å¤åˆå› å­ï¼ˆé‡èƒ½å¼‚åŠ¨ + ä»·æ ¼æ”¶æ•›ä¿¡å·ï¼‰
>>> f_vssp = op.VolSpikeStablePrice(turnover, close, open_, n_short=3, n_long=10)
"""

from __future__ import annotations

import warnings
from typing import Union

import numpy as np
import pandas as pd
from scipy.stats import spearmanr, pearsonr

# å±è”½ rolling apply ä¸­å¯èƒ½å‡ºç°çš„ NaN è­¦å‘Š
warnings.filterwarnings("ignore", category=RuntimeWarning)


class AlphaOps:
    """
    å› å­ç®—å­åº“ï¼ˆå…¨é™æ€æ–¹æ³•ï¼‰ã€‚

    æ‰€æœ‰è¾“å…¥ DataFrame é¡»æ»¡è¶³ï¼š
        - Index: pd.DatetimeIndexï¼ˆæ—¶é—´å‡åºï¼‰
        - Columns: è‚¡ç¥¨ä»£ç 

    NaN å€¼å¤„ç†åŸåˆ™ï¼šæ»šåŠ¨çª—å£ä¸è¶³æ—¶è¿”å› NaNï¼Œæˆªé¢æ“ä½œè‡ªåŠ¨å¿½ç•¥ NaNã€‚
    """

    # ==================================================================
    # æ—¶åºç±»ç®—å­ (Time-Series)
    # ==================================================================

    @staticmethod
    def Ts_Sum(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """æ»‘åŠ¨çª—å£æ±‚å’Œã€‚

        Parameters
        ----------
        df     : è¾“å…¥å› å­çŸ©é˜µ
        window : çª—å£å¤§å°ï¼ˆå¤©æ•°ï¼‰

        Returns
        -------
        pd.DataFrame
            ä¸ df åŒå½¢çŠ¶ï¼Œå‰ window-1 è¡Œä¸º NaN
        """
        return df.rolling(window=window, min_periods=window).sum()

    @staticmethod
    def Ts_Mean(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """æ»‘åŠ¨çª—å£å‡å€¼ï¼ˆç§»åŠ¨å¹³å‡ï¼‰ã€‚"""
        return df.rolling(window=window, min_periods=window).mean()

    @staticmethod
    def Ts_Max(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """æ»‘åŠ¨çª—å£æœ€å¤§å€¼ã€‚"""
        return df.rolling(window=window, min_periods=window).max()

    @staticmethod
    def Ts_Min(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """æ»‘åŠ¨çª—å£æœ€å°å€¼ã€‚"""
        return df.rolling(window=window, min_periods=window).min()

    @staticmethod
    def Ts_Std(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """æ»‘åŠ¨çª—å£æ ‡å‡†å·®ã€‚"""
        return df.rolling(window=window, min_periods=window).std()

    @staticmethod
    def Ts_Delta(df: pd.DataFrame, period: int) -> pd.DataFrame:
        """å½“å‰å€¼ä¸ period å¤©å‰çš„å·®å€¼ (df - df.shift(period))ã€‚

        Parameters
        ----------
        period : å›çœ‹æœŸæ•°ï¼ˆå¤©ï¼‰
        """
        return df.diff(periods=period)

    @staticmethod
    def Ts_Delay(df: pd.DataFrame, period: int) -> pd.DataFrame:
        """æ•°æ®æ»å period å¤©ï¼ˆç­‰ä»·äº df.shift(period)ï¼‰ã€‚"""
        return df.shift(periods=period)

    @staticmethod
    def Ts_Rank(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """
        çª—å£å†…çš„æ—¶åºç™¾åˆ†æ¯”æ’åï¼ˆå½“å‰å€¼åœ¨è¿‡å» window ä¸ªè§‚æµ‹ä¸­çš„åˆ†ä½æ•°ï¼‰ã€‚

        å®ç°è¯´æ˜ï¼šé€åˆ—è°ƒç”¨ rolling.apply + rankdataï¼Œæœ€ç»ˆå€¼ä¸ºå½“å‰æ—¶åˆ»åœ¨
        çª—å£å†…çš„ç™¾åˆ†æ¯”æ’åï¼ˆ0~1ï¼‰ã€‚
        æ³¨ï¼šå› ä½¿ç”¨ applyï¼Œå¯¹å¤§çŸ©é˜µé€Ÿåº¦è¾ƒæ…¢ï¼›å¯è€ƒè™‘ç”¨ bottleneck åŠ é€Ÿã€‚

        Returns
        -------
        pd.DataFrame : å€¼åŸŸ [0, 1]
        """
        def _rank_last(x: np.ndarray) -> float:
            """è¿”å›æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ çš„ç™¾åˆ†æ¯”æ’åã€‚"""
            if np.all(np.isnan(x)):
                return np.nan
            valid = x[~np.isnan(x)]
            if len(valid) == 0:
                return np.nan
            # å½“å‰å€¼ï¼ˆæœ€åä¸€ä¸ªé NaN å€¼ï¼‰åœ¨çª—å£å†…çš„ç™¾åˆ†æ¯”æ’å
            curr = x[-1]
            if np.isnan(curr):
                return np.nan
            rank = np.sum(valid <= curr) / len(valid)
            return rank

        return df.rolling(window=window, min_periods=window).apply(
            _rank_last, raw=True
        )

    @staticmethod
    def Ts_Corr(
        df1: pd.DataFrame,
        df2: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        çª—å£å†…ä¸¤ä¸ªå› å­çŸ©é˜µçš„æ»šåŠ¨ç›¸å…³ç³»æ•°ï¼ˆé€åˆ— Pearson ç›¸å…³ï¼‰ã€‚

        Parameters
        ----------
        df1, df2 : å½¢çŠ¶ç›¸åŒçš„ DataFrameï¼ˆæ—¶é—´ Ã— è‚¡ç¥¨ï¼‰
        window   : æ»šåŠ¨çª—å£å¤§å°

        Returns
        -------
        pd.DataFrame : ä¸è¾“å…¥åŒå½¢çŠ¶ï¼Œå€¼åŸŸ [-1, 1]
        """
        # å¯¹é½ä¸¤ä¸ª DataFrame
        df1, df2 = df1.align(df2, join="inner")

        result_dict = {}
        for col in df1.columns:
            s1 = df1[col]
            s2 = df2[col]
            result_dict[col] = s1.rolling(window=window, min_periods=window).corr(s2)

        return pd.DataFrame(result_dict, index=df1.index)[df1.columns]

    # ==================================================================
    # æˆªé¢ç±»ç®—å­ (Cross-Sectional)
    # ==================================================================

    @staticmethod
    def Rank(df: pd.DataFrame) -> pd.DataFrame:
        """
        å…¨å¸‚åœºæˆªé¢ç™¾åˆ†æ¯”æ’åï¼ˆ0~1ï¼Œå€¼è¶Šå¤§æ’åè¶Šé å‰ï¼‰ã€‚

        å¯¹æ¯ä¸ªæ—¶é—´æˆªé¢ï¼Œå¯¹æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼åšç™¾åˆ†æ¯”æ’åï¼ˆå‡åºï¼‰ã€‚
        NaN å€¼ä¸å‚ä¸æ’åï¼Œå¯¹åº”ä½ç½®ä»ä¸º NaNã€‚

        Returns
        -------
        pd.DataFrame : å€¼åŸŸ [0, 1]
        """
        return df.rank(axis=1, pct=True, na_option="keep")

    @staticmethod
    def ZScore(df: pd.DataFrame) -> pd.DataFrame:
        """
        æˆªé¢æ ‡å‡†åŒ–ï¼ˆZ-Score Normalizationï¼‰ã€‚

        æ¯ä¸ªæ—¶é—´æˆªé¢å‡å»æˆªé¢å‡å€¼åé™¤ä»¥æˆªé¢æ ‡å‡†å·®ã€‚
        è‡³å°‘éœ€è¦ 2 ä¸ªé NaN å€¼ï¼Œå¦åˆ™è¿”å› NaNã€‚

        Returns
        -------
        pd.DataFrame : å‡å€¼=0ï¼Œæ ‡å‡†å·®=1
        """
        mean_ = df.mean(axis=1)
        std_  = df.std(axis=1, ddof=1)
        # é¿å…é™¤ä»¥é›¶
        std_[std_ < 1e-10] = np.nan
        return df.sub(mean_, axis=0).div(std_, axis=0)

    @staticmethod
    def Scale(df: pd.DataFrame, a: float = 1.0) -> pd.DataFrame:
        """
        å°†æˆªé¢ç»å¯¹å€¼ä¹‹å’Œç¼©æ”¾è‡³ aã€‚

        sum(|scaled_i|) = aï¼ˆæ¯ä¸ªæˆªé¢ç‹¬ç«‹ç¼©æ”¾ï¼‰ã€‚
        ç”¨äºå°†å› å­å€¼ç¼©æ”¾ä¸ºåä¹‰æŒä»“æƒé‡ä¹‹å’Œç­‰äº a çš„å½¢å¼ã€‚

        Parameters
        ----------
        a : ç›®æ ‡ç»å¯¹å€¼ä¹‹å’Œï¼Œé»˜è®¤ 1.0

        Returns
        -------
        pd.DataFrame
        """
        abs_sum = df.abs().sum(axis=1)
        abs_sum[abs_sum < 1e-10] = np.nan  # é¿å…é™¤ä»¥é›¶
        return df.div(abs_sum, axis=0).mul(a)

    # ==================================================================
    # ç‰¹æ®Šç±»ç®—å­ (Special)
    # ==================================================================

    @staticmethod
    def Decay_Linear(df: pd.DataFrame, d: int) -> pd.DataFrame:
        """
        çº¿æ€§åŠ æƒç§»åŠ¨å¹³å‡è¡°å‡ï¼ˆWorldQuant æ ¸å¿ƒç®—å­ï¼‰ã€‚

        æƒé‡å‘é‡ï¼šw = [1, 2, ..., d]ï¼ˆæœ€è¿‘æ•°æ®æƒé‡æœ€å¤§ï¼‰ï¼Œå½’ä¸€åŒ–åæ±‚åŠ æƒå‡å€¼ã€‚
        å³ï¼šdecay(t) = sum_{k=0}^{d-1} w_{d-k} * x_{t-k} / sum(w)

        Parameters
        ----------
        d : è¡°å‡çª—å£å¤§å°

        Returns
        -------
        pd.DataFrame : çº¿æ€§è¡°å‡åŠ æƒå¹³å‡å€¼
        """
        # æƒé‡å‘é‡ [1, 2, ..., d]ï¼Œæœ€æ—§çš„æƒé‡ä¸º 1ï¼Œæœ€æ–°çš„æƒé‡ä¸º d
        weights = np.arange(1, d + 1, dtype=np.float64)
        weights /= weights.sum()

        def _weighted_mean(x: np.ndarray) -> float:
            if np.any(np.isnan(x)):
                # æœ‰ NaN æ—¶ç”¨æœ‰æ•ˆæ•°æ®é‡æ–°åŠ æƒ
                valid_mask = ~np.isnan(x)
                if valid_mask.sum() < max(1, d // 2):
                    return np.nan
                w = weights[valid_mask]
                w = w / w.sum()
                return np.dot(w, x[valid_mask])
            return np.dot(weights, x)

        return df.rolling(window=d, min_periods=max(1, d // 2)).apply(
            _weighted_mean, raw=True
        )

    @staticmethod
    def Neutralize(
        df: pd.DataFrame,
        group_data: Union[pd.Series, pd.DataFrame],
    ) -> pd.DataFrame:
        """
        è¡Œä¸šä¸­æ€§åŒ–ï¼šåˆ©ç”¨ OLS æ®‹å·®æ³•å‰”é™¤è¡Œä¸šæš´éœ²ã€‚

        å¯¹æ¯ä¸ªæ—¶é—´æˆªé¢ï¼Œä»¥è¡Œä¸šè™šæ‹Ÿå˜é‡ä¸ºè‡ªå˜é‡åš OLS å›å½’ï¼Œå–æ®‹å·®ä½œä¸º
        ä¸­æ€§åŒ–åçš„å› å­å€¼ã€‚æ®‹å·®ä¸å«è¡Œä¸šå…±æ€§æˆåˆ†ã€‚

        Parameters
        ----------
        df         : éœ€è¦ä¸­æ€§åŒ–çš„å› å­çŸ©é˜µ (T Ã— N)
        group_data : è¡Œä¸šæ˜ å°„
            - pd.Series: index=è‚¡ç¥¨ä»£ç ï¼Œvalues=è¡Œä¸šåç§°ï¼ˆé™æ€è¡Œä¸šï¼‰
            - pd.DataFrame: (T Ã— N)ï¼Œæ”¯æŒåŠ¨æ€è¡Œä¸šå˜æ›´ï¼ˆæš‚ä¸å®ç°ï¼Œé»˜è®¤å–æœ€åä¸€è¡Œï¼‰

        Returns
        -------
        pd.DataFrame : è¡Œä¸šä¸­æ€§åŒ–åçš„å› å­çŸ©é˜µï¼Œå‡å€¼æ¥è¿‘0

        Notes
        -----
        å®ç°ç»†èŠ‚ï¼š
        1. æ„å»ºè¡Œä¸šå“‘å˜é‡çŸ©é˜µ X (N Ã— n_industries)
        2. å¯¹å½“æ—¥æœ‰æ•ˆè‚¡ç¥¨å­é›†ï¼ŒOLS: factor = X * beta + residual
        3. å– residual ä½œä¸ºæ–°çš„å› å­å€¼
        """
        # å¤„ç† group_data æ ¼å¼
        if isinstance(group_data, pd.DataFrame):
            # å–æœ€åä¸€è¡Œä½œä¸ºé™æ€è¡Œä¸šåˆ†ç±»
            group_series = group_data.iloc[-1]
        else:
            group_series = group_data  # pd.Series

        # å¯¹é½è‚¡ç¥¨åˆ—è¡¨
        common_stocks = df.columns.intersection(group_series.index)
        df_aligned = df[common_stocks]
        group_aligned = group_series[common_stocks]

        # é¢„æ„å»ºå“‘å˜é‡çŸ©é˜µï¼ˆé™æ€ï¼‰
        dummies = pd.get_dummies(group_aligned, dtype=np.float64).values  # (N, K)

        result = pd.DataFrame(np.nan, index=df.index, columns=df.columns)

        for date in df.index:
            row = df_aligned.loc[date].values  # (N,)
            valid_mask = ~np.isnan(row)

            if valid_mask.sum() < dummies.shape[1] + 1:
                # æœ‰æ•ˆè‚¡ç¥¨æ•°é‡ä¸è¶³ï¼Œæ— æ³•å›å½’
                result.loc[date, common_stocks] = row
                continue

            X = dummies[valid_mask]       # (n_valid, K)
            y = row[valid_mask]           # (n_valid,)

            # OLS: min ||y - X*beta||^2
            try:
                beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)
                residuals = y - X @ beta
                # å°†æ®‹å·®å†™å›
                res_full = np.full(valid_mask.shape, np.nan)
                res_full[valid_mask] = residuals
                result.loc[date, common_stocks] = res_full
            except np.linalg.LinAlgError:
                result.loc[date, common_stocks] = row

        return result

    # ==================================================================
    # æ—¶åºç±»æ‰©å±•ç®—å­ (Time-Series Extended)
    # ==================================================================

    @staticmethod
    def Ts_Skew(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """
        æ»šåŠ¨ååº¦ï¼ˆä¸‰é˜¶æ ‡å‡†çŸ©ï¼‰ã€‚

        è¡¡é‡çª—å£å†…æ”¶ç›Šç‡åˆ†å¸ƒçš„ä¸å¯¹ç§°ç¨‹åº¦ï¼š
          - æ­£ååº¦ï¼ˆå³åï¼‰ï¼šå³å°¾é•¿ï¼Œæç«¯æ­£æ”¶ç›Šæ¦‚ç‡æ›´é«˜
          - è´Ÿååº¦ï¼ˆå·¦åï¼‰ï¼šå·¦å°¾é•¿ï¼Œæç«¯è´Ÿæ”¶ç›Šæ¦‚ç‡æ›´é«˜

        æ•°å­¦å®šä¹‰ï¼š
            Skew = E[(X - Î¼)Â³] / ÏƒÂ³

        Parameters
        ----------
        df     : è¾“å…¥çŸ©é˜µ (T Ã— N)ï¼Œé€šå¸¸ä¸ºæ”¶ç›Šç‡åºåˆ—
        window : æ»šåŠ¨çª—å£å¤§å°ï¼ˆè‡³å°‘éœ€è¦ 3 ä¸ªæ ·æœ¬ï¼‰

        Returns
        -------
        pd.DataFrame : ä¸ df åŒå½¢çŠ¶ï¼Œå‰ window-1 è¡Œä¸º NaN
        """
        return df.rolling(window=window, min_periods=max(3, window)).skew()

    @staticmethod
    def Ts_Kurt(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """
        æ»šåŠ¨å³°åº¦ï¼ˆå››é˜¶æ ‡å‡†çŸ©ï¼Œè¶…é¢å³°åº¦ï¼‰ã€‚

        è¡¡é‡çª—å£å†…åˆ†å¸ƒå°¾éƒ¨åšåº¦ï¼š
          - æ­£è¶…é¢å³°åº¦ï¼ˆ> 0ï¼‰ï¼šå°–å³°åšå°¾ï¼Œæç«¯å€¼æ›´é¢‘ç¹ï¼ˆæ­£æ€åˆ†å¸ƒ = 0ï¼‰
          - è´Ÿè¶…é¢å³°åº¦ï¼ˆ< 0ï¼‰ï¼šæ‰å³°è–„å°¾ï¼Œåˆ†å¸ƒæ›´é›†ä¸­

        æ•°å­¦å®šä¹‰ï¼ˆFisher è¶…é¢å³°åº¦ï¼‰ï¼š
            Kurt = E[(X - Î¼)â´] / Ïƒâ´ - 3

        Parameters
        ----------
        df     : è¾“å…¥çŸ©é˜µ (T Ã— N)
        window : æ»šåŠ¨çª—å£å¤§å°ï¼ˆè‡³å°‘éœ€è¦ 4 ä¸ªæ ·æœ¬ï¼‰

        Returns
        -------
        pd.DataFrame : è¶…é¢å³°åº¦ï¼Œæ­£æ€åˆ†å¸ƒå¯¹åº”å€¼ä¸º 0
        """
        return df.rolling(window=window, min_periods=max(4, window)).kurt()

    @staticmethod
    def Ts_Autocorr(
        df: pd.DataFrame,
        lag: int,
        window: int,
    ) -> pd.DataFrame:
        """
        æ»šåŠ¨è‡ªç›¸å…³ç³»æ•°ï¼ˆlag é˜¶ Pearson è‡ªç›¸å…³ï¼‰ã€‚

        è¡¡é‡æ—¶é—´åºåˆ—åœ¨ lag æœŸæ»åä¸‹çš„çº¿æ€§ç›¸å…³æ€§ï¼š
          - æ­£è‡ªç›¸å…³ï¼šåºåˆ—æœ‰è¶‹åŠ¿æ€§ï¼ˆåŠ¨é‡ï¼‰
          - è´Ÿè‡ªç›¸å…³ï¼šåºåˆ—æœ‰åè½¬æ€§ï¼ˆå‡å€¼å›å½’ï¼‰

        æ•°å­¦å®šä¹‰ï¼š
            AutoCorr(lag) = corr(Xâ‚œ, Xâ‚œâ‚‹â‚—â‚â‚‰) in rolling window

        Parameters
        ----------
        df     : è¾“å…¥çŸ©é˜µ (T Ã— N)
        lag    : æ»åé˜¶æ•°ï¼ˆå¤©æ•°ï¼‰
        window : æ»šåŠ¨çª—å£å¤§å°ï¼Œé¡»æ»¡è¶³ window > lag

        Returns
        -------
        pd.DataFrame : å€¼åŸŸ [-1, 1]

        Notes
        -----
        åŸºäº pandas rolling.corr å®ç°å…¨å‘é‡åŒ–è®¡ç®—ï¼Œæ— æ˜¾å¼å¾ªç¯ã€‚
        """
        if window <= lag:
            raise ValueError(
                f"window ({window}) å¿…é¡»å¤§äº lag ({lag})ï¼Œ"
                f"å¦åˆ™æ— æ³•è®¡ç®—æœ‰æ•ˆçš„è‡ªç›¸å…³ç³»æ•°ã€‚"
            )
        return df.rolling(window=window, min_periods=window).corr(df.shift(lag))

    @staticmethod
    def Ts_Hurst(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """
        æ»šåŠ¨ Hurst æŒ‡æ•°ï¼ˆåŸºäº R/S åˆ†æçš„å•å°ºåº¦è¿‘ä¼¼ï¼‰ã€‚

        Hurst æŒ‡æ•° H è¡¡é‡æ—¶é—´åºåˆ—çš„é•¿ç¨‹ä¾èµ–æ€§ï¼ˆåˆ†å½¢ç»´åº¦ï¼‰ï¼š
          - H â‰ˆ 0.5 â†’ éšæœºæ¸¸èµ°ï¼ˆå¸ƒæœ—è¿åŠ¨ï¼‰ï¼Œæ— è®°å¿†æ€§
          - H > 0.5 â†’ æŒç»­æ€§è¶‹åŠ¿ï¼Œè¿‡å»æ¶¨åˆ™æœªæ¥æ›´å¯èƒ½ç»§ç»­æ¶¨
          - H < 0.5 â†’ åæŒç»­æ€§ï¼ˆå‡å€¼å›å½’ï¼‰ï¼Œè¿‡å»æ¶¨åˆ™æœªæ¥æ›´å¯èƒ½è·Œ

        R/S åˆ†æï¼ˆRescaled Range Analysisï¼‰ï¼š
            1. è®¡ç®—çª—å£å‡å€¼ Î¼
            2. ç´¯ç§¯åå·®åºåˆ— Y(t) = Î£(X(i) - Î¼)
            3. æå·® R = max(Y) - min(Y)
            4. æ ‡å‡†å·® S = std(X)
            5. H = log(R/S) / log(n/2)ï¼ˆå•å°ºåº¦è¿‘ä¼¼ï¼Œn = çª—å£é•¿åº¦ï¼‰

        Parameters
        ----------
        df     : è¾“å…¥çŸ©é˜µ (T Ã— N)ï¼Œé€šå¸¸ä¸ºå¯¹æ•°æ”¶ç›Šç‡åºåˆ—ï¼ˆä½¿ç”¨å‰è¯·å– log returnï¼‰
        window : æ»šåŠ¨çª—å£å¤§å°ï¼ˆå»ºè®® â‰¥ 20ï¼Œè¶Šå¤§è¶Šç¨³å®šï¼‰

        Returns
        -------
        pd.DataFrame : å€¼åŸŸç†è®ºä¸º (0, 1)ï¼Œå®é™…çº¦åœ¨ [0.3, 0.8]

        Notes
        -----
        ä½¿ç”¨ rolling.apply(raw=True) å®ç°ï¼Œ`raw=True` ä¼ é€’ numpy æ•°ç»„
        è€Œé Series å¯¹è±¡ï¼Œé¿å…äº† Python å¯¹è±¡å¼€é”€ï¼ˆçº¦å¿« 10 å€ï¼‰ã€‚
        """
        def _hurst_scalar(x: np.ndarray) -> float:
            """å•çª—å£ R/S Hurst ä¼°è®¡ã€‚"""
            n = len(x)
            if n < 8:
                return np.nan
            # è¿‡æ»¤ NaN
            x = x[~np.isnan(x)]
            if len(x) < 8:
                return np.nan
            mean_x   = x.mean()
            deviation = np.cumsum(x - mean_x)
            R = deviation.max() - deviation.min()    # æå·®
            S = x.std(ddof=1)                        # æ ‡å‡†å·®
            if S < 1e-10:
                return np.nan
            return np.log(R / S) / np.log(len(x) / 2)

        return df.rolling(
            window=window, min_periods=max(8, window // 2)
        ).apply(_hurst_scalar, raw=True)

    # ==================================================================
    # é‡ä»·å› å­ (Price-Volume)
    # ==================================================================

    @staticmethod
    def VWAP(
        close: pd.DataFrame,
        volume: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        æˆäº¤é‡åŠ æƒå¹³å‡ä»·ï¼ˆVWAPï¼ŒVolume Weighted Average Priceï¼‰ã€‚

        åœ¨æ»šåŠ¨çª—å£å†…ï¼Œä»¥æˆäº¤é‡ä¸ºæƒé‡è®¡ç®—åŠ æƒå¹³å‡ä»·æ ¼ï¼š
            VWAP = Î£(Páµ¢ Ã— Váµ¢) / Î£Váµ¢ï¼Œå¯¹ i âˆˆ [t-window+1, t]

        VWAP å¸¸è¢«è§†ä¸ºçŸ­æœŸå‡è¡¡ä»·æ ¼åŸºå‡†ï¼Œé«˜äº VWAP æ—¶ä¸ºå–å‹å¼ºä¿¡å·ï¼Œ
        ä½äº VWAP æ—¶ä¸ºä¹°ç›˜å¼ºä¿¡å·ã€‚

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        volume : æˆäº¤é‡çŸ©é˜µ (T Ã— N)ï¼Œå•ä½ä»»æ„
        window : æ»šåŠ¨çª—å£å¤§å°

        Returns
        -------
        pd.DataFrame : VWAP çŸ©é˜µ (T Ã— N)ï¼Œé‡çº²ä¸ close ç›¸åŒ
        """
        pv = close * volume
        vwap = (
            pv.rolling(window=window, min_periods=window).sum()
            / volume.rolling(window=window, min_periods=window).sum()
        )
        return vwap

    @staticmethod
    def VWAP_Bias(
        close: pd.DataFrame,
        volume: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        VWAP ä¹–ç¦»ç‡ï¼ˆVWAP Biasï¼‰ã€‚

        è¡¡é‡å½“å‰æ”¶ç›˜ä»·ç›¸å¯¹æ»šåŠ¨ VWAP çš„ç™¾åˆ†æ¯”åç¦»ç¨‹åº¦ï¼š
            VWAP_Bias = Close / VWAP(window) - 1

        ç»æµå«ä¹‰ï¼š
          - > 0ï¼šä»·æ ¼é«˜äº VWAPï¼Œå¤šå¤´å ä¼˜ï¼ˆæˆ–ç›¸å¯¹è¶…ä¹°ï¼‰
          - < 0ï¼šä»·æ ¼ä½äº VWAPï¼Œç©ºå¤´å ä¼˜ï¼ˆæˆ–ç›¸å¯¹ä½ä¼°ï¼‰
          - å‡å€¼å›å½’ä¿¡å·ï¼šæç«¯è´Ÿä¹–ç¦»ï¼ˆå¤§å¹…ä½äº VWAPï¼‰å¾€å¾€é¢„ç¤ºçŸ­æœŸåå¼¹
          - è¶‹åŠ¿è·Ÿè¸ªä¿¡å·ï¼šæŒç»­æ­£ä¹–ç¦»çš„è‚¡ç¥¨åŠ¨é‡è¾ƒå¼º

        ä¸ PVDeviation çš„åŒºåˆ«ï¼š
          - VWAP_Biasï¼šç™¾åˆ†æ¯”åç¦»ï¼ˆåŸå§‹å¹…åº¦ï¼Œä¿ç•™é‡çº²ï¼‰
          - PVDeviationï¼šé™¤ä»¥ä»·æ ¼æ ‡å‡†å·®æ ‡å‡†åŒ–ï¼ˆæ— é‡çº²ï¼‰

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        volume : æˆäº¤é‡çŸ©é˜µ (T Ã— N)ï¼Œå•ä½ä»»æ„
        window : è®¡ç®— VWAP çš„æ»šåŠ¨çª—å£å¤§å°

        Returns
        -------
        pd.DataFrame : VWAP ä¹–ç¦»ç‡ (T Ã— N)ï¼Œå€¼åŸŸæ— ç•Œï¼Œå…¸å‹èŒƒå›´ [-0.1, 0.1]
                       VWAP ä¸º 0 æˆ– NaN æ—¶å¯¹åº”ä½ç½®è¿”å› NaN
        """
        vwap = AlphaOps.VWAP(close, volume, window)
        vwap[vwap.abs() < 1e-10] = np.nan   # é¿å…é™¤ä»¥é›¶
        return close / vwap - 1.0

    @staticmethod
    def PVDeviation(
        close: pd.DataFrame,
        volume: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        é‡ä»·èƒŒç¦»æŒ‡æ ‡ï¼ˆPrice-Volume Deviationï¼‰ã€‚

        è¡¡é‡å½“å‰æ”¶ç›˜ä»·ä¸ VWAP çš„æ ‡å‡†åŒ–åå·®ï¼š
            PVDev = (Close - VWAP) / RollingStd(Close, window)

        ç»æµå«ä¹‰ï¼š
          - PVDev > 0ï¼šä»·æ ¼é«˜äºè¿‘æœŸé‡åŠ æƒå‡ä»·ï¼ˆç›¸å¯¹è¶…ä¹°ï¼‰
          - PVDev < 0ï¼šä»·æ ¼ä½äºè¿‘æœŸé‡åŠ æƒå‡ä»·ï¼ˆç›¸å¯¹è¶…å–ï¼‰
          - ç»“åˆæˆäº¤é‡åˆ†æï¼šé‡ç¼©ä»·å‡ï¼ˆPVDev > 0 + ç¼©é‡ï¼‰ä¸ºå¼ºåŠ¿ä¿¡å·

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        volume : æˆäº¤é‡çŸ©é˜µ (T Ã— N)
        window : è®¡ç®— VWAP å’Œæ ‡å‡†å·®çš„æ»šåŠ¨çª—å£

        Returns
        -------
        pd.DataFrame : æ ‡å‡†åŒ–é‡ä»·åå·®ï¼Œå€¼åŸŸæ— ç•Œï¼ˆå…¸å‹èŒƒå›´ [-3, 3]ï¼‰
        """
        vwap    = AlphaOps.VWAP(close, volume, window)
        std_    = close.rolling(window=window, min_periods=window).std()
        std_[std_ < 1e-10] = np.nan
        return (close - vwap) / std_

    @staticmethod
    def Amihud(
        close: pd.DataFrame,
        volume: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        Amihud éæµåŠ¨æ€§å› å­ï¼ˆAmihud Illiquidity Ratioï¼‰ã€‚

        è¡¡é‡å•ä½æˆäº¤é‡å¼•èµ·çš„ä»·æ ¼å†²å‡»ï¼Œæ˜¯æµåŠ¨æ€§çš„åå‘æŒ‡æ ‡ï¼š
            Illiq = mean(|retâ‚œ| / volumeâ‚œ) for t in [t-window+1, t]

        å…¶ä¸­ ret = close/close.shift(1) - 1ï¼ˆæ—¥æ”¶ç›Šç‡ç»å¯¹å€¼ï¼‰ã€‚

        ç»æµå«ä¹‰ï¼š
          - Illiq è¶Šå¤§ â†’ æµåŠ¨æ€§è¶Šå·®ï¼Œå°é¢äº¤æ˜“å¼•èµ·å¤§å¹…ä»·æ ¼æ³¢åŠ¨
          - å¸¸ä½œä¸ºæµåŠ¨æ€§æº¢ä»·å› å­ï¼šéæµåŠ¨æ€§é«˜çš„è‚¡ç¥¨è¦æ±‚æ›´é«˜é¢„æœŸæ”¶ç›Š
          - å¾®ç›˜è‚¡ Illiq é€šå¸¸è¿œé«˜äºå¤§ç›˜è“ç­¹è‚¡

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        volume : æˆäº¤é‡çŸ©é˜µ (T Ã— N)ï¼Œå»ºè®®å•ä½ä¸º"æ‰‹ï¼ˆ100è‚¡ï¼‰"æˆ–"å…ƒ"
        window : æ»šåŠ¨å‡å€¼çª—å£

        Returns
        -------
        pd.DataFrame : Amihud æ¯”ç‡ (T Ã— N)ï¼Œå€¼ â‰¥ 0

        Notes
        -----
        å»ºè®®åœ¨ä½¿ç”¨å‰å–å¯¹æ•°å˜æ¢ np.log(1 + Amihud) ä»¥æ¶ˆé™¤æç«¯å€¼ã€‚
        æˆäº¤é‡ä¸º 0 çš„è¡Œå¯¹åº”ä½ç½®è¿”å› NaNã€‚
        """
        ret     = close.pct_change()             # æ—¥æ”¶ç›Šç‡
        safe_vol = volume.replace(0, np.nan)     # é¿å…é™¤ä»¥é›¶
        illiq   = (ret.abs() / safe_vol).rolling(
            window=window, min_periods=window
        ).mean()
        return illiq

    # ==================================================================
    # åŠ¨é‡å› å­ (Momentum)
    # ==================================================================

    @staticmethod
    def RiskAdjMomentum(
        close: pd.DataFrame,
        window: int,
        vol_window: int,
    ) -> pd.DataFrame:
        """
        é£é™©è°ƒæ•´åŠ¨é‡å› å­ï¼ˆRisk-Adjusted Momentumï¼‰ã€‚

        ç»å…¸åŠ¨é‡å› å­ï¼ˆç´¯è®¡æ”¶ç›Šï¼‰é™¤ä»¥åŒæœŸæ³¢åŠ¨ç‡ï¼Œè¡¡é‡å•ä½é£é™©ä¸‹çš„åŠ¨é‡å¼ºåº¦ï¼š
            RiskAdjMom = PctChange(window) / RollingStd(ret, vol_window)

        ç›¸æ¯”åŸå§‹åŠ¨é‡ï¼Œé£é™©è°ƒæ•´åŠ¨é‡ï¼š
          - å‰”é™¤äº†é«˜æ³¢åŠ¨ç‡é©±åŠ¨çš„è™šå‡åŠ¨é‡ä¿¡å·
          - å¯¹ä½æ³¢åŠ¨ç‡è¶‹åŠ¿è‚¡ç»™äºˆæ›´é«˜è¯„åˆ†
          - ä¸ Sharpe æ¯”ç‡çš„æ¨ªæˆªé¢æ¯”è¾ƒå«ä¹‰ç±»ä¼¼

        Parameters
        ----------
        close      : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        window     : åŠ¨é‡è®¡ç®—å‘¨æœŸï¼ˆç´¯è®¡æ”¶ç›Šçš„å›çœ‹çª—å£ï¼Œå¤©æ•°ï¼‰
        vol_window : æ³¢åŠ¨ç‡è®¡ç®—çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé€šå¸¸ vol_window < window

        Returns
        -------
        pd.DataFrame : é£é™©è°ƒæ•´åŠ¨é‡å€¼ï¼Œå€¼åŸŸæ— ç•Œï¼ˆå…¸å‹èŒƒå›´ [-5, 5]ï¼‰
        """
        ret      = close.pct_change()
        cum_ret  = close.pct_change(periods=window)                   # ç´¯è®¡æ”¶ç›Š
        roll_vol = ret.rolling(window=vol_window, min_periods=vol_window).std()
        roll_vol[roll_vol < 1e-10] = np.nan
        return cum_ret / roll_vol

    @staticmethod
    def PricePathQuality(
        close: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        è·¯å¾„è´¨é‡å› å­ï¼ˆPrice Path Qualityï¼‰ã€‚

        è¡¡é‡ä»·æ ¼åœ¨ window å¤©å†…è¶‹åŠ¿çš„"å•è°ƒæ€§"ä¸"çº¿æ€§ç¨‹åº¦"ï¼š
            PathQuality = |Spearman(t, price)| Ã— Pearson(t, price)Â²

        - |Spearman(t, price)|ï¼šè¡¡é‡ä»·æ ¼æ—¶åºçš„å•è°ƒæ€§ï¼ˆå•è°ƒä¸Šæ¶¨/ä¸‹è·Œè¶Šå¼ºè¶Šæ¥è¿‘ 1ï¼‰
        - Pearson(t, price)Â²  ï¼šè¡¡é‡ä»·æ ¼ä¸æ—¶é—´çš„çº¿æ€§æ‹Ÿåˆä¼˜åº¦ï¼ˆRÂ²ï¼‰
        - ä¸¤è€…ä¹˜ç§¯ï¼šåŒæ—¶è¦æ±‚è¶‹åŠ¿å•è°ƒä¸”çº¿æ€§ï¼ˆé”¯é½¿å½¢è¶‹åŠ¿å¾—åˆ†ä½ï¼‰

        æ•°å€¼èŒƒå›´ [0, 1]ï¼š
          - æ¥è¿‘ 1 â†’ ä»·æ ¼åœ¨çª—å£å†…è¿‘ä¼¼çº¿æ€§å•è°ƒè¶‹åŠ¿ï¼ˆæœ€ä¼˜è¶‹åŠ¿è·¯å¾„ï¼‰
          - æ¥è¿‘ 0 â†’ éœ‡è¡æˆ–æ— æ˜æ˜¾è¶‹åŠ¿

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        window : è¯„ä¼°çª—å£å¤§å°ï¼ˆå»ºè®® 10~60 å¤©ï¼‰

        Returns
        -------
        pd.DataFrame : è·¯å¾„è´¨é‡åˆ†æ•° (T Ã— N)ï¼Œå€¼åŸŸ [0, 1]

        Notes
        -----
        ä½¿ç”¨ rolling.apply(raw=True) + scipy.statsï¼Œ
        raw=True ä¼ é€’ numpy æ•°ç»„ï¼Œæ€§èƒ½ä¼˜äº raw=False çº¦ 10 å€ã€‚
        """
        def _path_quality(x: np.ndarray) -> float:
            """è®¡ç®—å•ä¸ªçª—å£çš„è·¯å¾„è´¨é‡åˆ†æ•°ã€‚"""
            n = len(x)
            valid_mask = ~np.isnan(x)
            x_valid = x[valid_mask]
            if len(x_valid) < 4:
                return np.nan
            t = np.arange(len(x_valid), dtype=np.float64)
            # Spearman å•è°ƒæ€§
            rho_result = spearmanr(t, x_valid)
            rho = rho_result.statistic if hasattr(rho_result, 'statistic') else rho_result[0]
            if np.isnan(rho):
                return np.nan
            # Pearson çº¿æ€§ RÂ²
            r_result = pearsonr(t, x_valid)
            r = r_result.statistic if hasattr(r_result, 'statistic') else r_result[0]
            if np.isnan(r):
                return np.nan
            return float(abs(rho) * r ** 2)

        return close.rolling(
            window=window, min_periods=max(4, window // 2)
        ).apply(_path_quality, raw=True)

    @staticmethod
    def RangeBreakout(
        close: pd.DataFrame,
        high: pd.DataFrame,
        low: pd.DataFrame,
        window: int,
    ) -> pd.DataFrame:
        """
        åŒºé—´éœ‡è¡çªç ´å› å­ï¼ˆRange Breakout Positionï¼‰ã€‚

        è®¡ç®—å½“å‰æ”¶ç›˜ä»·åœ¨è¿‡å» window å¤©é«˜ä½åŒºé—´å†…çš„ç›¸å¯¹ä½ç½®ï¼ˆé€šé“ä½ç½®ï¼‰ï¼š
            RangeBreakout = (Close - RollingMin(Low, window))
                           / (RollingMax(High, window) - RollingMin(Low, window))

        ç»æµå«ä¹‰ï¼š
          - = 1.0 â†’ å½“å‰ä»·æ ¼å¤„äº window æ—¥æœ€é«˜ç‚¹ï¼ˆå¼ºåŠ¿çªç ´ï¼‰
          - = 0.0 â†’ å½“å‰ä»·æ ¼å¤„äº window æ—¥æœ€ä½ç‚¹ï¼ˆå¼±åŠ¿è·Œç ´ï¼‰
          - = 0.5 â†’ å¤„äºåŒºé—´ä¸­ä½
          - å¸¸ç”¨äºè¶‹åŠ¿è·Ÿè¸ªç­–ç•¥ï¼šå€¼é«˜ â†’ çœ‹å¤šï¼Œå€¼ä½ â†’ çœ‹ç©º

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        high   : æœ€é«˜ä»·çŸ©é˜µ (T Ã— N)
        low    : æœ€ä½ä»·çŸ©é˜µ (T Ã— N)
        window : åŒºé—´è®¡ç®—å›çœ‹çª—å£ï¼ˆå¤©æ•°ï¼‰

        Returns
        -------
        pd.DataFrame : åŒºé—´ä½ç½® (T Ã— N)ï¼Œå€¼åŸŸ [0, 1]ï¼Œ
                       åŒºé—´å®½åº¦æ¥è¿‘ 0 æ—¶è¿”å› NaN
        """
        rol_max = high.rolling(window=window, min_periods=window).max()
        rol_min = low.rolling(window=window, min_periods=window).min()
        range_  = rol_max - rol_min
        range_[range_ < 1e-10] = np.nan
        return (close - rol_min) / range_

    # ==================================================================
    # æŠ€æœ¯æŒ‡æ ‡ (Technical Indicators)
    # ==================================================================

    @staticmethod
    def RSI(close: pd.DataFrame, window: int = 14) -> pd.DataFrame:
        """
        ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼ˆRSIï¼ŒRelative Strength Indexï¼‰ã€‚

        ä½¿ç”¨ Wilder å¹³æ»‘æ³•ï¼ˆç­‰ä»·äº EWMï¼Œspan = 2Ã—window - 1ï¼‰è®¡ç®— RSIï¼š
            1. è®¡ç®—æ—¥æ”¶ç›Šå·®åˆ†ï¼šdelta = close.diff()
            2. åˆ†ç¦»ä¸Šæ¶¨ï¼ˆgainï¼‰ä¸ä¸‹è·Œï¼ˆlossï¼‰
            3. Wilder å¹³æ»‘ï¼šAvgGain = EWM(gain, span=2w-1)
                           AvgLoss = EWM(loss, span=2w-1)
            4. RS = AvgGain / AvgLoss
            5. RSI = 100 - 100 / (1 + RS)

        ç»æµå«ä¹‰ï¼š
          - RSI > 70 â†’ è¶…ä¹°åŒºé—´ï¼Œæ³¨æ„å›è°ƒé£é™©
          - RSI < 30 â†’ è¶…å–åŒºé—´ï¼Œæ³¨æ„åå¼¹æœºä¼š
          - ä¸æ ‡å‡† SMA ç‰ˆ RSI ä¸åŒï¼ŒWilder EWM æ›´å¹³æ»‘ï¼Œé¿å…çªå˜

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        window : RSI è®¡ç®—å‘¨æœŸï¼Œæ ‡å‡†å€¼ä¸º 14 å¤©

        Returns
        -------
        pd.DataFrame : RSI å€¼ (T Ã— N)ï¼Œå€¼åŸŸ [0, 100]

        Notes
        -----
        å…¨å‘é‡åŒ–å®ç°ï¼ˆåŸºäº pandas ewmï¼‰ï¼Œæ— æ˜¾å¼è‚¡ç¥¨å¾ªç¯ã€‚
        span = 2Ã—window - 1 æ˜¯ Wilder å¹³æ»‘ä¸ EWM çš„ç­‰ä»·å˜æ¢å…³ç³»ã€‚
        """
        delta  = close.diff()
        gain   = delta.clip(lower=0.0)          # ä¸Šæ¶¨éƒ¨åˆ†ï¼Œè·Œåˆ™ä¸º 0
        loss   = (-delta).clip(lower=0.0)       # ä¸‹è·Œç»å¯¹å€¼ï¼Œæ¶¨åˆ™ä¸º 0
        span   = 2 * window - 1                 # Wilder å¹³æ»‘ç­‰ä»· EWM span
        avg_gain = gain.ewm(span=span, min_periods=window, adjust=False).mean()
        avg_loss = loss.ewm(span=span, min_periods=window, adjust=False).mean()
        rs       = avg_gain / avg_loss.replace(0, np.nan)
        rsi      = 100.0 - 100.0 / (1.0 + rs)
        return rsi

    @staticmethod
    def KDJ(
        close: pd.DataFrame,
        high: pd.DataFrame,
        low: pd.DataFrame,
        n: int = 9,
        m1: int = 3,
        m2: int = 3,
    ) -> pd.DataFrame:
        """
        KDJ éšæœºæŒ‡æ ‡â€”â€”è¿”å› K å€¼ï¼ˆæœ€å¸¸ç”¨äºå› å­æ„å»ºï¼‰ã€‚

        è®¡ç®—æ­¥éª¤ï¼š
            1. RSVï¼ˆåŸå§‹éšæœºå€¼ï¼‰ï¼š
               RSV = (Close - Lowest_Low(n)) / (Highest_High(n) - Lowest_Low(n)) Ã— 100
            2. K å€¼ï¼ˆKçº¿ï¼‰ï¼šK = EWM(RSV, span=2Ã—m1-1)
               ï¼ˆç­‰ä»·äº Wilder å¹³æ»‘ï¼šK = 2/3Ã—K(prev) + 1/3Ã—RSVï¼Œå½“ m1=3 æ—¶ï¼‰
            3. D å€¼ï¼ˆä¿¡å·çº¿ï¼‰ï¼šD = EWM(K, span=2Ã—m2-1)  [æœªè¿”å›]
            4. J å€¼ï¼ˆèƒŒç¦»ï¼‰  ï¼šJ = 3Ã—K - 2Ã—D            [æœªè¿”å›]

        ç»æµå«ä¹‰ï¼ˆK å€¼ï¼‰ï¼š
          - K > 80 â†’ è¶…ä¹°åŒºé—´ï¼Œè¶‹åŠ¿å¯èƒ½å‡å¼±
          - K < 20 â†’ è¶…å–åŒºé—´ï¼Œå­˜åœ¨åå¼¹æœºä¼š
          - K çº¿ä¸Šç©¿ D çº¿ â†’ é‡‘å‰ï¼Œä¹°å…¥ä¿¡å·
          - K çº¿ä¸‹ç©¿ D çº¿ â†’ æ­»å‰ï¼Œå–å‡ºä¿¡å·

        Parameters
        ----------
        close : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        high  : æœ€é«˜ä»·çŸ©é˜µ (T Ã— N)
        low   : æœ€ä½ä»·çŸ©é˜µ (T Ã— N)
        n     : RSV è®¡ç®—çš„å›çœ‹å¤©æ•°ï¼Œæ ‡å‡†å€¼ 9
        m1    : K å€¼çš„ EWM å‘¨æœŸï¼Œæ ‡å‡†å€¼ 3
        m2    : D å€¼çš„ EWM å‘¨æœŸï¼ˆå†…éƒ¨è®¡ç®—ç”¨ï¼‰ï¼Œæ ‡å‡†å€¼ 3

        Returns
        -------
        pd.DataFrame : K å€¼ (T Ã— N)ï¼Œå€¼åŸŸ [0, 100]

        Notes
        -----
        å…¨å‘é‡åŒ–å®ç°ï¼ŒåŸºäº pandas rolling + ewmï¼Œæ— æ˜¾å¼è‚¡ç¥¨å¾ªç¯ã€‚
        è‹¥éœ€ D/J å€¼ï¼Œå¯åœ¨å¤–éƒ¨è°ƒç”¨ï¼š
            D = KDJ_K.ewm(span=2*m2-1, adjust=False).mean()
            J = 3 * KDJ_K - 2 * D
        """
        # 1. è®¡ç®— n æ—¥æœ€é«˜ä»·/æœ€ä½ä»·
        highest_high = high.rolling(window=n, min_periods=n).max()
        lowest_low   = low.rolling(window=n, min_periods=n).min()

        # 2. RSVï¼šå½“å‰æ”¶ç›˜åœ¨ n æ—¥é«˜ä½åŒºé—´å†…çš„ç›¸å¯¹ä½ç½® Ã— 100
        range_ = highest_high - lowest_low
        range_[range_ < 1e-10] = np.nan
        rsv = (close - lowest_low) / range_ * 100.0

        # 3. K å€¼ï¼šå¯¹ RSV åš Wilder EWM å¹³æ»‘ï¼ˆspan = 2Ã—m1 - 1ï¼‰
        k_value = rsv.ewm(span=2 * m1 - 1, min_periods=n, adjust=False).mean()
        return k_value

    @staticmethod
    def MACD(
        close: pd.DataFrame,
        fast: int = 12,
        slow: int = 26,
        signal: int = 9,
    ) -> pd.DataFrame:
        """
        MACD æŸ±çŠ¶å›¾å› å­ï¼ˆMoving Average Convergence/Divergence Histogramï¼‰ã€‚

        è®¡ç®—æ­¥éª¤ï¼š
            1. EMA_fast  = EMA(close, fast)     [å¿«çº¿ï¼Œå¦‚ EMA(12)]
            2. EMA_slow  = EMA(close, slow)     [æ…¢çº¿ï¼Œå¦‚ EMA(26)]
            3. MACD çº¿   = EMA_fast - EMA_slow  [å·®ç¦»å€¼]
            4. Signal çº¿ = EMA(MACD çº¿, signal) [ä¿¡å·çº¿]
            5. MACD æŸ±   = MACD çº¿ - Signal çº¿  [è¿”å›å€¼ï¼Œå³ Histogram]

        ç»æµå«ä¹‰ï¼ˆæŸ±çŠ¶å›¾ï¼‰ï¼š
          - æŸ± > 0 â†’ å¿«çº¿åœ¨æ…¢çº¿ä¸Šæ–¹ï¼Œå¤šå¤´å ä¼˜
          - æŸ± < 0 â†’ å¿«çº¿åœ¨æ…¢çº¿ä¸‹æ–¹ï¼Œç©ºå¤´å ä¼˜
          - æŸ±ç”±è´Ÿè½¬æ­£ï¼ˆé›¶è½´ä¸Šç©¿ï¼‰â†’ é‡‘å‰ä¿¡å·
          - æŸ±ç”±æ­£è½¬è´Ÿï¼ˆé›¶è½´ä¸‹ç©¿ï¼‰â†’ æ­»å‰ä¿¡å·
          - æŸ±ç»å¯¹å€¼æ”¶ç¼© â†’ è¶‹åŠ¿å‡å¼±

        Parameters
        ----------
        close  : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        fast   : å¿«é€Ÿ EMA å‘¨æœŸï¼Œæ ‡å‡†å€¼ 12
        slow   : æ…¢é€Ÿ EMA å‘¨æœŸï¼Œæ ‡å‡†å€¼ 26
        signal : ä¿¡å·çº¿ EMA å‘¨æœŸï¼Œæ ‡å‡†å€¼ 9

        Returns
        -------
        pd.DataFrame : MACD æŸ±çŠ¶å›¾ï¼ˆHistogramï¼‰ (T Ã— N)ï¼Œå€¼åŸŸæ— ç•Œ
                       æ­£å€¼è¡¨ç¤ºä¸Šæ¶¨åŠ¨èƒ½å¼ºï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹è·ŒåŠ¨èƒ½å¼º

        Notes
        -----
        å…¨å‘é‡åŒ–å®ç°ï¼ˆä¸‰æ¬¡ ewmï¼‰ï¼Œæ— æ˜¾å¼è‚¡ç¥¨å¾ªç¯ã€‚
        è‹¥éœ€ MACD çº¿æˆ– Signal çº¿ï¼Œå¯åˆ†æ­¥è®¡ç®—ï¼š
            macd_line   = close.ewm(span=fast).mean() - close.ewm(span=slow).mean()
            signal_line = macd_line.ewm(span=signal).mean()
        """
        ema_fast   = close.ewm(span=fast,   min_periods=fast,   adjust=False).mean()
        ema_slow   = close.ewm(span=slow,   min_periods=slow,   adjust=False).mean()
        macd_line  = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, min_periods=signal, adjust=False).mean()
        histogram  = macd_line - signal_line
        return histogram

    # ==================================================================
    # ç¼©é‡ç¨³ä»·å› å­ (VolSpike-PriceStable)
    # ==================================================================
    #
    # æ ¸å¿ƒé€»è¾‘ï¼šæ‰¾å‡ºæˆäº¤é‡ï¼ˆæ¢æ‰‹ç‡ï¼‰çªç„¶æ”¾å¤§ï¼Œä½†ä»·æ ¼æ³¢åŠ¨å´å¼‚å¸¸æ”¶ç¼©çš„è‚¡ç¥¨ã€‚
    # æ­¤ç±»ä¿¡å·å¸¸è§äºä¸»åŠ›èµ„é‡‘åœ¨å»ºä»“é˜¶æ®µåˆ»æ„å‹åˆ¶ä»·æ ¼æ³¢åŠ¨çš„è¡Œä¸ºç‰¹å¾ï¼š
    #   - å¤§é‡æˆäº¤å‘ç”Ÿï¼Œä½†ä¹°å–åŒæ–¹åŠ›é‡å‡è¡¡ï¼Œä»·æ ¼çº¹ä¸ä¸åŠ¨
    #   - æš—ç¤ºæ°´ä¸‹ç­¹ç äº¤æ¢ï¼ˆæ´—ç›˜/å»ºä»“ï¼‰ï¼Œå±äºæ½œä¼ä¿¡å·
    #
    # ä¸‰ä¸ªå­å› å­ï¼š
    #   VolSpike        â€” æ¢æ‰‹ç‡è¿‘æœŸå‡å€¼ / å†å²å‡å€¼ï¼ˆé‡èƒ½æ”¾å¤§å€æ•°ï¼‰
    #   PriceVarShrink  â€” ä»·æ ¼æ–¹å·®è¿‘æœŸ / å†å²ï¼ˆæ³¢åŠ¨æ”¶ç¼©ç¨‹åº¦ï¼‰
    #   PriceMeanShrink â€” æ”¶ç›˜ä»·å‡å€¼è¿‘æœŸ / å†å²ï¼ˆä»·æ ¼è¶‹åŠ¿ä¸‹ç§»ç¨‹åº¦ï¼‰
    #
    # å¤åˆå› å­ï¼š
    #   VolSpikeStablePrice â€” åŒæ—¶æ»¡è¶³é‡æ”¾å¤§ã€ä»·æ ¼æ–¹å·®æ”¶ç¼©ã€å‡ä»·ä¸‹ç§»çš„ç»¼åˆä¿¡å·
    # ==================================================================

    @staticmethod
    def VolSpike(
        turnover: pd.DataFrame,
        n_short: int = 3,
        n_long: int = 10,
        n_multiple: float = 2.0,
    ) -> pd.DataFrame:
        """
        æˆäº¤é‡ï¼ˆæ¢æ‰‹ç‡ï¼‰æ”¾å¤§å› å­ï¼ˆVolume Spike Ratioï¼‰ã€‚

        è¡¡é‡å½“å‰çŸ­æœŸæ¢æ‰‹ç‡ç›¸å¯¹å†å²åŸºå‡†çš„æ”¾å¤§ç¨‹åº¦ï¼š
            VolSpike = M1 / M2

        å…¶ä¸­ï¼š
            M1 = mean(turnover, n_short)              â€” æœ€è¿‘ n_short å¤©å‡æ¢æ‰‹ç‡
            M2 = mean(turnover[t-n_short-n_long : t-n_short], n_long)
                                                       â€” å‰ n_long å¤©å‡æ¢æ‰‹ç‡ï¼ˆåŸºå‡†æœŸï¼‰

        åˆ¤å®šæ¡ä»¶ï¼ˆé‡æ˜¾è‘—æ”¾å¤§ï¼‰ï¼š
            VolSpike > n_multipleï¼ˆå³ M1 > M2 Ã— n_multipleï¼‰

        ç»æµå«ä¹‰ï¼š
          - VolSpike >> 1 â†’ è¿‘æœŸæˆäº¤é‡ç›¸æ¯”å†å²å¤§å¹…æ”¾å¤§ï¼Œå¸‚åœºæ´»è·ƒåº¦æ¿€å¢
          - ç»“åˆä»·æ ¼æ³¢åŠ¨æ”¶ç¼©ï¼ˆPriceVarShrinkï¼‰å¯è¯†åˆ«"é‡å¢ä»·ç¨³"çš„å»ºä»“è¡Œä¸º
          - å•ç‹¬ä½¿ç”¨æ—¶ä¹Ÿå¯ä½œä¸ºå¸‚åœºæƒ…ç»ª/æ´»è·ƒåº¦çš„ä»£ç†æŒ‡æ ‡

        Parameters
        ----------
        turnover   : æ¢æ‰‹ç‡çŸ©é˜µ (T Ã— N)ï¼Œå€¼ä¸ºæ¯æ—¥æ¢æ‰‹ç‡ï¼ˆå¦‚ 0.02 è¡¨ç¤º 2%ï¼‰
                     ä¹Ÿå¯æ›¿æ¢ä¸ºæˆäº¤é‡ã€æˆäº¤é¢ç­‰é‡èƒ½ä»£ç†æŒ‡æ ‡
        n_short    : çŸ­æœŸè§‚å¯Ÿçª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œè§‚å¯Ÿå½“å‰å¼‚åŠ¨ï¼Œé»˜è®¤ 3 å¤©
        n_long     : é•¿æœŸåŸºå‡†çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œä½œä¸ºèƒŒæ™¯å¯¹æ¯”ï¼Œé»˜è®¤ 10 å¤©
        n_multiple : åˆ¤å®š"æ˜¾è‘—æ”¾å¤§"çš„å€æ•°é˜ˆå€¼ï¼ˆå³ vol_mult å‚æ•°ï¼‰ï¼Œé»˜è®¤ 2.0
                     VolSpike > n_multiple æ—¶è§†ä¸ºé‡èƒ½æ˜¾è‘—æ”¾å¤§

        Returns
        -------
        pd.DataFrame : é‡èƒ½æ”¾å¤§æ¯”ç‡ (T Ã— N)ï¼Œå€¼ â‰¥ 0
                       å€¼åŸŸæ— ç•Œï¼ˆå…¸å‹èŒƒå›´ [0, 5]ï¼‰ï¼Œå‰ n_short+n_long-1 è¡Œä¸º NaN
                       M2 â‰¤ 0 æˆ–ä¸º NaN æ—¶å¯¹åº”ä½ç½®è¿”å› NaN

        Notes
        -----
        åŸºå‡†æœŸï¼ˆM2ï¼‰å– t æ—¥å¾€å‰æ¨ n_short å¤©ä¹‹å¤–çš„ n_long å¤©ï¼Œ
        ç¡®ä¿çŸ­æœŸçª—å£ï¼ˆM1ï¼‰ä¸åŸºå‡†æœŸï¼ˆM2ï¼‰å®Œå…¨ä¸é‡å ï¼Œé¿å…è‡ªç›¸å…³ã€‚
        """
        # M1ï¼šæœ€è¿‘ n_short å¤©å‡æ¢æ‰‹ç‡
        m1 = turnover.rolling(window=n_short, min_periods=n_short).mean()

        # M2ï¼šåŸºå‡†æœŸï¼ˆå‘å‰è·³è¿‡ n_short å¤©ï¼Œå†å– n_long å¤©ï¼‰
        # å®ç°ï¼šå…ˆå¯¹æ¢æ‰‹ç‡åš n_short å¤©å»¶è¿Ÿï¼Œå†å– n_long å¤©å‡å€¼
        m2 = turnover.shift(n_short).rolling(window=n_long, min_periods=n_long).mean()

        # é¿å…é™¤ä»¥é›¶æˆ–åŸºå‡†ä¸ºé›¶
        m2_safe = m2.copy()
        m2_safe[m2_safe.abs() < 1e-10] = np.nan

        return m1 / m2_safe

    @staticmethod
    def PriceVarShrink(
        close: pd.DataFrame,
        open_: pd.DataFrame,
        n_short: int = 3,
        n_long: int = 10,
        n_multiple: float = 0.5,
    ) -> pd.DataFrame:
        """
        ä»·æ ¼æ–¹å·®æ”¶ç¼©å› å­ï¼ˆPrice Variance Shrink Ratioï¼‰ã€‚

        è¡¡é‡è¿‘æœŸä»·æ ¼æ³¢åŠ¨ç›¸å¯¹å†å²åŸºå‡†çš„æ”¶ç¼©ç¨‹åº¦ï¼š
            PriceVarShrink = V1 / V2

        å…¶ä¸­ï¼Œæ–¹å·®è®¡ç®—å°†æ”¶ç›˜ä»·ä¸å¼€ç›˜ä»·åˆå¹¶åè”åˆè®¡ç®—ï¼ˆå¢å¤§æ ·æœ¬é‡ï¼Œæ›´ç¨³å¥ï¼‰ï¼š
            combined_short = [close_{t-n+1..t}, open_{t-n+1..t}]  åˆå¹¶ä¸º 2Ã—n_short ä¸ªç‚¹
            combined_long  = [close_{t-n_s-n_l+1..t-n_s}, open_{...}]  2Ã—n_long ä¸ªç‚¹
            V1 = var(combined_short)
            V2 = var(combined_long)

        åˆ¤å®šæ¡ä»¶ï¼ˆæ³¢åŠ¨æ˜¾è‘—æ”¶ç¼©ï¼‰ï¼š
            PriceVarShrink < n_multipleï¼ˆå³ V1 < V2 Ã— n_multipleï¼‰

        ç»æµå«ä¹‰ï¼š
          - PriceVarShrink << 1 â†’ è¿‘æœŸä»·æ ¼æ³¢åŠ¨å¤§å¹…æ”¶çª„ï¼ˆæ— è®ºå¼€ç›˜/æ”¶ç›˜å‡å¦‚æ­¤ï¼‰
          - ç»“åˆé‡èƒ½æ”¾å¤§ï¼ˆVolSpikeï¼‰æ„æˆ"é‡å¤§ä»·ç¨³"ä¿¡å·
          - ä»·æ ¼æ–¹å·®æ”¶ç¼©è¶Šå°ï¼Œè¯´æ˜ä¹°å–åŒæ–¹åœ¨åšå¼ˆä¸­è¶Šè¶‹äºå‡è¡¡ï¼ˆç­¹ç äº¤æ¢ï¼‰

        Parameters
        ----------
        close      : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        open_      : å¼€ç›˜ä»·çŸ©é˜µ (T Ã— N)ï¼ˆæ³¨æ„ï¼šPython ä¿ç•™å­—ï¼Œå‚æ•°åç”¨ open_ï¼‰
        n_short    : çŸ­æœŸæ–¹å·®è®¡ç®—çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 3 å¤©
        n_long     : é•¿æœŸæ–¹å·®åŸºå‡†çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 10 å¤©
        n_multiple : åˆ¤å®š"æ˜¾è‘—æ”¶ç¼©"çš„å€æ•°é˜ˆå€¼ï¼ˆå³ pricevar_shrink å‚æ•°ï¼‰ï¼Œé»˜è®¤ 0.5
                     PriceVarShrink < n_multiple æ—¶è§†ä¸ºä»·æ ¼æ³¢åŠ¨æ˜¾è‘—æ”¶ç¼©

        Returns
        -------
        pd.DataFrame : ä»·æ ¼æ–¹å·®æ”¶ç¼©æ¯”ç‡ (T Ã— N)ï¼Œå€¼ â‰¥ 0
                       å€¼è¶Šå°è¡¨ç¤ºè¿‘æœŸæ³¢åŠ¨ç›¸å¯¹å†å²è¶Šæ”¶ç¼©
                       V2 â‰¤ 0 æˆ–ä¸º NaN æ—¶å¯¹åº”ä½ç½®è¿”å› NaN

        Notes
        -----
        åˆå¹¶å¼€ç›˜ä»·ä¸æ”¶ç›˜ä»·åä¸€èµ·è®¡ç®—æ–¹å·®ï¼Œç­‰æ•ˆäºåŒæ—¶å…³æ³¨æ—¥å†…æŒ¯å¹…ä¸æ—¥é—´æ³¢åŠ¨ï¼Œ
        ä½¿çŸ­çª—å£ï¼ˆå¦‚ 3 å¤©åªæœ‰ 6 ä¸ªç‚¹ï¼‰çš„ä¼°è®¡æ›´ç¨³å¥ã€‚
        åŸºå‡†æœŸåŒæ ·è·³è¿‡ n_short å¤©ï¼Œä¸ VolSpike é€»è¾‘ä¿æŒä¸€è‡´ï¼Œç¡®ä¿çª—å£ä¸é‡å ã€‚
        """
        def _rolling_var_combined(
            price_a: pd.DataFrame,
            price_b: pd.DataFrame,
            window: int,
            shift: int = 0,
        ) -> pd.DataFrame:
            """å°†ä¸¤ä¸ªä»·æ ¼åºåˆ—åˆå¹¶åè®¡ç®—æ»šåŠ¨æ–¹å·®ï¼ˆé€åˆ— applyï¼‰ã€‚"""
            if shift > 0:
                price_a = price_a.shift(shift)
                price_b = price_b.shift(shift)

            def _col_var(col_a: pd.Series, col_b: pd.Series) -> pd.Series:
                """å¯¹å•åˆ—åˆå¹¶åºåˆ—æ±‚æ»šåŠ¨æ–¹å·®ã€‚"""
                def _var_window(idx: int) -> float:
                    if idx < window - 1:
                        return np.nan
                    a_vals = col_a.iloc[idx - window + 1 : idx + 1].values
                    b_vals = col_b.iloc[idx - window + 1 : idx + 1].values
                    combined = np.concatenate([a_vals, b_vals])
                    valid = combined[~np.isnan(combined)]
                    if len(valid) < 3:
                        return np.nan
                    return float(np.var(valid, ddof=1))

                return pd.Series(
                    [_var_window(i) for i in range(len(col_a))],
                    index=col_a.index,
                )

            result = {}
            for col in price_a.columns:
                result[col] = _col_var(price_a[col], price_b[col])
            return pd.DataFrame(result, index=price_a.index)[price_a.columns]

        # V1ï¼šæœ€è¿‘ n_short å¤©ï¼Œåˆå¹¶ close + open çš„æ–¹å·®
        v1 = _rolling_var_combined(close, open_, window=n_short, shift=0)

        # V2ï¼šåŸºå‡†æœŸï¼Œå‘å‰è·³è¿‡ n_short å¤©åå– n_long å¤©ï¼Œåˆå¹¶ close + open çš„æ–¹å·®
        v2 = _rolling_var_combined(close, open_, window=n_long, shift=n_short)

        # é¿å…é™¤ä»¥é›¶
        v2_safe = v2.copy()
        v2_safe[v2_safe.abs() < 1e-10] = np.nan

        return v1 / v2_safe

    @staticmethod
    def PriceMeanShrink(
        close: pd.DataFrame,
        n_short: int = 3,
        n_long: int = 10,
        n_multiple: float = 0.98,
    ) -> pd.DataFrame:
        """
        æ”¶ç›˜ä»·å‡å€¼ä¸‹ç§»å› å­ï¼ˆPrice Mean Shrink Ratioï¼‰ã€‚

        è¡¡é‡è¿‘æœŸæ”¶ç›˜ä»·å‡å€¼ç›¸å¯¹å†å²åŸºå‡†çš„ç›¸å¯¹æ°´å¹³ï¼š
            PriceMeanShrink = P1 / P2

        å…¶ä¸­ï¼š
            P1 = mean(close, n_short)              â€” æœ€è¿‘ n_short å¤©å‡ä»·
            P2 = mean(close[t-n_short-n_long : t-n_short], n_long)
                                                    â€” å‰ n_long å¤©å‡ä»·ï¼ˆåŸºå‡†æœŸï¼‰

        åˆ¤å®šæ¡ä»¶ï¼ˆä»·æ ¼å‡å€¼ç›¸å¯¹ä¸‹ç§»ï¼‰ï¼š
            PriceMeanShrink < n_multipleï¼ˆå³ P1 < P2 Ã— n_multipleï¼‰

        ç»æµå«ä¹‰ï¼š
          - PriceMeanShrink < 1 â†’ è¿‘æœŸå‡ä»·ä½äºå†å²åŸºå‡†ï¼Œè‚¡ä»·å¤„äºä¸‹æ²‰è¶‹åŠ¿
          - ä¸é‡èƒ½æ”¾å¤§ç»“åˆæ—¶ï¼Œè¡¨ç°ä¸º"é‡å¢ä»·è·Œ"æˆ–"é‡å¢ä»·æ¨ª"ä¸­çš„ä»·æ ¼æ»‘è½
          - ä¸»åŠ›åœ¨æ‰“å‹å¸ç­¹æ—¶å¸¸è§æ­¤å½¢æ€ï¼šå¢é‡æ¢æ‰‹ä½†å‡ä»·å°å¹…èµ°ä½
          - å€¼åŸŸé€šå¸¸åœ¨ [0.9, 1.1] é™„è¿‘ï¼›<1 ä¸ºä»·æ ¼ä¸‹ç§»ï¼Œ>1 ä¸ºä»·æ ¼ä¸Šç§»

        Parameters
        ----------
        close      : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        n_short    : çŸ­æœŸå‡å€¼è®¡ç®—çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 3 å¤©
        n_long     : é•¿æœŸåŸºå‡†çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 10 å¤©
        n_multiple : åˆ¤å®š"ä»·æ ¼å‡å€¼ä¸‹ç§»"çš„å€æ•°é˜ˆå€¼ï¼ˆå³ price_shrink å‚æ•°ï¼‰ï¼Œé»˜è®¤ 0.98
                     PriceMeanShrink < n_multiple æ—¶è§†ä¸ºå‡ä»·æ˜¾è‘—ä¸‹ç§»

        Returns
        -------
        pd.DataFrame : ä»·æ ¼å‡å€¼æ¯”ç‡ (T Ã— N)ï¼Œå€¼ > 0
                       < 1 è¡¨ç¤ºå‡ä»·ä¸‹ç§»ï¼Œ> 1 è¡¨ç¤ºå‡ä»·ä¸Šç§»ï¼Œ= 1 è¡¨ç¤ºæŒå¹³
                       P2 â‰¤ 0 æˆ–ä¸º NaN æ—¶å¯¹åº”ä½ç½®è¿”å› NaN

        Notes
        -----
        åŸºå‡†æœŸåŒæ ·è·³è¿‡ n_short å¤©ï¼Œä¸ VolSpike / PriceVarShrink é€»è¾‘ä¸€è‡´ï¼Œ
        ä¸‰ä¸ªå­å› å­å¯¹åº”åŒä¸€ç»„æ—¶é—´çª—å£ï¼Œå¯ç›´æ¥å¤åˆå åŠ ã€‚
        """
        # P1ï¼šæœ€è¿‘ n_short å¤©å‡ä»·
        p1 = close.rolling(window=n_short, min_periods=n_short).mean()

        # P2ï¼šåŸºå‡†æœŸï¼ˆå‘å‰è·³è¿‡ n_short å¤©ï¼Œå†å– n_long å¤©å‡å€¼ï¼‰
        p2 = close.shift(n_short).rolling(window=n_long, min_periods=n_long).mean()

        # é¿å…é™¤ä»¥é›¶ï¼ˆä»·æ ¼åºåˆ—é€šå¸¸ > 0ï¼Œä½†é˜²å¾¡æ€§å¤„ç†ï¼‰
        p2_safe = p2.copy()
        p2_safe[p2_safe.abs() < 1e-10] = np.nan

        return p1 / p2_safe

    @staticmethod
    def VolSpikeStablePrice(
        turnover: pd.DataFrame,
        close: pd.DataFrame,
        open_: pd.DataFrame,
        n_short: int = 3,
        n_long: int = 10,
        n_multiple: float = 2.0,
        vol_mult: float = 2.0,
        pricevar_shrink: float = 0.5,
        price_shrink: float = 0.98,
    ) -> pd.DataFrame:
        """
        ç¼©é‡ç¨³ä»·å¤åˆå› å­ï¼ˆVolume Spike + Stable Price Compositeï¼‰ã€‚

        åŒæ—¶æ•æ‰"æ¢æ‰‹ç‡æ˜¾è‘—æ”¾å¤§"ã€"ä»·æ ¼æ–¹å·®æ˜¾è‘—æ”¶ç¼©"ã€"å‡ä»·å°å¹…ä¸‹ç§»"ä¸‰é‡ä¿¡å·ï¼Œ
        ä¸‰è€…åŒæ—¶æ»¡è¶³æ—¶å¾—åˆ†æ›´é«˜ï¼Œç”¨äºè¯†åˆ«ä¸»åŠ›å»ºä»“/ç­¹ç äº¤æ¢è¡Œä¸ºã€‚

        å­å› å­è®¡ç®—ï¼š
            S1 = VolSpike(turnover, n_short, n_long)        â€” é‡èƒ½æ”¾å¤§æ¯”ï¼ˆM1/M2ï¼‰
            S2 = PriceVarShrink(close, open_, n_short, n_long) â€” ä»·æ ¼æ–¹å·®æ”¶ç¼©æ¯”ï¼ˆV1/V2ï¼‰
            S3 = PriceMeanShrink(close, n_short, n_long)    â€” å‡ä»·ä¸‹ç§»æ¯”ï¼ˆP1/P2ï¼‰

        å„å­å› å­ä¿¡å·æ–¹å‘ï¼š
            S1 è¶Šå¤§ï¼ˆé‡è¶Šæ”¾å¤§ï¼‰â†’ ä¿¡å·è¶Šå¼ºï¼Œä¹˜ä»¥æ­£æƒé‡
            S2 è¶Šå°ï¼ˆæ³¢åŠ¨è¶Šæ”¶ç¼©ï¼‰â†’ ä¿¡å·è¶Šå¼ºï¼Œå–å€’æ•°æˆ–è´Ÿå·
            S3 è¶Šå°ï¼ˆä»·æ ¼è¶Šä¸‹ç§»ï¼‰â†’ ä¿¡å·è¶Šå¼ºï¼Œå–å€’æ•°æˆ–è´Ÿå·

        å¤åˆæ‰“åˆ†ï¼ˆä¸‰é‡å½’ä¸€åŒ–ååŠ æƒï¼‰ï¼š
            ç»¼åˆä¿¡å· = w1 Ã— ZScore(S1) + w2 Ã— ZScore(-S2) + w3 Ã— ZScore(-S3)

        å…¶ä¸­å„è‡ªçš„æˆªæ­¢é˜ˆå€¼ï¼ˆvol_mult / pricevar_shrink / price_shrinkï¼‰å†³å®š
        å„å­å› å­æ˜¯å¦çœŸæ­£"æ˜¾è‘—"â€”â€”å¾—åˆ†ç”±åŸå§‹æ¯”ç‡ç›´æ¥è®¡ç®—ï¼Œé˜ˆå€¼å‚æ•°ä¾›å¤–éƒ¨åˆ†æä½¿ç”¨ã€‚

        Parameters
        ----------
        turnover        : æ¢æ‰‹ç‡çŸ©é˜µ (T Ã— N)
        close           : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        open_           : å¼€ç›˜ä»·çŸ©é˜µ (T Ã— N)
        n_short         : çŸ­æœŸè§‚å¯Ÿçª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 3 å¤©
        n_long          : é•¿æœŸåŸºå‡†çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 10 å¤©
        n_multiple      : ä¸‰ä¸ªå­å› å­å…±ç”¨çš„åŸºç¡€å€æ•°å‚æ•°ï¼Œä¼ å…¥å„å­å› å­çš„ n_multiple
                          ï¼ˆå½“ä¸‰ä¸ªé˜ˆå€¼éœ€ç»Ÿä¸€è°ƒæ•´æ—¶ä½¿ç”¨ï¼›ç‹¬ç«‹è°ƒæ•´è¯·åˆ†åˆ«è®¾ç½®ä¸‹æ–¹å‚æ•°ï¼‰
        vol_mult        : é‡èƒ½æ”¾å¤§çš„åˆ¤å®šé˜ˆå€¼ï¼ˆVolSpike > vol_mult ä¸ºæ˜¾è‘—ï¼‰ï¼Œé»˜è®¤ 2.0
                          è¦†ç›– n_multiple å¯¹ VolSpike å­å› å­çš„å½±å“
        pricevar_shrink : ä»·æ ¼æ–¹å·®æ”¶ç¼©çš„åˆ¤å®šé˜ˆå€¼ï¼ˆPriceVarShrink < pricevar_shrink ä¸ºæ˜¾è‘—ï¼‰ï¼Œ
                          é»˜è®¤ 0.5ï¼›è¦†ç›– n_multiple å¯¹ PriceVarShrink å­å› å­çš„å½±å“
        price_shrink    : å‡ä»·ä¸‹ç§»çš„åˆ¤å®šé˜ˆå€¼ï¼ˆPriceMeanShrink < price_shrink ä¸ºæ˜¾è‘—ï¼‰ï¼Œ
                          é»˜è®¤ 0.98ï¼›è¦†ç›– n_multiple å¯¹ PriceMeanShrink å­å› å­çš„å½±å“

        Returns
        -------
        pd.DataFrame : å¤åˆå› å­å¾—åˆ† (T Ã— N)ï¼Œå€¼åŸŸæ— ç•Œï¼ˆæˆªé¢ ZScore æ ‡å‡†åŒ–åçš„çº¿æ€§ç»„åˆï¼‰
                       æ­£å€¼è¡¨ç¤º"é‡å¢ä»·ç¨³"ä¿¡å·å¼ºåº¦è¶Šé«˜
                       å‰ n_short+n_long-1 è¡Œä¸º NaN

        Notes
        -----
        1. ä¸‰ä¸ªå­å› å­å…ˆåšæˆªé¢ ZScore æ ‡å‡†åŒ–ï¼Œå†ç­‰æƒç›¸åŠ ï¼Œç¡®ä¿é‡çº²ç»Ÿä¸€ã€‚
        2. S2ï¼ˆä»·æ ¼æ–¹å·®æ¯”ï¼‰å–è´Ÿå·å ZScoreï¼Œä½¿"æ³¢åŠ¨è¶Šæ”¶ç¼© â†’ å¾—åˆ†è¶Šé«˜"ã€‚
        3. S3ï¼ˆå‡ä»·æ¯”ï¼‰å–è´Ÿå·å ZScoreï¼Œä½¿"å‡ä»·è¶Šä¸‹ç§» â†’ å¾—åˆ†è¶Šé«˜"ã€‚
        4. é˜ˆå€¼å‚æ•°ï¼ˆvol_mult / pricevar_shrink / price_shrinkï¼‰ä¸å½±å“å› å­å€¼çš„
           è®¡ç®—é€»è¾‘ï¼Œä»…ä½œä¸ºç­–ç•¥å±‚é¢çš„å‚è€ƒé˜ˆå€¼ï¼Œä¾›å¤–éƒ¨æ¡ä»¶ç­›é€‰ä½¿ç”¨ã€‚
        5. å¦‚éœ€ä»…ä¿ç•™"ä¸‰é‡ä¿¡å·åŒæ—¶æ»¡è¶³"çš„è‚¡ç¥¨ï¼Œå¯åœ¨å¤–éƒ¨åšå¦‚ä¸‹æ©ç ï¼š
               mask = (S1 > vol_mult) & (S2 < pricevar_shrink) & (S3 < price_shrink)
               factor = composite.where(mask)
        """
        # â”€â”€ è®¡ç®—ä¸‰ä¸ªå­å› å­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        s1 = AlphaOps.VolSpike(
            turnover,
            n_short=n_short,
            n_long=n_long,
            n_multiple=vol_mult,
        )
        s2 = AlphaOps.PriceVarShrink(
            close,
            open_,
            n_short=n_short,
            n_long=n_long,
            n_multiple=pricevar_shrink,
        )
        s3 = AlphaOps.PriceMeanShrink(
            close,
            n_short=n_short,
            n_long=n_long,
            n_multiple=price_shrink,
        )

        # â”€â”€ æˆªé¢ ZScore æ ‡å‡†åŒ– + æ–¹å‘å¯¹é½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # S1ï¼šé‡èƒ½è¶Šå¤§ â†’ å¾—åˆ†è¶Šé«˜ï¼ˆæ­£å‘ï¼‰
        z1 = AlphaOps.ZScore(s1)

        # S2ï¼šæ³¢åŠ¨è¶Šæ”¶ç¼©ï¼ˆæ¯”ç‡è¶Šå°ï¼‰â†’ å¾—åˆ†è¶Šé«˜ï¼ˆå–è´Ÿåæ ‡å‡†åŒ–ï¼‰
        z2 = AlphaOps.ZScore(-s2)

        # S3ï¼šå‡ä»·è¶Šä¸‹ç§»ï¼ˆæ¯”ç‡è¶Šå°ï¼‰â†’ å¾—åˆ†è¶Šé«˜ï¼ˆå–è´Ÿåæ ‡å‡†åŒ–ï¼‰
        z3 = AlphaOps.ZScore(-s3)

        # â”€â”€ ç­‰æƒå¤åˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        composite = (z1 + z2 + z3) / 3.0

        return composite

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ†• V3 æ‰©å±•ï¼šå¸ƒæ—å¸¦å¼‚åŠ¨å› å­
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def Bollinger_Outlier_Frequency(
        close: pd.DataFrame,
        period: int = 30,
        k: float = 3.5,
        lookback_window: int = 60,
    ) -> pd.DataFrame:
        """
        å¸ƒæ—å¸¦æç«¯çªç ´é¢‘ç‡å› å­ï¼ˆBollinger Band Outlier Frequencyï¼‰ã€‚

        è®¡ç®—åœ¨è¿‡å» lookback_window å¤©å†…ï¼Œæ”¶ç›˜ä»·çªç ´æå®½å¸ƒæ—å¸¦ï¼ˆk å€æ ‡å‡†å·®ï¼‰
        ä¸Šè½¨æˆ–ä¸‹è½¨çš„å¤©æ•°å æ¯”ï¼Œè¡¡é‡è‚¡ç¥¨çš„"ç ´ä½"ç‰¹å¾ä¸æç«¯è¶‹åŠ¿å¼ºåº¦ã€‚

        è®¡ç®—æ­¥éª¤ï¼š
            1. ä¸­è½¨ (MB)    = close çš„ period æ—¥ç®€å•ç§»åŠ¨å¹³å‡
            2. æ ‡å‡†å·® (std) = close çš„ period æ—¥æ»šåŠ¨æ ‡å‡†å·®
            3. ä¸Šè½¨ (Upper) = MB + k * std
            4. ä¸‹è½¨ (Lower) = MB - k * std
            5. ç¦»ç¾¤åˆ¤å®šï¼šclose > Upper æˆ– close < Lowerï¼Œè®°ä¸º 1ï¼Œå¦åˆ™è®°ä¸º 0
            6. é¢‘ç‡å¾—åˆ†    = rolling_mean(outlier, lookback_window)
                            å³è¿‡å» lookback_window å¤©å†…ç¦»ç¾¤å¤©æ•°å æ€»å¤©æ•°çš„æ¯”ä¾‹

        ç»æµå«ä¹‰ï¼š
          - é¢‘ç‡è¶Šé«˜ â†’ è‚¡ä»·åå¤å†²ç ´æå®½å¸ƒæ—å¸¦ï¼Œè¶‹åŠ¿æå¼ºæˆ–å­˜åœ¨å¼‚å¸¸æ³¢åŠ¨
          - k=3.5 çš„æå®½è®¾å®šä½¿å¾—æ­£æ€åˆ†å¸ƒä¸‹ç†è®ºçªç ´æ¦‚ç‡ < 0.05%ï¼Œ
            å®é™…çªç ´ä»£è¡¨çœŸå®çš„ä»·æ ¼å¼‚å¸¸æˆ–è¶‹åŠ¿æ€§çªç ´
          - é«˜é¢‘ç‡ä¿¡å·å¯ç”¨äºåŠ¨é‡è·Ÿè¸ªï¼ˆè¶‹åŠ¿æŒç»­æ€§å¼ºï¼‰æˆ–å¼‚å¸¸æ£€æµ‹ï¼ˆä»·æ ¼è¡Œä¸ºå¼‚å¸¸ï¼‰

        Parameters
        ----------
        close          : æ”¶ç›˜ä»·çŸ©é˜µ (T Ã— N)
        period         : å¸ƒæ—å¸¦å‡çº¿ä¸æ ‡å‡†å·®çš„è®¡ç®—çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 30 å¤©
        k              : æ ‡å‡†å·®å€æ•°ï¼Œé»˜è®¤ 3.5ï¼ˆæå®½å¸¦ï¼Œç†è®ºçªç ´ç‡ < 0.05%ï¼‰
        lookback_window: ç»Ÿè®¡çªç ´é¢‘ç‡çš„å›æµ‹çª—å£ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ 60 å¤©

        Returns
        -------
        pd.DataFrame : çªç ´é¢‘ç‡ (T Ã— N)ï¼Œå€¼åŸŸ [0, 1]
                       0 = è¿‡å» lookback_window å¤©å†…ä»æœªçªç ´å¸ƒæ—å¸¦
                       1 = æ¯å¤©éƒ½åœ¨çªç ´å¸ƒæ—å¸¦
                       å‰ period + lookback_window - 2 è¡Œä¸º NaN

        Notes
        -----
        - std ä¸º 0ï¼ˆä»·æ ¼å®Œå…¨æ— æ³¢åŠ¨ï¼‰æ—¶ï¼Œå°† std_safe ç½®ä¸º NaNï¼Œ
          é¿å…è™šå‡çªç ´ä¿¡å·ï¼ˆä»·æ ¼ç­‰äºå‡å€¼å´å›  std=0 å¯¼è‡´ Upper=Lower=MBï¼‰
        - å»ºè®®ä¸ Rank() æ­é…ä½¿ç”¨åšæˆªé¢æ’ååé€å…¥ VectorEngine
        """
        # â”€â”€ Step 1 & 2ï¼šä¸­è½¨ + æ ‡å‡†å·® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mb  = close.rolling(window=period, min_periods=period).mean()
        std = close.rolling(window=period, min_periods=period).std()

        # æ ‡å‡†å·®ä¸º 0 æ—¶ç½® NaNï¼ˆé˜²æ­¢å…¨ä»·æ ¼ç›¸ç­‰å¯¼è‡´è™šå‡çªç ´ï¼‰
        std_safe = std.copy()
        std_safe[std_safe.abs() < 1e-10] = np.nan

        # â”€â”€ Step 3 & 4ï¼šä¸Šä¸‹è½¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        upper = mb + k * std_safe
        lower = mb - k * std_safe

        # â”€â”€ Step 5ï¼šç¦»ç¾¤åˆ¤å®š (1 = çªç ´, 0 = æœªçªç ´) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        outlier = ((close > upper) | (close < lower)).astype(float)
        # å¸ƒæ—å¸¦æœ¬èº«ä¸º NaNï¼ˆçª—å£ä¸è¶³ï¼‰æ—¶ï¼Œoutlier ä¹Ÿç½®ä¸º NaN
        outlier[mb.isna()] = np.nan

        # â”€â”€ Step 6ï¼šæ»šåŠ¨é¢‘ç‡ï¼ˆlookback_window å¤©å†…å‡å€¼ = çªç ´æ¯”ä¾‹ï¼‰â”€â”€â”€â”€â”€â”€
        freq = outlier.rolling(
            window=lookback_window, min_periods=lookback_window
        ).mean()

        return freq
