# QuantAlpha Engine

> å·¥ä¸šçº§å› å­ç ”å‘ä¸å›æµ‹æ¡†æ¶ Â· ä»¿ç…§ WorldQuant å·¥ä½œæµ

**v2.0.0 æ–°ç‰¹æ€§** ğŸš€ æ–°å¢ 13 ä¸ªé¢„æ„å»ºç®—å­ï¼ˆæ—¶åº/é‡ä»·/åŠ¨é‡/æŠ€æœ¯æŒ‡æ ‡ï¼‰+ `fusion` å¤šå› å­èåˆæ¨¡å—ï¼ˆç»Ÿè®¡èåˆ / æœºå™¨å­¦ä¹ èåˆï¼‰ï¼Œæ”¯æŒä¸€é”®è¾“å‡º `BacktestResult`ã€‚

**v2.1.0 æ–°ç‰¹æ€§** ğŸ• `VectorEngine` æ”¯æŒ `start_date` / `end_date` å‚æ•°ï¼Œçµæ´»æ§åˆ¶å›æµ‹è¯„ä¼°æ—¶é—´åŒºé—´ï¼ˆä¸å½±å“å› å­å†å²çª—å£è®¡ç®—ï¼‰ã€‚

**V3 æ–°ç‰¹æ€§** ğŸ“Š æ–°å¢ 4 ä¸ªç¼©é‡ç¨³ä»·å› å­ç®—å­ï¼ˆ`VolSpike`ã€`PriceVarShrink`ã€`PriceMeanShrink`ã€`VolSpikeStablePrice`ï¼‰ã€‚

---

## ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [ç›®å½•ç»“æ„](#ç›®å½•ç»“æ„)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ä¾èµ–å®‰è£…](#ä¾èµ–å®‰è£…)
- [æ¨¡å—è¯¦è§£](#æ¨¡å—è¯¦è§£)
  - [MockDataGenerator â€” æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨](#1-mockdatagenerator--æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨)
  - [AlphaOps â€” ç®—å­åº“](#2-alphaops--ç®—å­åº“)ï¼ˆè¯¦ç»†æ–‡æ¡£è§ [FACTORS.md](./FACTORS.md)ï¼‰
  - [VectorEngine â€” å›æµ‹å¼•æ“](#3-vectorengine--å›æµ‹å¼•æ“)
  - [BacktestResult â€” å›æµ‹ç»“æœå¯¹è±¡](#4-backtestresult--å›æµ‹ç»“æœå¯¹è±¡)
  - [Performance â€” ç»©æ•ˆæŒ‡æ ‡è®¡ç®—](#5-performance--ç»©æ•ˆæŒ‡æ ‡è®¡ç®—)
  - [Report â€” å¯è§†åŒ–æŠ¥å‘Š](#6-report--å¯è§†åŒ–æŠ¥å‘Š)
  - [ğŸ†• Fusion â€” å¤šå› å­èåˆæ¡†æ¶ (v2)](#7-fusion--å¤šå› å­èåˆæ¡†æ¶-v2)
    - [Labeler â€” æ ‡ç­¾ç”Ÿæˆå™¨](#71-labeler--æ ‡ç­¾ç”Ÿæˆå™¨)
    - [StatisticalCombiner â€” ç»Ÿè®¡èåˆ](#72-statisticalcombiner--ç»Ÿè®¡èåˆ)
    - [MLCombiner â€” æœºå™¨å­¦ä¹ èåˆ](#73-mlcombiner--æœºå™¨å­¦ä¹ èåˆ)
- [æŒ‡æ ‡è¯´æ˜](#æŒ‡æ ‡è¯´æ˜)
- [ä½¿ç”¨çœŸå®æ•°æ®](#ä½¿ç”¨çœŸå®æ•°æ®)
- [å› å­æ„é€ ç¤ºä¾‹é›†](#å› å­æ„é€ ç¤ºä¾‹é›†)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## é¡¹ç›®ç®€ä»‹

QuantAlpha Engine æ˜¯ä¸€ä¸ªé¢å‘é‡åŒ–ç ”ç©¶å‘˜çš„**å› å­å›æµ‹ä¸€ç«™å¼æ¡†æ¶**ï¼Œæ ¸å¿ƒè®¾è®¡ç†å¿µä»¿ç…§ WorldQuant Alpha å¹³å°å·¥ä½œæµï¼š

- ç”¨**åµŒå¥—ç®—å­**æè¿°å› å­é€»è¾‘ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå¯è¯»æ€§å¼º
- **å…¨å‘é‡åŒ–**è®¡ç®—ï¼Œæ‰€æœ‰æ“ä½œåŸºäº pandas/numpy çŸ©é˜µè¿ç®—ï¼Œæ— æ˜¾å¼è‚¡ç¥¨å¾ªç¯
- ä¸¥æ ¼é˜²æ­¢**æœªæ¥å‡½æ•°ï¼ˆLook-ahead biasï¼‰**ï¼šT æ—¥å› å­å€¼ â†’ T+1 æ—¥å®é™…æ”¶ç›Š
- æ”¯æŒ**åœç‰Œã€æ¶¨è·Œåœ**è‡ªåŠ¨è¿‡æ»¤ï¼Œæ‰£é™¤çœŸå®äº¤æ˜“æˆæœ¬
- ä¸€è¡Œä»£ç  `.run()` å¾—åˆ°å®Œæ•´ç»©æ•ˆæŠ¥å‘Š

**æœ€ç®€ä½¿ç”¨æµç¨‹ï¼š**

```python
from quant_alpha_engine import MockDataGenerator
from quant_alpha_engine.ops import AlphaOps as op
from quant_alpha_engine.backtest import VectorEngine

# 1. å‡†å¤‡æ•°æ®
data = MockDataGenerator(n_stocks=100, n_days=504).generate()

# 2. ç”¨ç®—å­æ„é€ å› å­ï¼ˆæ”¯æŒä»»æ„åµŒå¥—ï¼‰
factor = op.Rank(op.Ts_Delta(data.close, 20))

# 3. ä¸€è¡Œè°ƒç”¨å›æµ‹
result = VectorEngine(
    factor=factor, close=data.close,
    is_suspended=data.is_suspended, is_limit=data.is_limit
).run()

# 4. æŸ¥çœ‹ç»“æœ
result.print_summary()   # æ§åˆ¶å°æ‰“å°æŒ‡æ ‡è¡¨æ ¼
result.plot()            # ç”Ÿæˆ 6 å­å›¾åˆ†ææŠ¥å‘Š
```

---

## ç›®å½•ç»“æ„

```
quant_alpha_engine/
â”œâ”€â”€ __init__.py                    # ç»Ÿä¸€å¯¼å‡ºï¼Œä¸€è¡Œå¯¼å…¥æ‰€æœ‰æ¨¡å—ï¼ˆv2.0.0ï¼‰
â”œâ”€â”€ data/
â”‚   â””â”€â”€ mock_generator.py          # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨
â”œâ”€â”€ ops/
â”‚   â””â”€â”€ alpha_ops.py               # ç®—å­åº“ï¼ˆv1: 13ä¸ª + v2: 13ä¸ªæ–°ç®—å­ + V3: 4ä¸ªç¼©é‡ç¨³ä»·ç®—å­ï¼‰
â”œâ”€â”€ backtest/
â”‚   â”œâ”€â”€ performance.py             # ç»©æ•ˆæŒ‡æ ‡è®¡ç®—
â”‚   â””â”€â”€ vector_engine.py           # çŸ©é˜µå¼å‡€å€¼å›æµ‹å¼•æ“
â”œâ”€â”€ fusion/                        # ğŸ†• v2.0 å¤šå› å­èåˆæ¡†æ¶
â”‚   â”œâ”€â”€ __init__.py                # å¯¼å‡º Labeler / StatisticalCombiner / MLCombiner
â”‚   â”œâ”€â”€ labeler.py                 # å‰å‘æ”¶ç›Šç‡æ ‡ç­¾ç”Ÿæˆå™¨
â”‚   â””â”€â”€ combiner.py                # ç»Ÿè®¡èåˆ + ML èåˆå®ç°
â””â”€â”€ visualization/
    â””â”€â”€ report.py                  # Matplotlib 6å­å›¾æŠ¥å‘Šï¼ˆæ”¯æŒä¸­æ–‡å­—ä½“è‡ªåŠ¨æ£€æµ‹ï¼‰

QuantAlpha_Demo.ipynb              # v1 Jupyter æ¼”ç¤º
QuantAlpha_Demo_V2.ipynb           # ğŸ†• v2 Jupyter æ¼”ç¤ºï¼ˆæ¨èå…¥å£ï¼Œå«èåˆæ¡†æ¶ï¼‰
QuantAlpha_Demo_V3.ipynb           # ğŸ†• V3 Jupyter æ¼”ç¤ºï¼ˆç¼©é‡ç¨³ä»·å› å­ï¼‰
demo.py                            # Python è„šæœ¬ç‰ˆæ¼”ç¤º
requirements.txt                   # ä¾èµ–åˆ—è¡¨
FACTORS.md                         # ğŸ“– å› å­ç®—å­å®Œæ•´å‚è€ƒæ–‡æ¡£ï¼ˆç‹¬ç«‹æ–‡ä»¶ï¼‰
```

---

## å¿«é€Ÿå¼€å§‹

**æ–¹å¼ä¸€ï¼ˆæ¨èï¼‰ï¼šç›´æ¥æ‰“å¼€ V2 Jupyter Notebook**

```bash
jupyter notebook QuantAlpha_Demo_V2.ipynb
```

åŒ…å«æ‰€æœ‰ v2.0 æ–°ç‰¹æ€§æ¼”ç¤ºï¼ˆ13 ä¸ªæ–°ç®—å­ + å¤šå› å­èåˆå®Œæ•´æµç¨‹ï¼‰ã€‚

**æ–¹å¼äºŒï¼šæ‰“å¼€ V3 Jupyter Notebookï¼ˆç¼©é‡ç¨³ä»·å› å­ï¼‰**

```bash
jupyter notebook QuantAlpha_Demo_V3.ipynb
```

**æ–¹å¼ä¸‰ï¼šæ‰“å¼€ V1 Jupyter Notebookï¼ˆåŸºç¡€åŠŸèƒ½ï¼‰**

```bash
jupyter notebook QuantAlpha_Demo.ipynb
```

**æ–¹å¼å››ï¼šè¿è¡Œ Python è„šæœ¬**

```bash
python demo.py
```

---

## ä¾èµ–å®‰è£…

```bash
pip install -r requirements.txt
```

| ä¾èµ–åŒ… | æœ€ä½ç‰ˆæœ¬ | ç”¨é€” |
|--------|----------|------|
| numpy | 1.24 | çŸ©é˜µè¿ç®— |
| pandas | 2.0 | DataFrame æ ¸å¿ƒæ“ä½œ |
| matplotlib | 3.7 | å›¾è¡¨ç»˜åˆ¶ |
| seaborn | 0.12 | çƒ­åŠ›å›¾ï¼ˆå¯é€‰ï¼Œæ— åˆ™é™çº§ï¼‰ |
| scipy | 1.10 | KDEã€æ­£æ€æ‹Ÿåˆã€OLSã€min-variance ä¼˜åŒ– |
| **scikit-learn** | **1.3** | **ğŸ†• MLCombiner æœºå™¨å­¦ä¹ èåˆï¼ˆå¿…é€‰ï¼‰** |

> **å¯é€‰ä¾èµ–ï¼š** è‹¥éœ€ä½¿ç”¨ `MLCombiner(model_type='xgboost')`ï¼Œé¢å¤–å®‰è£…ï¼š
> ```bash
> pip install xgboost>=1.7.0
> ```
> æœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§ä¸º `random_forest`ï¼Œä¸å½±å“å…¶ä»–åŠŸèƒ½ã€‚

> **ä¸­æ–‡å­—ä½“ï¼š** `result.plot()` ä¼šè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä¸­çš„ CJK å­—ä½“ï¼ˆå¾®è½¯é›…é»‘ã€SimHeiã€PingFang SC ç­‰ï¼‰ã€‚è‹¥æ£€æµ‹ä¸åˆ°ï¼Œä¸­æ–‡æ ‡ç­¾å°†æ˜¾ç¤ºä¸ºæ–¹å—ï¼Œä¸å½±å“æ•°å€¼å±•ç¤ºã€‚

---

## æ¨¡å—è¯¦è§£

---

### 1. MockDataGenerator â€” æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine import MockDataGenerator`

ç”¨äºåœ¨æ²¡æœ‰çœŸå®æ•°æ®æ—¶å¿«é€Ÿç”Ÿæˆæµ‹è¯•ç”¨å¸‚åœºæ•°æ®ã€‚åŸºäº**å‡ ä½•å¸ƒæœ—è¿åŠ¨ï¼ˆGBMï¼‰**å åŠ è¡Œä¸šå…±åŒå› å­ï¼Œæ¨¡æ‹ŸçœŸå®å¸‚åœºçš„è¡Œä¸šç›¸å…³ç»“æ„ã€åœç‰Œã€æ¶¨è·Œåœç­‰ç‰¹å¾ã€‚

#### æ„é€ å‚æ•°

```python
MockDataGenerator(
    n_stocks        = 100,          # è‚¡ç¥¨æ•°é‡
    n_days          = 504,          # äº¤æ˜“æ—¥æ€»æ•°ï¼ˆ504 â‰ˆ 2å¹´ï¼‰
    n_industries    = 10,           # è¡Œä¸šæ•°é‡
    start_date      = '2022-01-01', # èµ·å§‹æ—¥æœŸï¼ˆè·³è¿‡å‘¨æœ«ï¼‰
    seed            = 42,           # éšæœºç§å­ï¼ŒNone åˆ™æ¯æ¬¡ç»“æœä¸åŒ
    mu              = 0.08,         # æ‰€æœ‰è‚¡ç¥¨å¹´åŒ–æ¼‚ç§»ç‡çš„åŸºå‡†å€¼
    sigma           = 0.30,         # æ‰€æœ‰è‚¡ç¥¨å¹´åŒ–æ³¢åŠ¨ç‡çš„åŸºå‡†å€¼
    suspended_ratio = 0.04,         # æœ‰åœç‰Œå†å²çš„è‚¡ç¥¨å æ¯”ï¼ˆçº¦4%ï¼‰
    limit_pct       = 0.099,        # æ¶¨è·Œåœè§¦å‘é˜ˆå€¼ï¼ˆ|æ¶¨è·Œå¹…| >= 9.9%ï¼‰
)
```

#### å‚æ•°è¯¦è§£

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `n_stocks` | int | 100 | ç”Ÿæˆçš„è‚¡ç¥¨æ•°é‡ã€‚è¶Šå¤§ï¼Œæˆªé¢è¦†ç›–è¶Šå…¨ï¼Œä½†è¿ç®—ç•¥æ…¢ |
| `n_days` | int | 504 | äº¤æ˜“æ—¥æ•°ã€‚252 â‰ˆ 1å¹´ï¼Œ504 â‰ˆ 2å¹´ï¼Œ756 â‰ˆ 3å¹´ |
| `n_industries` | int | 10 | è¡Œä¸šæ•°é‡ã€‚æ¯ä¸ªè¡Œä¸šè‡³å°‘åˆ†é… 2 åªè‚¡ç¥¨ |
| `start_date` | str | `'2022-01-01'` | èµ·å§‹æ—¥æœŸã€‚è‡ªåŠ¨è·³è¿‡å‘¨æœ«ï¼Œä¸å¤„ç†èŠ‚å‡æ—¥ |
| `seed` | int \| None | 42 | å›ºå®šéšæœºç§å­ä¿è¯å¤ç°æ€§ï¼›è®¾ä¸º `None` æ¯æ¬¡éšæœº |
| `mu` | float | 0.08 | å¹´åŒ–æ¼‚ç§»ç‡åŸºå‡†ï¼ˆæ¯åªè‚¡ç¥¨åœ¨æ­¤åŸºç¡€ä¸Š Â±4% éšæœºåç§»ï¼‰|
| `sigma` | float | 0.30 | å¹´åŒ–æ³¢åŠ¨ç‡åŸºå‡†ï¼ˆæ¯åªè‚¡ç¥¨åœ¨æ­¤åŸºç¡€ä¸Š Â±10% éšæœºåç§»ï¼‰|
| `suspended_ratio` | float | 0.04 | å†å²åœç‰Œè‚¡ç¥¨å æ¯”ï¼Œæ¯åªåœç‰Œè‚¡æœ‰ 1~3 æ®µè¿ç»­åœç‰ŒæœŸ |
| `limit_pct` | float | 0.099 | æ¶¨è·Œåœåˆ¤æ–­é˜ˆå€¼ï¼ŒAè‚¡é€šå¸¸ä¸º 0.099ï¼ˆ9.9%ï¼‰|

#### æ–¹æ³•

```python
data = gen.generate()   # ç”Ÿæˆå¹¶è¿”å› MockData å¯¹è±¡
```

#### MockData å¯¹è±¡å­—æ®µ

`generate()` è¿”å›ä¸€ä¸ª `MockData` æ•°æ®ç±»ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å­—æ®µ | ç±»å‹ | å½¢çŠ¶ | è¯´æ˜ |
|------|------|------|------|
| `data.close` | DataFrame | T Ã— N | æ”¶ç›˜ä»·ï¼Œåœç‰ŒæœŸé—´ä¸º NaN |
| `data.open` | DataFrame | T Ã— N | å¼€ç›˜ä»· |
| `data.high` | DataFrame | T Ã— N | æœ€é«˜ä»· |
| `data.low` | DataFrame | T Ã— N | æœ€ä½ä»· |
| `data.volume` | DataFrame | T Ã— N | æˆäº¤é‡ï¼ˆæ‰‹ï¼Œ100è‚¡/æ‰‹ï¼‰ï¼Œä¸æ³¢åŠ¨æ­£ç›¸å…³ |
| `data.industry` | Series | N | è¡Œä¸šæ˜ å°„ï¼Œ`index=è‚¡ç¥¨ä»£ç , values=è¡Œä¸šåç§°` |
| `data.is_suspended` | DataFrame | T Ã— N | åœç‰ŒçŸ©é˜µï¼Œ`True` è¡¨ç¤ºå½“æ—¥åœç‰Œ |
| `data.is_limit` | DataFrame | T Ã— N | æ¶¨è·ŒåœçŸ©é˜µï¼Œ`True` è¡¨ç¤ºè§¦å‘æ¶¨åœæˆ–è·Œåœ |

æ‰€æœ‰ DataFrame çš„ `index` ä¸º `DatetimeIndex`ï¼ˆäº¤æ˜“æ—¥ï¼‰ï¼Œ`columns` ä¸ºè‚¡ç¥¨ä»£ç ï¼ˆå¦‚ `SH600000`ï¼‰ã€‚

#### ä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine import MockDataGenerator

# åŸºç¡€ç”¨æ³•
gen  = MockDataGenerator(n_stocks=100, n_days=504, seed=42)
data = gen.generate()

close    = data.close        # æ”¶ç›˜ä»·çŸ©é˜µ
volume   = data.volume       # æˆäº¤é‡çŸ©é˜µ
industry = data.industry     # è¡Œä¸šæ˜ å°„ Series
is_susp  = data.is_suspended # åœç‰ŒçŸ©é˜µ
is_limit = data.is_limit     # æ¶¨è·ŒåœçŸ©é˜µ

# æŸ¥çœ‹æ•°æ®
print(data.close.shape)                 # (504, 100)
print(data.close.index[:3])             # DatetimeIndex å‰3ä¸ªäº¤æ˜“æ—¥
print(data.industry.value_counts())     # å„è¡Œä¸šè‚¡ç¥¨æ•°é‡åˆ†å¸ƒ

# ç†Šå¸‚æ¨¡æ‹Ÿï¼ˆé«˜æ³¢åŠ¨ã€è´Ÿæ¼‚ç§»ï¼‰
bear_gen  = MockDataGenerator(mu=-0.05, sigma=0.45, seed=100)
bear_data = bear_gen.generate()
```

---

### 2. AlphaOps â€” ç®—å­åº“

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.ops import AlphaOps as op`

æ‰€æœ‰ç®—å­å‡ä¸º**é™æ€æ–¹æ³•**ï¼Œè¾“å…¥è¾“å‡ºå‡ä¸º `pd.DataFrame`ï¼ˆIndex=æ—¶é—´ï¼ŒColumns=è‚¡ç¥¨ï¼‰ï¼Œæ”¯æŒä»»æ„åµŒå¥—ç»„åˆã€‚

> ğŸ“– **å› å­ç®—å­å®Œæ•´å‚è€ƒæ–‡æ¡£ï¼ˆå‚æ•°è¯¦è§£ / å…¬å¼ / ç¤ºä¾‹ä»£ç ï¼‰è¯·è§ï¼š[FACTORS.md](./FACTORS.md)**

#### ç®—å­é€ŸæŸ¥

| ç±»åˆ« | ç®—å­ | ç‰ˆæœ¬ | ç®€ä»‹ |
|------|------|------|------|
| **æ—¶åºç±»** | `Ts_Sum` | v1 | æ»šåŠ¨æ±‚å’Œ |
| | `Ts_Mean` | v1 | æ»šåŠ¨å‡å€¼ |
| | `Ts_Max` | v1 | æ»šåŠ¨æœ€å¤§å€¼ |
| | `Ts_Min` | v1 | æ»šåŠ¨æœ€å°å€¼ |
| | `Ts_Std` | v1 | æ»šåŠ¨æ ‡å‡†å·® |
| | `Ts_Delta` | v1 | N æ—¥ä»·æ ¼å˜åŒ–é‡ |
| | `Ts_Delay` | v1 | N æ—¥å»¶è¿Ÿï¼ˆå¹³ç§»ï¼‰ |
| | `Ts_Rank` | v1 | æ—¶åºç™¾åˆ†ä½æ’å |
| | `Ts_Corr` | v1 | æ»šåŠ¨ Pearson ç›¸å…³ç³»æ•° |
| **æˆªé¢ç±»** | `Rank` | v1 | æˆªé¢ç™¾åˆ†æ¯”æ’å [0,1] |
| | `ZScore` | v1 | æˆªé¢ Z-Score æ ‡å‡†åŒ– |
| | `Scale` | v1 | æˆªé¢ç»å¯¹å€¼å½’ä¸€åŒ– |
| **ç‰¹æ®Šç±»** | `Decay_Linear` | v1 | çº¿æ€§è¡°å‡ç§»åŠ¨å¹³å‡ï¼ˆå¹³æ»‘ä¿¡å·ï¼‰ |
| | `Neutralize` | v1 | OLS è¡Œä¸šä¸­æ€§åŒ– |
| **æ—¶åºç»Ÿè®¡** ğŸ†• | `Ts_Skew` | v2 | æ»šåŠ¨ååº¦ï¼ˆåˆ†å¸ƒå°¾éƒ¨é£é™©ï¼‰ |
| | `Ts_Kurt` | v2 | æ»šåŠ¨å³°åº¦ï¼ˆæç«¯è·³è·ƒé£é™©ï¼‰ |
| | `Ts_Autocorr` | v2 | æ»šåŠ¨è‡ªç›¸å…³ç³»æ•°ï¼ˆè¶‹åŠ¿/åè½¬ï¼‰ |
| | `Ts_Hurst` | v2 | Hurst æŒ‡æ•°ï¼ˆé•¿è®°å¿†æ€§ï¼‰ |
| **é‡ä»·å› å­** ğŸ†• | `VWAP` | v2 | æˆäº¤é‡åŠ æƒå‡ä»· |
| | `VWAP_Bias` | v2 | VWAP ä¹–ç¦»ç‡ |
| | `PVDeviation` | v2 | é‡ä»·åç¦»åº¦ï¼ˆæ ‡å‡†åŒ–ï¼‰ |
| | `Amihud` | v2 | Amihud éæµåŠ¨æ€§æŒ‡æ ‡ |
| **åŠ¨é‡å› å­** ğŸ†• | `RiskAdjMomentum` | v2 | é£é™©è°ƒæ•´åŠ¨é‡ï¼ˆåŠ¨é‡å¤æ™®ï¼‰ |
| | `PricePathQuality` | v2 | ä»·æ ¼è·¯å¾„è´¨é‡ï¼ˆè¶‹åŠ¿çº¿æ€§åº¦ï¼‰ |
| | `RangeBreakout` | v2 | åŒºé—´çªç ´ä½ç½® [0,1] |
| **æŠ€æœ¯æŒ‡æ ‡** ğŸ†• | `RSI` | v2 | ç›¸å¯¹å¼ºå¼±æŒ‡æ•° [0,100] |
| | `KDJ` | v2 | KDJ æŒ‡æ ‡ K å€¼ |
| | `MACD` | v2 | MACD æŸ±çŠ¶å›¾ï¼ˆDIF-DEAï¼‰ |
| **ç¼©é‡ç¨³ä»·** ğŸ†• | `VolSpike` | V3 | æˆäº¤é‡å¼‚åŠ¨å¼ºåº¦ |
| | `PriceVarShrink` | V3 | ç¼©é‡ä»·æ ¼æ³¢åŠ¨æ”¶ç¼© |
| | `PriceMeanShrink` | V3 | ç¼©é‡ä»·æ ¼è¶‹åŠ¿å¹³å¦ |
| | `VolSpikeStablePrice` | V3 | ç¼©é‡ç¨³ä»·ç»¼åˆè¯„åˆ†ï¼ˆæ¨èï¼‰|

#### å¿«é€Ÿä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine.ops import AlphaOps as op

# æ—¶åº + æˆªé¢ç»„åˆï¼ˆæœ€å¸¸è§æ¨¡å¼ï¼‰
factor = op.Rank(op.Ts_Delta(data.close, 5))

# é‡ä»·èƒŒç¦» + è¡Œä¸šä¸­æ€§åŒ–
factor_vp = op.Neutralize(
    op.Rank(-op.Ts_Corr(data.volume, data.close, 10)),
    data.industry
)

# V3 ç¼©é‡ç¨³ä»·æ ¸å¿ƒå› å­
factor_vss = op.Rank(
    op.VolSpikeStablePrice(data.close, data.volume,
                           price_window=10, vol_window=20)
)
```

---

### 3. VectorEngine â€” å›æµ‹å¼•æ“

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.backtest import VectorEngine`

çŸ©é˜µå¼å‡€å€¼å›æµ‹å¼•æ“ï¼Œæ¥æ”¶å› å­çŸ©é˜µå’Œè¡Œæƒ…æ•°æ®ï¼Œè¾“å‡ºå®Œæ•´å›æµ‹ç»“æœã€‚

#### æ„é€ å‚æ•°

```python
VectorEngine(
    factor          = factor_df,     # å¿…å¡«ï¼šå› å­çŸ©é˜µ
    close           = close_df,      # å¿…å¡«ï¼šæ”¶ç›˜ä»·çŸ©é˜µ
    is_suspended    = susp_df,       # å¿…å¡«ï¼šåœç‰ŒçŸ©é˜µ
    is_limit        = limit_df,      # å¿…å¡«ï¼šæ¶¨è·ŒåœçŸ©é˜µ
    rebalance_freq  = 1,             # è°ƒä»“é¢‘ç‡ï¼ˆå¤©æ•°ï¼‰
    top_n           = 50,            # æŒä»“è‚¡ç¥¨æ•°
    weight_method   = 'equal',       # æƒé‡æ–¹å¼
    cost_rate       = 0.0015,        # å•è¾¹äº¤æ˜“æˆæœ¬
    initial_capital = 1_000_000.0,   # åˆå§‹èµ„é‡‘ï¼ˆä»…å±•ç¤ºç”¨ï¼‰
    # â”€â”€ å†…ç½®é¢„å¤„ç†å‚æ•°ï¼ˆv2.0 æ–°å¢ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    delay           = 1,             # å› å­å»¶è¿Ÿå¤©æ•°ï¼ˆ0=ä¸å»¶è¿Ÿï¼‰
    decay           = 0,             # çº¿æ€§è¡°å‡çª—å£ï¼ˆ0=ä¸è¡°å‡ï¼‰
    industry        = None,          # è¡Œä¸šæ˜ å°„ï¼ŒNone=è·³è¿‡ä¸­æ€§åŒ–
    # â”€â”€ å›æµ‹æ—¶é—´èŒƒå›´æ§åˆ¶ï¼ˆv2.1 æ–°å¢ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    start_date      = None,          # å›æµ‹å¼€å§‹æ—¥æœŸï¼Œå¦‚ '2022-06-01'ï¼ŒNone=ä¸é™åˆ¶
    end_date        = None,          # å›æµ‹ç»“æŸæ—¥æœŸï¼Œå¦‚ '2023-12-31'ï¼ŒNone=ä¸é™åˆ¶
)
```

#### å‚æ•°è¯¦è§£

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `factor` | DataFrame | â€” | **å¿…å¡«**ã€‚å› å­çŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œå€¼è¶Šå¤§ä»£è¡¨è¯¥è‚¡ç¥¨è¶Šåº”è¯¥è¢«ä¹°å…¥ |
| `close` | DataFrame | â€” | **å¿…å¡«**ã€‚æ”¶ç›˜ä»·çŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œç”¨äºè®¡ç®—æ¯æ—¥æ”¶ç›Šç‡ |
| `is_suspended` | DataFrame | â€” | **å¿…å¡«**ã€‚åœç‰ŒçŸ©é˜µï¼ˆT Ã— Nï¼Œboolï¼‰ã€‚åœç‰Œè‚¡ç¥¨å½“æ—¥æƒé‡è‡ªåŠ¨ç½®é›¶ |
| `is_limit` | DataFrame | â€” | **å¿…å¡«**ã€‚æ¶¨è·ŒåœçŸ©é˜µï¼ˆT Ã— Nï¼Œboolï¼‰ã€‚æ¶¨è·Œåœè‚¡ç¥¨å½“æ—¥æƒé‡è‡ªåŠ¨ç½®é›¶ï¼ˆæ— æ³•æˆäº¤ï¼‰|
| `rebalance_freq` | int | 1 | è°ƒä»“é¢‘ç‡ã€‚`1`=æ¯æ—¥è°ƒä»“ï¼Œ`5`=æ¯å‘¨è°ƒä»“ï¼Œ`21`â‰ˆæ¯æœˆè°ƒä»“ã€‚éè°ƒä»“æ—¥æŒä»“ä¸å˜ |
| `top_n` | int | 50 | æ¯æ¬¡è°ƒä»“æ—¶ï¼ŒæŒ‰å› å­å€¼æ’åå–å‰ N åªè‚¡ç¥¨æŒä»“ã€‚è‹¥å¯äº¤æ˜“è‚¡ç¥¨ä¸è¶³ N åªï¼Œåˆ™å–å…¨éƒ¨å¯äº¤æ˜“è‚¡ç¥¨ |
| `weight_method` | str | `'equal'` | æŒä»“æƒé‡è®¡ç®—æ–¹å¼ï¼Œè§ä¸‹æ–¹è¯´æ˜ |
| `cost_rate` | float | 0.0015 | å•è¾¹äº¤æ˜“æˆæœ¬ç‡ï¼ˆæ‰‹ç»­è´¹ + æ»‘ç‚¹ï¼‰ã€‚æ¯æ¬¡æ¢æ‰‹çš„ä¹°å…¥æˆ–å–å‡ºå‡æŒ‰æ­¤æ¯”ç‡æ‰£è´¹ |
| `initial_capital` | float | 1,000,000 | åˆå§‹èµ„é‡‘ï¼Œä»…ç”¨äºç»“æœå±•ç¤ºï¼Œä¸å½±å“æ”¶ç›Šç‡è®¡ç®— |
| `delay` | int | **1** | å› å­å»¶è¿Ÿå¤©æ•°ï¼ˆ`Ts_Delay`ï¼‰ã€‚`1` è¡¨ç¤º T æ—¥å› å­åœ¨ T+1 æ—¥åç”Ÿæ•ˆï¼Œé˜²æ­¢æ—¥å†…ä½¿ç”¨æœªæ¥æ•°æ®ï¼›`0` å…³é—­å»¶è¿Ÿ |
| `decay` | int | 0 | çº¿æ€§è¡°å‡çª—å£ï¼ˆ`Decay_Linear`ï¼‰ã€‚å¯¹å› å­åšçº¿æ€§åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå¹³æ»‘ä¿¡å·ã€é™ä½æ¢æ‰‹ç‡ï¼›`0` è·³è¿‡ |
| `industry` | Series/DataFrame/None | None | è¡Œä¸šæ˜ å°„ï¼ˆè‚¡ç¥¨ â†’ è¡Œä¸šæ ‡ç­¾ï¼‰ï¼Œä¼ å…¥åè‡ªåŠ¨å¯¹å› å­åš OLS è¡Œä¸šä¸­æ€§åŒ–ï¼ˆ`Neutralize`ï¼‰ï¼›`None` è·³è¿‡ |
| `start_date` | str/None | None | å›æµ‹è¯„ä¼°èµ·å§‹æ—¥æœŸï¼ˆå¦‚ `'2022-06-01'`ï¼‰ã€‚ä¸å½±å“å› å­å†å²çª—å£è®¡ç®—ï¼Œä»…æˆªå–å‡€å€¼æ›²çº¿åŒºé—´ï¼›`None` ä¸é™åˆ¶ |
| `end_date` | str/None | None | å›æµ‹è¯„ä¼°ç»“æŸæ—¥æœŸï¼ˆå¦‚ `'2023-12-31'`ï¼‰ã€‚ä¸å½±å“å› å­å†å²çª—å£è®¡ç®—ï¼Œä»…æˆªå–å‡€å€¼æ›²çº¿åŒºé—´ï¼›`None` ä¸é™åˆ¶ |

PLACEHOLDER_SPLIT_MARKER

ç­‰ä»·äº `df.shift(period)`ã€‚å¸¸ç”¨äºæ„é€ "Nå¤©å‰çš„å€¼"å‚ä¸è®¡ç®—ã€‚

```python
result = op.Ts_Delay(df, period)
```

```python
# ä¸Šå‘¨åŒä¸€å¤©çš„ä»·æ ¼
close_5d_ago = op.Ts_Delay(data.close, 5)

# æ„é€ ç›¸å¯¹å¼ºåº¦ï¼šå½“å‰ä»·æ ¼ / 20å¤©å‰ä»·æ ¼
rs = data.close / op.Ts_Delay(data.close, 20)
```

---

##### `Ts_Rank(df, window)` â€” æ—¶åºçª—å£å†…ç™¾åˆ†æ¯”æ’å

å½“å‰å€¼åœ¨è¿‡å» `window` ä¸ªè§‚æµ‹å€¼ä¸­çš„**åˆ†ä½æ•°æ’å**ï¼ˆè¶Šé«˜è¡¨ç¤ºå½“å‰å¤„äºå†å²é«˜ä½ï¼‰ã€‚

```python
result = op.Ts_Rank(df, window)   # è¿”å›å€¼åŸŸ [0, 1]
```

| å‚æ•° | è¯´æ˜ |
|------|------|
| `window` | å†å²å›çœ‹çª—å£ï¼ˆå¤©æ•°ï¼‰ |

**ä¸æˆªé¢ `Rank` çš„åŒºåˆ«ï¼š**
- `Ts_Rank`ï¼šå•åªè‚¡ç¥¨åœ¨è‡ªèº«å†å²ä¸­çš„æ’åï¼ˆæ—¶é—´ç»´åº¦ï¼‰
- `Rank`ï¼šæ‰€æœ‰è‚¡ç¥¨åœ¨åŒä¸€æˆªé¢æ—¥æœŸä¸­çš„æ’åï¼ˆæˆªé¢ç»´åº¦ï¼‰

```python
# å½“å‰æˆäº¤é‡åœ¨è¿‘20å¤©ä¸­çš„å†å²åˆ†ä½ï¼ˆ>0.8 è¡¨ç¤ºé‡èƒ½å¤„äºå†å²é«˜ä½ï¼‰
vol_rank = op.Ts_Rank(data.volume, 20)

# ä»·æ ¼å¤„äºå†å²é«˜ä½ + æˆäº¤é‡ä¹Ÿå¤„äºé«˜ä½ â†’ æ”¾é‡åˆ›æ–°é«˜
breakout = op.Rank(op.Ts_Rank(data.close, 60) + op.Ts_Rank(data.volume, 20))
```

> âš ï¸ `Ts_Rank` å†…éƒ¨ä½¿ç”¨ `rolling.apply`ï¼Œå¯¹è¶…å¤§çŸ©é˜µï¼ˆ>500åªè‚¡ç¥¨ï¼‰é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®® `window` ä¸è¶…è¿‡ 60ã€‚

---

##### `Ts_Corr(df1, df2, window)` â€” æ»šåŠ¨ç›¸å…³ç³»æ•°

è®¡ç®—ä¸¤ä¸ªåŒå½¢çŠ¶ DataFrame åœ¨æ»šåŠ¨çª—å£å†…çš„é€åˆ— **Pearson ç›¸å…³ç³»æ•°**ã€‚

```python
result = op.Ts_Corr(df1, df2, window)   # è¿”å›å€¼åŸŸ [-1, 1]
```

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `df1` | DataFrame | ç¬¬ä¸€ä¸ªè¾“å…¥çŸ©é˜µ |
| `df2` | DataFrame | ç¬¬äºŒä¸ªè¾“å…¥çŸ©é˜µï¼Œé¡»ä¸ df1 å½¢çŠ¶ç›¸åŒ |
| `window` | int | æ»šåŠ¨çª—å£å¤§å° |

> ä¸¤ä¸ª DataFrame é¡»æœ‰ç›¸åŒçš„ index å’Œ columnsï¼›è‹¥ä¸ä¸€è‡´ï¼Œæ¡†æ¶è‡ªåŠ¨å–äº¤é›†å¯¹é½ã€‚

```python
# è¿‡å»10å¤©ï¼Œæˆäº¤é‡ä¸ä»·æ ¼çš„ç›¸å…³ç³»æ•°
# æ­£å€¼ï¼šé‡ä»·åŒå‘ï¼ˆæ”¾é‡ä¸Šæ¶¨ï¼‰ï¼›è´Ÿå€¼ï¼šé‡ä»·èƒŒç¦»ï¼ˆç¼©é‡ä¸Šæ¶¨ï¼‰
vol_price_corr = op.Ts_Corr(data.volume, data.close, 10)

# é‡ä»·èƒŒç¦»å› å­ï¼šè´Ÿç›¸å…³ï¼ˆç¼©é‡ä¸Šæ¶¨ï¼‰æ’åé å‰
factor = op.Rank(-vol_price_corr)

# è¡Œä¸šä¸­æ€§åŒ–åä½¿ç”¨
factor_neut = op.Neutralize(factor, data.industry)
```

---

#### æˆªé¢ç±» (Cross-Sectional)

æˆªé¢ç®—å­åœ¨**åŒä¸€æ—¥æœŸçš„æ‰€æœ‰è‚¡ç¥¨**ä¸Šæ“ä½œï¼ˆæ¨ªå‘æ“ä½œï¼‰ï¼Œé€è¡Œç‹¬ç«‹è®¡ç®—ã€‚

---

##### `Rank(df)` â€” æˆªé¢ç™¾åˆ†æ¯”æ’å

å¯¹æ¯ä¸ªæ—¥æœŸæˆªé¢ï¼Œå°†æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼åšç™¾åˆ†æ¯”æ’åã€‚

```python
result = op.Rank(df)   # è¿”å›å€¼åŸŸ [0, 1]
```

- å€¼è¶Šå¤§ â†’ è¯¥è‚¡ç¥¨åœ¨å½“æ—¥å› å­å€¼ä¸­æ’åè¶Šé å‰
- NaN å€¼ä¸å‚ä¸æ’åï¼Œå¯¹åº”ä½ç½®ä»è¿”å› NaN
- é€‚åˆæ¶ˆé™¤å› å­é‡çº²ï¼Œç»Ÿä¸€åŒ–ä¸åŒå› å­çš„å°ºåº¦

```python
# æœ€å¸¸ç”¨çš„ç”¨æ³•ï¼šå¯¹åŸå§‹å› å­åšæˆªé¢æ’åï¼Œå»é™¤æå€¼å½±å“
raw_factor = op.Ts_Delta(data.close, 20)
factor     = op.Rank(raw_factor)        # å€¼å‹ç¼©åˆ° [0,1]ï¼Œå‡åŒ€åˆ†å¸ƒ

# åµŒå¥—ï¼šå…ˆæ—¶åºå¤„ç†ï¼Œå†æˆªé¢æ’å
factor = op.Rank(op.Ts_Mean(data.volume, 5) / op.Ts_Mean(data.volume, 20))
```

---

##### `ZScore(df)` â€” æˆªé¢ Z-Score æ ‡å‡†åŒ–

å¯¹æ¯ä¸ªæ—¥æœŸæˆªé¢ï¼Œåšæ ‡å‡†åŒ–ï¼š`(value - æˆªé¢å‡å€¼) / æˆªé¢æ ‡å‡†å·®`ã€‚

```python
result = op.ZScore(df)   # æˆªé¢å‡å€¼â‰ˆ0ï¼Œæ ‡å‡†å·®â‰ˆ1
```

- é€‚åˆéœ€è¦ä¿ç•™å› å­çº¿æ€§ç»“æ„ï¼ˆè€Œä¸æ˜¯æ’åä¿¡æ¯ï¼‰çš„åœºæ™¯
- å¯¹æç«¯å€¼æ•æ„Ÿï¼ˆä¸ `Rank` ä¸åŒï¼Œæå€¼ä¼šè¢«ä¿ç•™ï¼‰
- è‡³å°‘éœ€è¦ 2 ä¸ªé NaN å€¼ï¼Œå¦åˆ™è¿”å› NaN

```python
# æ ‡å‡†åŒ–åçš„æˆäº¤é‡åç¦»åº¦
vol_zscore = op.ZScore(data.volume)

# ä¸ Rank çš„åŒºåˆ«
factor_rank   = op.Rank(raw_factor)    # å‡åŒ€åˆ†å¸ƒï¼Œå¯¹æå€¼ä¸æ•æ„Ÿ
factor_zscore = op.ZScore(raw_factor)  # æ­£æ€åˆ†å¸ƒï¼Œä¿ç•™æå€¼ä¿¡æ¯
```

---

##### `Scale(df, a=1.0)` â€” æˆªé¢ç»å¯¹å€¼ç¼©æ”¾

å°†æ¯ä¸ªæˆªé¢çš„å› å­ç»å¯¹å€¼ä¹‹å’Œç¼©æ”¾è‡³ `a`ï¼š`sum(|factor_i|) = a`ã€‚

```python
result = op.Scale(df, a=1.0)
```

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `a` | 1.0 | ç›®æ ‡ç»å¯¹å€¼ä¹‹å’Œ |

**å…¸å‹ç”¨é€”ï¼š** å°†å› å­å€¼ç›´æ¥ç”¨ä½œæŒä»“æƒé‡ï¼ˆå¤šç©ºç»„åˆï¼‰æ—¶ï¼Œ`Scale(factor, 1)` ç¡®ä¿æ€»æƒé‡ç»å¯¹å€¼ä¸º 1ï¼Œå³å¤šå¤´ + ç©ºå¤´æ€»æ æ†ä¸º 1ã€‚

```python
# å°†å› å­ç›´æ¥è½¬ä¸ºå¤šç©ºæƒé‡ï¼ˆæ­£å€¼åšå¤šï¼Œè´Ÿå€¼åšç©ºï¼Œæ€»æ æ†=1ï¼‰
weights_factor = op.Scale(op.ZScore(raw_factor), a=1.0)

# æ€»ç»å¯¹æƒé‡éªŒè¯
print(weights_factor.abs().sum(axis=1).mean())  # â‰ˆ 1.0
```

---

#### ç‰¹æ®Šç±» (Special)

---

##### `Decay_Linear(df, d)` â€” çº¿æ€§è¡°å‡åŠ æƒç§»åŠ¨å¹³å‡

WorldQuant å¹³å°çš„æ ¸å¿ƒç®—å­ä¹‹ä¸€ã€‚å¯¹è¿‡å» `d` å¤©æ•°æ®åšçº¿æ€§åŠ æƒå¹³å‡ï¼Œ**è¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šå¤§**ã€‚

```python
result = op.Decay_Linear(df, d)
```

| å‚æ•° | è¯´æ˜ |
|------|------|
| `d` | è¡°å‡çª—å£å¤§å°ï¼ˆå¤©æ•°ï¼‰ |

**æƒé‡åˆ†é…ï¼š**
- d å¤©å‰çš„æ•°æ®æƒé‡ä¸º **1**ï¼ˆæœ€å°ï¼‰
- d-1 å¤©å‰æƒé‡ä¸º **2**
- ...
- 1 å¤©å‰æƒé‡ä¸º **d-1**
- å½“å¤©æƒé‡ä¸º **d**ï¼ˆæœ€å¤§ï¼‰
- æ‰€æœ‰æƒé‡å½’ä¸€åŒ–åæ±‚åŠ æƒå‡å€¼

**ä¸æ™®é€šç§»åŠ¨å¹³å‡çš„åŒºåˆ«ï¼š**
- `Ts_Mean(df, d)`ï¼šç­‰æƒå‡å€¼ï¼Œæ¯å¤©æƒé‡ = 1/d
- `Decay_Linear(df, d)`ï¼šçº¿æ€§åŠ æƒï¼Œæœ€æ–°æ•°æ®æƒé‡æœ€é«˜ï¼Œä¿¡å·è¡°å‡æ›´å¹³æ»‘

```python
# å¯¹åŠ¨é‡ä¿¡å·åšçº¿æ€§è¡°å‡å¹³æ»‘ï¼ˆå‡å°‘ä¿¡å·æŠ–åŠ¨ï¼‰
raw_signal = op.Rank(op.Ts_Delta(data.close, 5))
smooth_signal = op.Decay_Linear(raw_signal, d=5)

# åµŒå¥—ï¼šå…ˆæˆªé¢æ’åï¼Œå†çº¿æ€§è¡°å‡ï¼Œå†é‡æ–°æ’å
factor = op.Rank(
    op.Decay_Linear(
        op.Rank(op.Ts_Delta(data.close, 10)),
        d=5
    )
)
```

---

##### `Neutralize(df, group_data)` â€” è¡Œä¸šä¸­æ€§åŒ–

é€šè¿‡ OLS æ®‹å·®æ³•ï¼Œ**å‰”é™¤å› å­ä¸­çš„è¡Œä¸šå…±æ€§æˆåˆ†**ï¼Œä¿ç•™è‚¡ç¥¨çš„çº¯ä¸ªè‚¡ç‰¹è´¨ä¿¡å·ã€‚

```python
result = op.Neutralize(df, group_data)
```

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `df` | DataFrame | éœ€è¦ä¸­æ€§åŒ–çš„å› å­çŸ©é˜µ (T Ã— N) |
| `group_data` | Series æˆ– DataFrame | è¡Œä¸šæ˜ å°„ã€‚`Series(index=è‚¡ç¥¨ä»£ç , values=è¡Œä¸šå)`ï¼ˆæ¨èï¼‰|

**åŸç†ï¼š** å¯¹æ¯ä¸ªæ—¶é—´æˆªé¢ï¼Œä»¥è¡Œä¸šå“‘å˜é‡çŸ©é˜µä¸ºè‡ªå˜é‡åš OLS å›å½’ï¼Œå–**æ®‹å·®**ä½œä¸ºä¸­æ€§åŒ–åçš„å› å­å€¼ã€‚æ®‹å·®ä¸­ä¸å«è¡Œä¸šæ•´ä½“çš„æ¶¨è·Œä¿¡æ¯ï¼Œåªä¿ç•™ä¸ªè‚¡ç›¸å¯¹è¡Œä¸šçš„è¶…é¢è¡¨ç°ã€‚

**é€‚ç”¨åœºæ™¯ï¼š**
- é¿å…å› å­å¤§é‡æš´éœ²äºæŸä¸€è¡Œä¸šï¼ˆå¦‚ç§‘æŠ€è‚¡ã€é“¶è¡Œè‚¡ï¼‰å¯¼è‡´çš„è¡Œä¸š Beta
- ä½¿å› å­åœ¨è¡Œä¸šå†…éƒ¨åšæ¨ªå‘æ¯”è¾ƒï¼Œè€Œéè·¨è¡Œä¸šæ¯”è¾ƒ

```python
# é‡ä»·ç›¸å…³å› å­ï¼Œè¡Œä¸šä¸­æ€§åŒ–
raw_corr = op.Ts_Corr(data.volume, data.close, window=10)
factor_raw  = op.Rank(-raw_corr)

# ä¸­æ€§åŒ–ï¼šæ¶ˆé™¤è¡Œä¸šå…±æ€§
factor_neut = op.Neutralize(factor_raw, data.industry)

# ä¸­æ€§åŒ–åçš„å‡å€¼æ¥è¿‘ 0ï¼ˆè¡Œä¸šå†…å¤šç©ºå¹³è¡¡ï¼‰
print(factor_neut.mean(axis=1).mean())   # â‰ˆ 0
```

> **æ³¨æ„ï¼š** `Neutralize` å†…éƒ¨å«é€è¡Œå¾ªç¯ï¼ˆæ¯æ—¥åšä¸€æ¬¡ OLSï¼‰ï¼Œå¯¹è¶…é•¿æ—¶é—´åºåˆ—ï¼ˆ>2000å¤©ï¼‰é€Ÿåº¦è¾ƒæ…¢ã€‚

---

### ğŸ†• æ—¶åºç»Ÿè®¡ç®—å­ (v2)

v2.0 æ–°å¢ 4 ä¸ªæ—¶åºç»Ÿè®¡ç®—å­ï¼Œç”¨äºæ•æ‰ä»·æ ¼/æ”¶ç›Šåºåˆ—çš„**é«˜é˜¶çŸ©**å’Œ**è‡ªç›¸å…³ç»“æ„**ã€‚

---

##### `Ts_Skew(df, window)` â€” æ»šåŠ¨ååº¦

```python
result = op.Ts_Skew(df, window)
```

è®¡ç®—è¿‡å» `window` å¤©çš„ä¸‰é˜¶æ ‡å‡†çŸ©ï¼ˆååº¦ï¼‰ã€‚æ­£ååº¦è¡¨ç¤ºå³å°¾åšï¼ˆå¶æœ‰å¤§æ¶¨ï¼‰ï¼Œè´Ÿååº¦è¡¨ç¤ºå·¦å°¾åšï¼ˆå¶æœ‰å¤§è·Œï¼‰ã€‚

| å‚æ•° | è¯´æ˜ |
|------|------|
| `window` | æ»šåŠ¨çª—å£å¤§å°ï¼ˆå¤©æ•°ï¼‰ï¼Œå»ºè®® â‰¥ 10 |

**è¿”å›å€¼åŸŸï¼š** (-âˆ, +âˆ)ï¼Œå…¸å‹å€¼åœ¨ [-3, 3] ä¹‹é—´ã€‚

```python
daily_ret = data.close.pct_change()
# æ»šåŠ¨ååº¦ï¼ˆè´Ÿååº¦ â†’ å°¾éƒ¨é£é™©å¤§ â†’ ä½é…ï¼‰
factor_skew = op.Rank(-op.Ts_Skew(daily_ret, 20))
```

---

##### `Ts_Kurt(df, window)` â€” æ»šåŠ¨å³°åº¦ï¼ˆè¶…é¢ï¼‰

```python
result = op.Ts_Kurt(df, window)
```

è®¡ç®—è¿‡å» `window` å¤©çš„è¶…é¢å³°åº¦ï¼ˆå››é˜¶çŸ© - 3ï¼‰ã€‚æ­£å€¼è¡¨ç¤ºå°–å³°åšå°¾ï¼Œè´Ÿå€¼è¡¨ç¤ºæ‰å¹³è–„å°¾ã€‚

```python
# é«˜å³°åº¦æ„å‘³ç€æç«¯æ”¶ç›Šå‡ºç°é¢‘ç‡æ›´é«˜ï¼ˆæ›´å±é™©ï¼‰
factor_kurt = op.Rank(-op.Ts_Kurt(daily_ret, 20))
```

---

##### `Ts_Autocorr(df, lag, window)` â€” æ»šåŠ¨è‡ªç›¸å…³ç³»æ•°

```python
result = op.Ts_Autocorr(df, lag, window)   # è¿”å›å€¼åŸŸ [-1, 1]
```

è®¡ç®—å½“å‰å€¼ä¸ `lag` å¤©å‰çš„å€¼åœ¨ `window` çª—å£å†…çš„æ»šåŠ¨ Pearson ç›¸å…³ç³»æ•°ã€‚

| å‚æ•° | è¯´æ˜ |
|------|------|
| `lag` | æ»åé˜¶æ•° |
| `window` | æ»šåŠ¨çª—å£å¤§å° |

```python
# 1é˜¶è‡ªç›¸å…³ç³»æ•°ï¼ˆ>0 è¶‹åŠ¿ï¼Œ<0 åè½¬ï¼‰
autocorr1 = op.Ts_Autocorr(daily_ret, lag=1, window=20)
# ç”¨è‡ªç›¸å…³åšå‡å€¼å›å½’ä¿¡å·ï¼šè´Ÿè‡ªç›¸å…³ â†’ åè½¬æœºä¼š
factor_mean_rev = op.Rank(-autocorr1)
```

---

##### `Ts_Hurst(df, window)` â€” èµ«æ–¯ç‰¹æŒ‡æ•°ï¼ˆR/S åˆ†æï¼‰

```python
result = op.Ts_Hurst(df, window)   # è¿”å›å€¼åŸŸçº¦ [0, 1]
```

é€šè¿‡ R/S åˆ†æï¼ˆæå·®/æ ‡å‡†å·®ï¼‰ä¼°è®¡èµ«æ–¯ç‰¹æŒ‡æ•°ï¼š
- **H > 0.5**ï¼šè¶‹åŠ¿æ€§ï¼ˆæŒç»­æ€§ï¼ŒåŠ¨é‡ä¿¡å·æœ‰æ•ˆï¼‰
- **H < 0.5**ï¼šå‡å€¼å›å½’ï¼ˆåæŒç»­æ€§ï¼Œåè½¬ä¿¡å·æœ‰æ•ˆï¼‰
- **H â‰ˆ 0.5**ï¼šéšæœºæ¸¸èµ°

```python
hurst = op.Ts_Hurst(data.close.pct_change(), window=30)
# è¶‹åŠ¿è‚¡ï¼ˆH é«˜ï¼‰åšåŠ¨é‡ï¼Œå‡å€¼å›å½’è‚¡ï¼ˆH ä½ï¼‰åšåè½¬
```

> âš ï¸ `Ts_Hurst` ä½¿ç”¨ `rolling.apply`ï¼Œå¯¹å¤§çŸ©é˜µè¾ƒæ…¢ï¼Œå»ºè®® `window` åœ¨ 20~60 ä¹‹é—´ã€‚

---

### ğŸ†• é‡ä»·å› å­ç®—å­ (v2)

v2.0 æ–°å¢ 3 ä¸ªé‡ä»·èåˆç®—å­ï¼Œæ•æ‰**æˆäº¤é‡ä¸ä»·æ ¼**çš„å¾®è§‚ç»“æ„å…³ç³»ã€‚

---

##### `VWAP(close, volume, window)` â€” æˆäº¤é‡åŠ æƒå‡ä»·

```python
result = op.VWAP(close, volume, window)
```

è®¡ç®—è¿‡å» `window` å¤©çš„æˆäº¤é‡åŠ æƒå‡ä»·ï¼š`Î£(P Ã— V) / Î£V`ã€‚

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `close` | DataFrame | æ”¶ç›˜ä»·çŸ©é˜µ |
| `volume` | DataFrame | æˆäº¤é‡çŸ©é˜µ |
| `window` | int | æ»šåŠ¨çª—å£å¤§å° |

**è¿”å›ï¼š** ä¸ `close` åŒå½¢çŠ¶ï¼Œå•ä½ä¸ä»·æ ¼ç›¸åŒã€‚

```python
vwap = op.VWAP(data.close, data.volume, window=10)
# ä»·æ ¼é«˜äº VWAP â†’ å¼ºåŠ¿ï¼›ä½äº VWAP â†’ å¼±åŠ¿
price_vs_vwap = op.Rank(data.close / vwap - 1)
```

---

##### `VWAP_Bias(close, volume, window)` â€” VWAP ä¹–ç¦»ç‡

```python
result = op.VWAP_Bias(close, volume, window)
```

è¡¡é‡å½“å‰æ”¶ç›˜ä»·ç›¸å¯¹æ»šåŠ¨ VWAP çš„**ç™¾åˆ†æ¯”åç¦»**ï¼š`Close / VWAP(window) - 1`

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `close` | DataFrame | æ”¶ç›˜ä»·çŸ©é˜µ |
| `volume` | DataFrame | æˆäº¤é‡çŸ©é˜µ |
| `window` | int | è®¡ç®— VWAP çš„æ»šåŠ¨çª—å£å¤§å° |

**è¿”å›å€¼åŸŸï¼š** æ— ç•Œï¼Œå…¸å‹èŒƒå›´ [-0.1, 0.1]ï¼ˆå³ Â±10%ï¼‰ã€‚

- **> 0**ï¼šä»·æ ¼é«˜äº VWAPï¼Œå¤šå¤´å ä¼˜ï¼ˆå¯èƒ½ç›¸å¯¹è¶…ä¹°ï¼‰
- **< 0**ï¼šä»·æ ¼ä½äº VWAPï¼Œç©ºå¤´å ä¼˜ï¼ˆæ½œåœ¨å‡å€¼å›å½’æœºä¼šï¼‰

> ä¸ `PVDeviation` çš„åŒºåˆ«ï¼š`VWAP_Bias` ä¿ç•™ä»·æ ¼é‡çº²ï¼ˆç™¾åˆ†æ¯”åç¦»ï¼‰ï¼Œ`PVDeviation` ç”¨ä»·æ ¼æ ‡å‡†å·®æ ‡å‡†åŒ–ï¼ˆæ— é‡çº²ï¼‰ï¼Œä¸¤è€…ä¿¡æ¯äº’è¡¥ã€‚

```python
bias = op.VWAP_Bias(data.close, data.volume, window=10)
# å‡å€¼å›å½’ä¿¡å·ï¼šå¤§å¹…ä½äº VWAP â†’ çŸ­æœŸåå¼¹
factor_bias_rev = op.Rank(-bias)
# è¶‹åŠ¿ä¿¡å·ï¼šæŒç»­æ­£ä¹–ç¦» â†’ åŠ¨é‡å¼º
factor_bias_mom = op.Rank(bias)
```

---

##### `PVDeviation(close, volume, window)` â€” é‡ä»·åç¦»åº¦

```python
result = op.PVDeviation(close, volume, window)
```

è®¡ç®—å½“å‰ä»·æ ¼ç›¸å¯¹ VWAP çš„åç¦»ç¨‹åº¦ï¼ˆæ ‡å‡†åŒ–ï¼‰ï¼š`(close - VWAP) / rolling_std(close, window)`ã€‚

å€¼ä¸ºæ­£è¡¨ç¤ºä»·æ ¼æ˜¾è‘—é«˜äº VWAPï¼ˆåšå¤šåè´µï¼‰ï¼Œå€¼ä¸ºè´Ÿè¡¨ç¤ºä»·æ ¼æ˜¾è‘—ä½äº VWAPï¼ˆæ½œåœ¨ä½ä¼°ï¼‰ã€‚

```python
pv_dev = op.PVDeviation(data.close, data.volume, window=10)
# è´Ÿåç¦»ï¼ˆä»·æ ¼ä½äº VWAPï¼‰â†’ å‡å€¼å›å½’ä¹°å…¥ä¿¡å·
factor_pvdev = op.Rank(-pv_dev)
```

---

##### `Amihud(close, volume, window)` â€” Amihud éæµåŠ¨æ€§æŒ‡æ ‡

```python
result = op.Amihud(close, volume, window)
```

Amihudï¼ˆ2002ï¼‰æå‡ºçš„éæµåŠ¨æ€§åº¦é‡ï¼š`mean(|æ—¥æ”¶ç›Šç‡| / æ—¥æˆäº¤é‡)`ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºå•ä½æˆäº¤é‡å¯¹ä»·æ ¼çš„å†²å‡»è¶Šå¤§ï¼ˆæµåŠ¨æ€§è¶Šå·®ï¼‰ã€‚

```python
amihud = op.Amihud(data.close, data.volume, window=20)
# é«˜æµåŠ¨æ€§è‚¡ç¥¨ï¼ˆAmihud ä½ï¼‰é€šå¸¸æ›´å—æœºæ„åå¥½
factor_liq = op.Rank(-amihud)
```

---

### ğŸ†• åŠ¨é‡å› å­ç®—å­ (v2)

v2.0 æ–°å¢ 3 ä¸ªåŠ¨é‡å› å­ç®—å­ï¼Œæä¾›æ¯”ç®€å•ä»·æ ¼åŠ¨é‡æ›´ç²¾ç»†çš„ä¿¡å·ã€‚

---

##### `RiskAdjMomentum(close, window, vol_window)` â€” é£é™©è°ƒæ•´åŠ¨é‡

```python
result = op.RiskAdjMomentum(close, window=20, vol_window=20)
```

é£é™©è°ƒæ•´åçš„åŠ¨é‡å› å­ï¼š`Næ—¥ç´¯è®¡æ”¶ç›Šç‡ / Næ—¥æ»šåŠ¨æ³¢åŠ¨ç‡`ï¼Œç­‰ä»·äºåŠ¨é‡ä¿¡å·çš„å¤æ™®æ¯”ç‡ã€‚

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `window` | 20 | åŠ¨é‡è®¡ç®—å‘¨æœŸï¼ˆå¤©æ•°ï¼‰ |
| `vol_window` | 20 | æ³¢åŠ¨ç‡è®¡ç®—çª—å£ï¼ˆå¤©æ•°ï¼‰|

```python
# é«˜å¤æ™®åŠ¨é‡ï¼šä¸ä»…æ¶¨äº†ï¼Œè€Œä¸”æ¶¨å¾—å¹³ç¨³
factor_ram = op.Rank(op.RiskAdjMomentum(data.close, window=20, vol_window=20))
```

---

##### `PricePathQuality(close, window)` â€” ä»·æ ¼è·¯å¾„è´¨é‡

```python
result = op.PricePathQuality(close, window)   # è¿”å›å€¼åŸŸ [-1, 1]
```

è¡¡é‡è¿‡å» `window` å¤©ä»·æ ¼èµ°åŠ¿çš„**å•è°ƒæ€§ä¸çº¿æ€§åº¦**ï¼š
`|Spearman(t, x)| Ã— Pearson(t, x)Â²`

- å€¼æ¥è¿‘ 1ï¼šä»·æ ¼å•è°ƒçº¿æ€§ä¸Šæ¶¨ï¼ˆé«˜è´¨é‡è¶‹åŠ¿ï¼‰
- å€¼æ¥è¿‘ 0ï¼šä»·æ ¼éœ‡è¡æ— æ–¹å‘
- è´Ÿå€¼ï¼šå•è°ƒä¸‹è·Œ

```python
# è·¯å¾„è´¨é‡é«˜çš„ä¸Šæ¶¨ â†’ å¼ºè¶‹åŠ¿ä¿¡å·
ppq = op.PricePathQuality(data.close, window=20)
factor_trend = op.Rank(ppq)
```

---

##### `RangeBreakout(close, high, low, window)` â€” åŒºé—´çªç ´ä½ç½®

```python
result = op.RangeBreakout(close, high, low, window)   # è¿”å›å€¼åŸŸ [0, 1]
```

å½“å‰æ”¶ç›˜ä»·åœ¨è¿‡å» `window` å¤©é«˜ä½åŒºé—´ä¸­çš„ä½ç½®ï¼š
`(close - rolling_min(low)) / (rolling_max(high) - rolling_min(low))`

- å€¼æ¥è¿‘ 1ï¼šæ¥è¿‘å†å²é«˜ç‚¹ï¼ˆçªç ´ä¿¡å·ï¼‰
- å€¼æ¥è¿‘ 0ï¼šæ¥è¿‘å†å²ä½ç‚¹ï¼ˆè¶…å–ä¿¡å·ï¼‰

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `close` | DataFrame | æ”¶ç›˜ä»· |
| `high` | DataFrame | æœ€é«˜ä»· |
| `low` | DataFrame | æœ€ä½ä»· |

```python
breakout = op.RangeBreakout(data.close, data.high, data.low, window=20)
# ä»·æ ¼å¤„äºåŒºé—´é«˜ä½ â†’ çªç ´è¶‹åŠ¿
factor_breakout = op.Rank(breakout)
```

---

### ğŸ†• æŠ€æœ¯æŒ‡æ ‡ç®—å­ (v2)

v2.0 æ–°å¢ç»å…¸æŠ€æœ¯åˆ†ææŒ‡æ ‡ä½œä¸ºå› å­ä¿¡å·ï¼Œå…¨éƒ¨å‘é‡åŒ–å®ç°ï¼Œæ”¯æŒä»»æ„è‚¡ç¥¨çŸ©é˜µã€‚

---

##### `RSI(close, window=14)` â€” ç›¸å¯¹å¼ºå¼±æŒ‡æ•°

```python
result = op.RSI(close, window=14)   # è¿”å›å€¼åŸŸ [0, 100]
```

Wilder å¹³æ»‘ RSIï¼š`100 - 100 / (1 + AvgGain / AvgLoss)`ï¼Œä½¿ç”¨ `ewm(span=2Ã—window-1)` å®ç°ã€‚

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `window` | 14 | RSI è®¡ç®—å‘¨æœŸ |

- **RSI > 70**ï¼šè¶…ä¹°ï¼ˆå¯èƒ½å›è°ƒï¼‰
- **RSI < 30**ï¼šè¶…å–ï¼ˆå¯èƒ½åå¼¹ï¼‰

```python
rsi = op.RSI(data.close, window=14)
# è¶…å–åè½¬å› å­
factor_rsi = op.Rank(-(rsi - 50).abs())  # è·ç¦» 50 è¶Šè¿‘è¶Šä¸­æ€§
# æˆ–ï¼šè¶…å–åšå¤š
factor_oversold = op.Rank(100 - rsi)
```

---

##### `KDJ(close, high, low, n=9, m1=3, m2=3)` â€” KDJ æŒ‡æ ‡ï¼ˆK å€¼ï¼‰

```python
result = op.KDJ(close, high, low, n=9, m1=3, m2=3)   # è¿”å› K å€¼ï¼Œçº¦ [0, 100]
```

åŸºäº RSVï¼ˆæœªæˆç†Ÿéšæœºå€¼ï¼‰çš„ EWM å¹³æ»‘ K å€¼ï¼š
- `RSV = (close - Ln) / (Hn - Ln) Ã— 100`
- `K = EWM(RSV, m1)`

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `n` | 9 | åŒºé—´å‘¨æœŸ |
| `m1` | 3 | K å€¼å¹³æ»‘ç³»æ•° |
| `m2` | 3 | D å€¼å¹³æ»‘ç³»æ•°ï¼ˆå½“å‰ä»…è¿”å› K å€¼ï¼‰|

```python
k_val = op.KDJ(data.close, data.high, data.low, n=9)
# K å€¼è¶…ä¹°è¶…å–
factor_kdj = op.Rank(50 - k_val)   # ä½ K å€¼æ’åé å‰ï¼ˆè¶…å–ï¼‰
```

---

##### `MACD(close, fast=12, slow=26, signal=9)` â€” MACD æŸ±çŠ¶å›¾

```python
result = op.MACD(close, fast=12, slow=26, signal=9)   # è¿”å› MACD æŸ±çŠ¶å›¾ï¼ˆHistogramï¼‰
```

æ ‡å‡† MACDï¼š
- `DIF = EMA(close, fast) - EMA(close, slow)`
- `DEA = EMA(DIF, signal)`
- **è¿”å›æŸ±çŠ¶å›¾** = `DIF - DEA`ï¼ˆæ­£å€¼ä¸Šç©¿ä¸ºä¹°å…¥ä¿¡å·ï¼Œè´Ÿå€¼ä¸‹ç©¿ä¸ºå–å‡ºä¿¡å·ï¼‰

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `fast` | 12 | å¿«çº¿ EMA å‘¨æœŸ |
| `slow` | 26 | æ…¢çº¿ EMA å‘¨æœŸ |
| `signal` | 9 | ä¿¡å·çº¿ EMA å‘¨æœŸ |

```python
macd_hist = op.MACD(data.close, fast=12, slow=26, signal=9)
# æŸ±çŠ¶å›¾ç”±è´Ÿè½¬æ­£ â†’ è¶‹åŠ¿åè½¬ä¿¡å·
factor_macd = op.Rank(macd_hist)
```

---

### 3. VectorEngine â€” å›æµ‹å¼•æ“

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.backtest import VectorEngine`

çŸ©é˜µå¼å‡€å€¼å›æµ‹å¼•æ“ï¼Œæ¥æ”¶å› å­çŸ©é˜µå’Œè¡Œæƒ…æ•°æ®ï¼Œè¾“å‡ºå®Œæ•´å›æµ‹ç»“æœã€‚

#### æ„é€ å‚æ•°

```python
VectorEngine(
    factor          = factor_df,     # å¿…å¡«ï¼šå› å­çŸ©é˜µ
    close           = close_df,      # å¿…å¡«ï¼šæ”¶ç›˜ä»·çŸ©é˜µ
    is_suspended    = susp_df,       # å¿…å¡«ï¼šåœç‰ŒçŸ©é˜µ
    is_limit        = limit_df,      # å¿…å¡«ï¼šæ¶¨è·ŒåœçŸ©é˜µ
    rebalance_freq  = 1,             # è°ƒä»“é¢‘ç‡ï¼ˆå¤©æ•°ï¼‰
    top_n           = 50,            # æŒä»“è‚¡ç¥¨æ•°
    weight_method   = 'equal',       # æƒé‡æ–¹å¼
    cost_rate       = 0.0015,        # å•è¾¹äº¤æ˜“æˆæœ¬
    initial_capital = 1_000_000.0,   # åˆå§‹èµ„é‡‘ï¼ˆä»…å±•ç¤ºç”¨ï¼‰
    # â”€â”€ å†…ç½®é¢„å¤„ç†å‚æ•°ï¼ˆv2.0 æ–°å¢ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    delay           = 1,             # å› å­å»¶è¿Ÿå¤©æ•°ï¼ˆ0=ä¸å»¶è¿Ÿï¼‰
    decay           = 0,             # çº¿æ€§è¡°å‡çª—å£ï¼ˆ0=ä¸è¡°å‡ï¼‰
    industry        = None,          # è¡Œä¸šæ˜ å°„ï¼ŒNone=è·³è¿‡ä¸­æ€§åŒ–
)
```

#### å‚æ•°è¯¦è§£

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `factor` | DataFrame | â€” | **å¿…å¡«**ã€‚å› å­çŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œå€¼è¶Šå¤§ä»£è¡¨è¯¥è‚¡ç¥¨è¶Šåº”è¯¥è¢«ä¹°å…¥ |
| `close` | DataFrame | â€” | **å¿…å¡«**ã€‚æ”¶ç›˜ä»·çŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œç”¨äºè®¡ç®—æ¯æ—¥æ”¶ç›Šç‡ |
| `is_suspended` | DataFrame | â€” | **å¿…å¡«**ã€‚åœç‰ŒçŸ©é˜µï¼ˆT Ã— Nï¼Œboolï¼‰ã€‚åœç‰Œè‚¡ç¥¨å½“æ—¥æƒé‡è‡ªåŠ¨ç½®é›¶ |
| `is_limit` | DataFrame | â€” | **å¿…å¡«**ã€‚æ¶¨è·ŒåœçŸ©é˜µï¼ˆT Ã— Nï¼Œboolï¼‰ã€‚æ¶¨è·Œåœè‚¡ç¥¨å½“æ—¥æƒé‡è‡ªåŠ¨ç½®é›¶ï¼ˆæ— æ³•æˆäº¤ï¼‰|
| `rebalance_freq` | int | 1 | è°ƒä»“é¢‘ç‡ã€‚`1`=æ¯æ—¥è°ƒä»“ï¼Œ`5`=æ¯å‘¨è°ƒä»“ï¼Œ`21`â‰ˆæ¯æœˆè°ƒä»“ã€‚éè°ƒä»“æ—¥æŒä»“ä¸å˜ |
| `top_n` | int | 50 | æ¯æ¬¡è°ƒä»“æ—¶ï¼ŒæŒ‰å› å­å€¼æ’åå–å‰ N åªè‚¡ç¥¨æŒä»“ã€‚è‹¥å¯äº¤æ˜“è‚¡ç¥¨ä¸è¶³ N åªï¼Œåˆ™å–å…¨éƒ¨å¯äº¤æ˜“è‚¡ç¥¨ |
| `weight_method` | str | `'equal'` | æŒä»“æƒé‡è®¡ç®—æ–¹å¼ï¼Œè§ä¸‹æ–¹è¯´æ˜ |
| `cost_rate` | float | 0.0015 | å•è¾¹äº¤æ˜“æˆæœ¬ç‡ï¼ˆæ‰‹ç»­è´¹ + æ»‘ç‚¹ï¼‰ã€‚æ¯æ¬¡æ¢æ‰‹çš„ä¹°å…¥æˆ–å–å‡ºå‡æŒ‰æ­¤æ¯”ç‡æ‰£è´¹ |
| `initial_capital` | float | 1,000,000 | åˆå§‹èµ„é‡‘ï¼Œä»…ç”¨äºç»“æœå±•ç¤ºï¼Œä¸å½±å“æ”¶ç›Šç‡è®¡ç®— |
| `delay` | int | **1** | å› å­å»¶è¿Ÿå¤©æ•°ï¼ˆ`Ts_Delay`ï¼‰ã€‚`1` è¡¨ç¤º T æ—¥å› å­åœ¨ T+1 æ—¥åç”Ÿæ•ˆï¼Œé˜²æ­¢æ—¥å†…ä½¿ç”¨æœªæ¥æ•°æ®ï¼›`0` å…³é—­å»¶è¿Ÿ |
| `decay` | int | 0 | çº¿æ€§è¡°å‡çª—å£ï¼ˆ`Decay_Linear`ï¼‰ã€‚å¯¹å› å­åšçº¿æ€§åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå¹³æ»‘ä¿¡å·ã€é™ä½æ¢æ‰‹ç‡ï¼›`0` è·³è¿‡ |
| `industry` | Series/DataFrame/None | None | è¡Œä¸šæ˜ å°„ï¼ˆè‚¡ç¥¨ â†’ è¡Œä¸šæ ‡ç­¾ï¼‰ï¼Œä¼ å…¥åè‡ªåŠ¨å¯¹å› å­åš OLS è¡Œä¸šä¸­æ€§åŒ–ï¼ˆ`Neutralize`ï¼‰ï¼›`None` è·³è¿‡ |

**`weight_method` å¯é€‰å€¼ï¼š**

| å€¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|----|------|----------|
| `'equal'` | Top-N è‚¡ç¥¨ç­‰æƒæŒä»“ï¼Œæ¯åªæƒé‡ = 1/N | é»˜è®¤æ¨èï¼Œæ¶ˆé™¤è§„æ¨¡åå·® |
| `'factor_weighted'` | Top-N è‚¡ç¥¨æŒ‰å› å­ç»å¯¹å€¼åŠ æƒï¼ˆå½’ä¸€åŒ–åï¼‰ï¼Œå› å­å€¼è¶Šå¤§æƒé‡è¶Šé«˜ | å¸Œæœ›å› å­å¼ºä¿¡å·è‚¡ç¥¨è·å¾—æ›´é«˜é…ç½® |

**è°ƒä»“é¢‘ç‡å»ºè®®ï¼š**

| `rebalance_freq` | ç­‰æ•ˆé¢‘ç‡ | é€‚ç”¨å› å­ç±»å‹ |
|------------------|----------|-------------|
| 1 | æ¯æ—¥è°ƒä»“ | é«˜é¢‘åŠ¨é‡ã€é‡ä»·å› å­ |
| 5 | æ¯å‘¨è°ƒä»“ | ä¸­é¢‘æŠ€æœ¯å› å­ï¼ˆæ¨èèµ·ç‚¹ï¼‰|
| 21 | æ¯æœˆè°ƒä»“ | ä½é¢‘åŸºæœ¬é¢å› å­ |

#### æ–¹æ³•

```python
result = engine.run()   # æ‰§è¡Œå›æµ‹ï¼Œè¿”å› BacktestResult
```

`run()` ä¼šè‡ªåŠ¨ï¼š
0. **å› å­é¢„å¤„ç†**ï¼ˆv2.0 æ–°å¢ï¼‰ï¼šæŒ‰ `delay â†’ decay â†’ neutralize` é¡ºåºæ‰§è¡Œå†…ç½®é¢„å¤„ç†ï¼ˆä»»ä¸€å‚æ•°ä¸ºé»˜è®¤å€¼æ—¶è‡ªåŠ¨è·³è¿‡å¯¹åº”æ­¥éª¤ï¼‰
1. å¯¹é½æ‰€æœ‰è¾“å…¥æ•°æ®ï¼ˆå–å…±åŒæ—¥æœŸå’Œè‚¡ç¥¨ï¼‰
2. è®¡ç®—å‰å‘ 1 æ—¥æ”¶ç›Šç‡ï¼ˆä¸¥æ ¼é˜²æœªæ¥å‡½æ•°ï¼‰
3. åœ¨è°ƒä»“æ—¥ç”Ÿæˆæƒé‡ï¼Œè¿‡æ»¤åœç‰Œ/æ¶¨è·Œåœè‚¡ç¥¨
4. è®¡ç®—æ¯æ—¥æ¢æ‰‹ç‡å’Œäº¤æ˜“æˆæœ¬
5. è®¡ç®—å‡€å€¼åºåˆ—å’Œå…¨é‡ç»©æ•ˆæŒ‡æ ‡

#### ä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine.backtest import VectorEngine

# åŸºç¡€ç”¨æ³•ï¼ˆæ¯å‘¨è°ƒä»“ï¼Œç­‰æƒæŒä»“30åªï¼Œé»˜è®¤ delay=1 è‡ªåŠ¨é˜²æœªæ¥å‡½æ•°ï¼‰
engine = VectorEngine(
    factor         = factor,
    close          = data.close,
    is_suspended   = data.is_suspended,
    is_limit       = data.is_limit,
    rebalance_freq = 5,
    top_n          = 30,
    weight_method  = 'equal',
    cost_rate      = 0.0015,
    # delay=1 ä¸ºé»˜è®¤å€¼ï¼ŒTæ—¥å› å­ â†’ T+1æ—¥ç”Ÿæ•ˆï¼ˆä¿å®ˆé£æ§ï¼‰
)
result = engine.run()

# å› å­åŠ æƒ + ä½æ¢æ‰‹ï¼ˆæ¯æœˆè°ƒä»“ï¼‰
engine2 = VectorEngine(
    factor         = factor,
    close          = data.close,
    is_suspended   = data.is_suspended,
    is_limit       = data.is_limit,
    rebalance_freq = 21,
    top_n          = 20,
    weight_method  = 'factor_weighted',
    cost_rate      = 0.0010,   # æ›´ä½æˆæœ¬ï¼ˆæœºæ„è´¹ç‡ï¼‰
)
result2 = engine2.run()

# å®Œæ•´é¢„å¤„ç†æµæ°´çº¿ï¼ˆdelay + decay + è¡Œä¸šä¸­æ€§åŒ–ï¼‰
engine3 = VectorEngine(
    factor         = factor,
    close          = data.close,
    is_suspended   = data.is_suspended,
    is_limit       = data.is_limit,
    rebalance_freq = 5,
    top_n          = 30,
    cost_rate      = 0.0015,
    delay          = 1,               # Step1: Tæ—¥å› å­ â†’ T+1æ—¥ç”Ÿæ•ˆ
    decay          = 5,               # Step2: çº¿æ€§è¡°å‡å¹³æ»‘ï¼ˆé™æ¢æ‰‹ç‡ï¼‰
    industry       = data.industry,   # Step3: OLSè¡Œä¸šä¸­æ€§åŒ–
)
result3 = engine3.run()
```

---

### 4. BacktestResult â€” å›æµ‹ç»“æœå¯¹è±¡

`engine.run()` è¿”å›ä¸€ä¸ª `BacktestResult` æ•°æ®ç±»ï¼ŒåŒ…å«æ‰€æœ‰ä¸­é—´ç»“æœå’Œç»©æ•ˆæŒ‡æ ‡ï¼Œå¯ç›´æ¥ç”¨äºäºŒæ¬¡åˆ†æã€‚

#### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `result.nav` | Series | ç­–ç•¥å‡€å€¼åºåˆ—ï¼Œä» 1.0 å¼€å§‹ï¼Œindex=æ—¥æœŸ |
| `result.daily_returns` | Series | æ‰£é™¤äº¤æ˜“æˆæœ¬åçš„æ—¥æ”¶ç›Šç‡ |
| `result.gross_returns` | Series | æ‰£é™¤æˆæœ¬**å‰**çš„æ—¥æ”¶ç›Šç‡ï¼ˆæ¯›æ”¶ç›Šï¼‰|
| `result.cost_series` | Series | æ¯æ—¥å®é™…äº¤æ˜“æˆæœ¬ï¼ˆæ¢æ‰‹ç‡ Ã— cost_rateï¼‰|
| `result.weights` | DataFrame | æŒä»“æƒé‡çŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œå·²å«å‰å‘å¡«å…… |
| `result.turnover` | Series | æ¯æ—¥å•è¾¹æ¢æ‰‹ç‡ = `sum(|w_t - w_{t-1}|) / 2` |
| `result.ic_series` | Series | æ¯æ—¥æˆªé¢ Rank IC å€¼ |
| `result.forward_returns` | DataFrame | å‰å‘1æ—¥æ”¶ç›Šç‡çŸ©é˜µï¼ˆT Ã— Nï¼‰|
| `result.factor` | DataFrame | å¯¹é½åçš„å› å­çŸ©é˜µï¼ˆT Ã— Nï¼‰|
| `result.metrics` | dict | æ‰€æœ‰ç»©æ•ˆæŒ‡æ ‡å­—å…¸ï¼ˆè§ä¸‹æ–¹æŒ‡æ ‡è¯´æ˜ï¼‰|
| `result.rebalance_dates` | list | å®é™…è°ƒä»“æ—¥æœŸåˆ—è¡¨ |

#### æ–¹æ³•

```python
result.print_summary()              # æ§åˆ¶å°æ‰“å° Unicode æ ¼å¼æŒ‡æ ‡è¡¨æ ¼
result.plot()                       # å¼¹çª—æ˜¾ç¤º 6 å­å›¾åˆ†ææŠ¥å‘Š
result.plot(save_path='out.png')    # ä¿å­˜æŠ¥å‘Šä¸º PNG æ–‡ä»¶ï¼ˆdpi=150ï¼‰
```

#### äºŒæ¬¡åˆ†æç¤ºä¾‹

```python
# æŸ¥çœ‹å‡€å€¼åºåˆ—
result.nav.plot(title='ç­–ç•¥å‡€å€¼')

# æŸ¥çœ‹æƒé‡åˆ†å¸ƒ
result.weights.sum(axis=1)   # æ¯æ—¥æ€»æƒé‡ï¼ˆåº”æ¥è¿‘1ï¼‰

# æ‰¾åˆ°æŒä»“æœ€å¤šçš„è‚¡ç¥¨
result.weights.mean().nlargest(10)   # å†å²å¹³å‡æƒé‡æœ€é«˜çš„10åªè‚¡ç¥¨

# æå– IC åºåˆ—åšç»Ÿè®¡
ic = result.ic_series.dropna()
print(f"IC å‡å€¼: {ic.mean():.4f}, ICIR: {ic.mean()/ic.std()*252**0.5:.3f}")

# è®¿é—®åŸå§‹æŒ‡æ ‡å­—å…¸
print(result.metrics['Sharpe_Ratio'])
print(result.metrics['IC_Mean'])

# è®¡ç®—ç´¯è®¡æˆæœ¬
cumcost = result.cost_series.cumsum()
```

---

### 5. Performance â€” ç»©æ•ˆæŒ‡æ ‡è®¡ç®—

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.backtest.performance import Performance`

ç‹¬ç«‹çš„ç»©æ•ˆè®¡ç®—å·¥å…·ç±»ï¼Œæ‰€æœ‰æ–¹æ³•ä¸ºé™æ€æ–¹æ³•ï¼Œå¯å¯¹ä»»æ„åºåˆ—è°ƒç”¨ï¼Œä¸ä¾èµ–å›æµ‹å¼•æ“ã€‚

#### æ–¹æ³•åˆ—è¡¨

---

##### `Performance.calc_annualized_return(nav)` â€” å¹´åŒ–æ”¶ç›Šç‡

```python
ann_ret = Performance.calc_annualized_return(nav)
# å…¬å¼ï¼š(nav_æœ« / nav_åˆ)^(252/T) - 1
```

| å‚æ•° | è¯´æ˜ |
|------|------|
| `nav` | å‡€å€¼åºåˆ—ï¼ˆpd.Seriesï¼Œä»1.0å¼€å§‹ï¼‰|

**è¿”å›ï¼š** floatï¼Œå¦‚ `0.15` è¡¨ç¤ºå¹´åŒ– 15%

---

##### `Performance.calc_annualized_volatility(returns)` â€” å¹´åŒ–æ³¢åŠ¨ç‡

```python
ann_vol = Performance.calc_annualized_volatility(returns)
# å…¬å¼ï¼šstd(r) * sqrt(252)
```

**è¿”å›ï¼š** floatï¼Œå¦‚ `0.20` è¡¨ç¤ºå¹´åŒ– 20%

---

##### `Performance.calc_sharpe(returns, risk_free=0.0, annualize=True)` â€” å¤æ™®æ¯”ç‡

```python
sharpe = Performance.calc_sharpe(returns, risk_free=0.03)
# å…¬å¼ï¼š(mean(r) - rf/252) / std(r) * sqrt(252)
```

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `returns` | â€” | æ—¥æ”¶ç›Šç‡åºåˆ— |
| `risk_free` | 0.0 | æ— é£é™©åˆ©ç‡ï¼ˆ**å¹´åŒ–**ï¼‰ï¼Œå¦‚ 0.03 è¡¨ç¤º 3% |
| `annualize` | True | æ˜¯å¦å¹´åŒ– |

**è¿”å›ï¼š** floatï¼Œè¶Šå¤§è¶Šå¥½ï¼ˆé€šå¸¸ >1 ä¸ºä¼˜ç§€ï¼Œ>2 ä¸ºå“è¶Šï¼‰

---

##### `Performance.calc_max_drawdown(nav)` â€” æœ€å¤§å›æ’¤

```python
mdd = Performance.calc_max_drawdown(nav)
# å…¬å¼ï¼šmin((nav_t - max(nav_{0..t})) / max(nav_{0..t}))
```

**è¿”å›ï¼š** floatï¼ˆ**è´Ÿæ•°**ï¼‰ï¼Œå¦‚ `-0.15` è¡¨ç¤ºæœ€å¤§å›æ’¤ -15%

---

##### `Performance.calc_calmar(nav)` â€” Calmar æ¯”ç‡

```python
calmar = Performance.calc_calmar(nav)
# å…¬å¼ï¼šå¹´åŒ–æ”¶ç›Šç‡ / |æœ€å¤§å›æ’¤|
```

**è¿”å›ï¼š** floatï¼Œè¡¡é‡å•ä½å›æ’¤é£é™©è·å¾—çš„å¹´åŒ–æ”¶ç›Šï¼Œè¶Šå¤§è¶Šå¥½

---

##### `Performance.calc_ic_series(factor, forward_returns)` â€” é€æ—¥ IC åºåˆ—

```python
ic_series = Performance.calc_ic_series(factor_df, fwd_ret_df)
```

| å‚æ•° | è¯´æ˜ |
|------|------|
| `factor` | å› å­çŸ©é˜µï¼ˆT Ã— Nï¼‰ |
| `forward_returns` | å¯¹åº”çš„å‰å‘æ”¶ç›ŠçŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œé¡»ä¸ factor å¯¹é½ |

**IC è®¡ç®—æ–¹å¼ï¼š** æ¯æ—¥æˆªé¢ Rank IC = Spearman ç›¸å…³ç³»æ•°ï¼ˆå‘é‡åŒ–å®ç°ï¼Œç­‰ä»·äºå¯¹æ’ååçš„å› å­å’Œæ”¶ç›Šåš Pearson ç›¸å…³ï¼‰

**è¿”å›ï¼š** pd.Seriesï¼Œæ¯æ—¥çš„ IC å€¼ï¼Œindex=æ—¥æœŸ

---

##### `Performance.calc_ic_stats(ic_series)` â€” IC ç»Ÿè®¡æ‘˜è¦

```python
stats = Performance.calc_ic_stats(ic_series)
```

**è¿”å›å­—å…¸ï¼š**

| Key | è¯´æ˜ |
|-----|------|
| `IC_Mean` | IC å‡å€¼ï¼Œé€šå¸¸ä¼˜ç§€å› å­çš„ |IC| > 0.03 |
| `IC_Std` | IC æ ‡å‡†å·®ï¼Œåæ˜  IC ç¨³å®šæ€§ |
| `ICIR` | IC ä¿¡æ¯æ¯”ç‡ = IC_Mean / IC_Std Ã— âˆš252ï¼Œé€šå¸¸ >0.5 ä¸ºä¼˜ç§€ |
| `IC_Positive_Ratio` | IC > 0 çš„æ¯”ä¾‹ï¼ˆèƒœç‡ï¼‰ï¼Œé€šå¸¸ >55% ä¸ºä¼˜ç§€ |
| `IC_t_stat` | IC å‡å€¼çš„ t ç»Ÿè®¡é‡ï¼Œ|t| > 2 è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘— |

---

##### `Performance.calc_turnover(weights)` â€” æ¢æ‰‹ç‡åºåˆ—

```python
turnover = Performance.calc_turnover(weights_df)
# å…¬å¼ï¼šsum(|w_t - w_{t-1}|) / 2
```

**è¿”å›ï¼š** pd.Seriesï¼Œæ¯æ—¥å•è¾¹æ¢æ‰‹ç‡ï¼ˆ0~1ä¹‹é—´ï¼Œå¦‚ 0.05 è¡¨ç¤º 5%ï¼‰

---

##### `Performance.calc_fitness(sharpe, nav, turnover)` â€” Fitness æŒ‡æ ‡

```python
fitness = Performance.calc_fitness(sharpe, nav, turnover)
# å…¬å¼ï¼šSharpe Ã— sqrt(|å¹´åŒ–æ”¶ç›Šç‡| / æ—¥å‡æ¢æ‰‹ç‡)
```

WorldQuant ç”¨äºç»¼åˆè¡¡é‡å› å­**æ”¶ç›Šè´¨é‡ Ã— ç¨³å®šæ€§ / æ¢æ‰‹æˆæœ¬**çš„ç»¼åˆæŒ‡æ ‡ã€‚

**è¿”å›ï¼š** floatï¼Œé€šå¸¸ >1.0 ä¸ºæœ‰ä»·å€¼çš„å› å­

---

##### `Performance.summary(...)` â€” å®Œæ•´æŒ‡æ ‡æ±‡æ€»

```python
metrics = Performance.summary(
    nav             = nav,
    daily_returns   = returns,
    weights         = weights,
    factor          = factor,
    forward_returns = fwd_ret,
    cost_series     = cost_series,   # å¯é€‰
)
```

**è¿”å›å­—å…¸ï¼ˆæ‰€æœ‰é”®åï¼‰ï¼š**

```python
{
    'å¹´åŒ–æ”¶ç›Šç‡': 0.1234,    # å¦‚ 0.1234 è¡¨ç¤º 12.34%
    'å¹´åŒ–æ³¢åŠ¨ç‡': 0.0856,
    'Sharpe_Ratio': 1.44,
    'Calmar_Ratio': 0.88,
    'æœ€å¤§å›æ’¤': -0.1567,     # è´Ÿæ•°
    'IC_Mean': 0.053,
    'IC_Std': 0.089,
    'ICIR': 1.23,
    'IC_èƒœç‡': 0.583,        # å¦‚ 0.583 è¡¨ç¤º 58.3%
    'IC_tç»Ÿè®¡é‡': 3.45,
    'æ—¥å‡æ¢æ‰‹ç‡': 0.056,
    'å¹´åŒ–æ‰‹ç»­è´¹': 0.0123,
    'Fitness': 0.89,
}
```

#### ç‹¬ç«‹ä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine.backtest.performance import Performance
import pandas as pd

# å¯¹è‡ªå·±çš„æ”¶ç›Šåºåˆ—è®¡ç®—æŒ‡æ ‡
my_returns = pd.Series([0.001, -0.002, 0.003, ...], index=dates)
my_nav     = (1 + my_returns).cumprod()

sharpe = Performance.calc_sharpe(my_returns, risk_free=0.03)
mdd    = Performance.calc_max_drawdown(my_nav)
print(f"Sharpe: {sharpe:.3f}, MaxDD: {mdd*100:.1f}%")

# è®¡ç®— IC
ic = Performance.calc_ic_series(my_factor, my_fwd_returns)
stats = Performance.calc_ic_stats(ic)
print(f"IC å‡å€¼: {stats['IC_Mean']:.4f}, ICIR: {stats['ICIR']:.3f}")
```

---

### 6. Report â€” å¯è§†åŒ–æŠ¥å‘Š

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.visualization.report import Report`

é€šå¸¸é€šè¿‡ `result.plot()` é—´æ¥è°ƒç”¨ï¼Œä¹Ÿå¯ç›´æ¥è°ƒç”¨ `Report.plot(result)`ã€‚

#### `Report.plot(result, save_path=None, benchmark_seed=2024)`

```python
Report.plot(result)                            # å¼¹çª—å±•ç¤º
Report.plot(result, save_path='report.png')    # ä¿å­˜ä¸º PNGï¼ˆdpi=150ï¼‰
Report.plot(result, benchmark_seed=42)         # æŒ‡å®šåŸºå‡†éšæœºç§å­
```

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `result` | â€” | BacktestResult å¯¹è±¡ |
| `save_path` | None | ä¿å­˜è·¯å¾„ï¼ˆå¦‚ `'./output/factor1.png'`ï¼‰ã€‚ä¸º None æ—¶å¼¹çª—å±•ç¤º |
| `benchmark_seed` | 2024 | æ¨¡æ‹ŸåŸºå‡†ï¼ˆéšæœºæ¸¸èµ°ï¼‰çš„éšæœºç§å­ï¼Œå›ºå®šåæ¯æ¬¡åŸºå‡†ç›¸åŒ |

#### 6 å­å›¾å¸ƒå±€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ˆ å‡€å€¼æ›²çº¿     â”‚  ğŸ—“ï¸ æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾ â”‚   ğŸ“Š IC æ—¶åº      â”‚
â”‚  ç­–ç•¥ vs åŸºå‡†    â”‚   è¡Œ=å¹´ï¼Œåˆ—=æœˆ    â”‚  æ­£ç»¿è´Ÿçº¢ + å‡å€¼çº¿ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‰ æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ â”‚   ğŸ”„ æ¢æ‰‹ç‡åºåˆ—   â”‚   ğŸ“ IC åˆ†å¸ƒ      â”‚
â”‚  ç›´æ–¹å›¾+KDE+æ­£æ€ â”‚  æŠ˜çº¿+å‡å€¼+è°ƒä»“æ—¥ â”‚ ç›´æ–¹å›¾+æ­£æ€+èƒœç‡  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  é¡¶éƒ¨æŒ‡æ ‡æ‘˜è¦æ¡ï¼ˆ8é¡¹æ ¸å¿ƒæŒ‡æ ‡ï¼‰
```

| å­å›¾ | å†…å®¹ | å…³é”®ä¿¡æ¯ |
|------|------|----------|
| å‡€å€¼æ›²çº¿ | ç­–ç•¥å‡€å€¼ï¼ˆçº¢ï¼‰+ æ¨¡æ‹ŸåŸºå‡†ï¼ˆç°è™šçº¿ï¼‰+ å›æ’¤é˜´å½± | æœ€å¤§å›æ’¤æ ‡æ³¨ç®­å¤´ |
| æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾ | æ¯æœˆæ”¶ç›Šç‡ï¼Œçº¢ç»¿é…è‰²ï¼ˆç»¿=æ­£æ”¶ç›Šï¼Œçº¢=è´Ÿæ”¶ç›Šï¼‰| ç›´è§‚çœ‹å­£èŠ‚æ€§è§„å¾‹ |
| IC æ—¶åº | æ¯æ—¥ IC æŸ±çŠ¶å›¾ï¼ˆæ­£ç»¿è´Ÿçº¢ï¼‰+ IC å‡å€¼è™šçº¿ | å·¦ä¸Šè§’æ ‡æ³¨ ICIR |
| æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ | å®é™…åˆ†å¸ƒç›´æ–¹å›¾ + KDE + æ­£æ€åˆ†å¸ƒå¯¹æ¯”æ›²çº¿ | å°–å³°åšå°¾ç‰¹å¾ |
| æ¢æ‰‹ç‡åºåˆ— | éé›¶æ¢æ‰‹ç‡æŠ˜çº¿ + å‡å€¼è™šçº¿ + è°ƒä»“æ—¥æ ‡è®°ï¼ˆç°è‰²ç«–çº¿ï¼‰| äº†è§£æˆæœ¬èŠ‚å¥ |
| IC åˆ†å¸ƒ | IC å€¼åˆ†å¸ƒç›´æ–¹å›¾ + æ­£æ€æ‹Ÿåˆ + èƒœç‡æ ‡æ³¨ | IC åˆ†å¸ƒåæ­£æ€§ |

---

### 7. Fusion â€” å¤šå› å­èåˆæ¡†æ¶ (v2)

**å¯¼å…¥è·¯å¾„ï¼š**
```python
from quant_alpha_engine.fusion import Labeler, StatisticalCombiner, MLCombiner
# æˆ–é€šè¿‡æ ¹åŒ…ç›´æ¥å¯¼å…¥ï¼š
from quant_alpha_engine import Labeler, StatisticalCombiner, MLCombiner
```

å¤šå› å­èåˆæ¡†æ¶æä¾›ä¸¤ç§èŒƒå¼å°†å¤šä¸ªå•å› å­åˆæˆä¸ºä¸€ä¸ªç»¼åˆå› å­ï¼Œå¹¶ç›´æ¥è¾“å‡ºæ ‡å‡† `BacktestResult`ï¼Œæ— ç¼å¯¹æ¥ç°æœ‰è¯„ä¼°ä½“ç³»ã€‚

**å®Œæ•´èåˆæµç¨‹ï¼š**

```python
from quant_alpha_engine import MockDataGenerator, Labeler, StatisticalCombiner, MLCombiner
from quant_alpha_engine.ops import AlphaOps as op

# 1. å‡†å¤‡æ•°æ®
data   = MockDataGenerator(n_stocks=100, n_days=504).generate()
close  = data.close

# 2. æ„é€ å¤šä¸ªå•å› å­
f1 = op.Rank(op.Ts_Delta(close, 5))
f2 = op.Rank(-op.Ts_Corr(data.volume, close, 10))
f3 = op.Rank(op.MACD(close))

# 3. ç”Ÿæˆæ ‡ç­¾
label = Labeler().set_label(target='close', horizon=5, data={'close': close})

# 4. ç»Ÿè®¡èåˆï¼ˆIC åŠ æƒï¼‰
stat = StatisticalCombiner('ic_weighted').fit([f1, f2, f3], label)
result = stat.evaluate(
    [f1, f2, f3],
    close=close, is_suspended=data.is_suspended, is_limit=data.is_limit,
    rebalance_freq=5, top_n=30,
)
result.print_summary()
result.plot()

# 5. ML èåˆï¼ˆRidgeï¼Œé˜²æœªæ¥å‡½æ•°ï¼‰
ml = MLCombiner('ridge', min_train_periods=60, refit_freq=20)
ml.fit([f1, f2, f3], label)
result2 = ml.evaluate(
    [f1, f2, f3],
    close=close, is_suspended=data.is_suspended, is_limit=data.is_limit,
    rebalance_freq=5, top_n=30,
)
result2.plot()
print(ml.feature_importances_)  # æŸ¥çœ‹å„å› å­é‡è¦æ€§
```

---

#### 7.1 Labeler â€” æ ‡ç­¾ç”Ÿæˆå™¨

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.fusion import Labeler`

ç”Ÿæˆç”¨äºå¤šå› å­èåˆçš„**å‰å‘æ”¶ç›Šç‡æ ‡ç­¾**ï¼ˆç›‘ç£å­¦ä¹ çš„ç›®æ ‡ Yï¼‰ã€‚

##### `set_label(target, horizon, method, data, custom_label)` â€” ç”Ÿæˆæ ‡ç­¾

```python
label = Labeler().set_label(
    target       = 'close',    # ç›®æ ‡ä»·æ ¼å­—æ®µï¼š'close' | 'open' | 'vwap' ç­‰
    horizon      = 5,          # å‰å‘å¤©æ•°ï¼ˆé¢„æµ‹å‡ å¤©åçš„æ”¶ç›Šï¼‰
    method       = 'return',   # æ”¶ç›Šè®¡ç®—æ–¹å¼ï¼š'return' | 'log_return'
    data         = {'close': close_df},  # å«ç›®æ ‡ä»·æ ¼çŸ©é˜µçš„å­—å…¸
    custom_label = None,       # ç”¨æˆ·è‡ªå®šä¹‰ Y (TÃ—N DataFrame)ï¼Œä¼˜å…ˆçº§æœ€é«˜
)
```

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `target` | `'close'` | ä»·æ ¼å­—æ®µåï¼Œéœ€ä¸ `data` å­—å…¸ä¸­çš„ key å¯¹åº” |
| `horizon` | `1` | å‰å‘å¤©æ•°ï¼Œå¦‚ `5` è¡¨ç¤ºé¢„æµ‹ 5 æ—¥åçš„æ”¶ç›Šç‡ |
| `method` | `'return'` | `'return'`ï¼šç®€å•æ”¶ç›Šç‡ `P_{t+h}/P_t - 1`ï¼›`'log_return'`ï¼šå¯¹æ•°æ”¶ç›Šç‡ |
| `data` | `None` | ä»·æ ¼æ•°æ®å­—å…¸ï¼Œå¦‚ `{'close': close_df}` |
| `custom_label` | `None` | è‹¥æä¾›ï¼Œç›´æ¥è¿”å›è¯¥ DataFrameï¼ˆè·³è¿‡å†…ç½®è®¡ç®—ï¼‰|

**è¿”å›ï¼š** pd.DataFrameï¼ˆT Ã— Nï¼‰ï¼Œä¸è¾“å…¥ä»·æ ¼çŸ©é˜µå½¢çŠ¶ç›¸åŒï¼Œå‰ `horizon` è¡Œä¸º NaNã€‚

```python
# æ–¹å¼ä¸€ï¼šå†…ç½®æ ‡ç­¾ï¼ˆ5æ—¥ç®€å•æ”¶ç›Šç‡ï¼‰
y = Labeler().set_label(target='close', horizon=5, data={'close': close})

# æ–¹å¼äºŒï¼šå¯¹æ•°æ”¶ç›Šç‡æ ‡ç­¾
y_log = Labeler().set_label(target='close', horizon=5,
                             method='log_return', data={'close': close})

# æ–¹å¼ä¸‰ï¼šç”¨æˆ·è‡ªå®šä¹‰æ ‡ç­¾
my_y = (close.shift(-3) / close - 1)   # 3æ—¥æ”¶ç›Šç‡
y_custom = Labeler().set_label(custom_label=my_y)

# é™æ€å·¥å‚æ–¹æ³•ï¼ˆç›´æ¥ä»ä»·æ ¼è®¡ç®—ï¼‰
y_static = Labeler.from_price(close, horizon=5, method='return')
```

---

#### 7.2 StatisticalCombiner â€” ç»Ÿè®¡èåˆ

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.fusion import StatisticalCombiner`

åŸºäºç»Ÿè®¡æƒé‡çš„å¤šå› å­åˆæˆï¼Œæ”¯æŒä¸‰ç§æƒé‡è®¡ç®—æ–¹å¼ã€‚

##### æ„é€ å‚æ•°

```python
StatisticalCombiner(method='equal')
```

| `method` | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|----------|------|----------|
| `'equal'` | ç­‰æƒåˆæˆ | å¿«é€ŸåŸºå‡†ï¼Œæ— éœ€è®­ç»ƒæ ‡ç­¾ |
| `'ic_weighted'` | æŒ‰ IC å‡å€¼åŠ æƒ | é¢„æµ‹åŠ›å¼ºçš„å› å­è·å¾—æ›´é«˜æƒé‡ |
| `'min_variance'` | æœ€å°æ–¹å·®ä¼˜åŒ–ï¼ˆSLSQPï¼‰ | è¿½æ±‚åˆæˆå› å­çš„ç¨³å®šæ€§ |

> æ‰€æœ‰æ–¹æ³•åœ¨åˆæˆå‰è‡ªåŠ¨å¯¹æ¯ä¸ªå› å­åš `rank(axis=1, pct=True)` å¤„ç†ï¼ˆæ¶ˆé™¤é‡çº²ï¼‰ã€‚

##### æ–¹æ³•

```python
combiner = StatisticalCombiner('ic_weighted')

# è®­ç»ƒï¼ˆè®¡ç®—æƒé‡ï¼‰
combiner.fit(factors=[f1, f2, f3], label=y)

# é¢„æµ‹ï¼ˆç”Ÿæˆåˆæˆå› å­ TÃ—Nï¼‰
composite = combiner.predict([f1, f2, f3])

# ä¸€é”®å›æµ‹è¯„ä¼°
result = combiner.evaluate(
    factors      = [f1, f2, f3],
    close        = close,
    is_suspended = data.is_suspended,
    is_limit     = data.is_limit,
    rebalance_freq = 5,
    top_n        = 30,
    weight_method  = 'equal',
    cost_rate      = 0.0015,
)

# æŸ¥çœ‹æƒé‡
print(combiner.weights_)          # np.ndarrayï¼Œå„å› å­æƒé‡
print(combiner.ic_matrix_)        # DataFrameï¼Œæ¯æ—¥å„å› å­ IC å€¼

# æŒä¹…åŒ–
combiner.save('stat_combiner.pkl')
loaded = StatisticalCombiner.load('stat_combiner.pkl')
```

##### ä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine.fusion import StatisticalCombiner

# ç­‰æƒåˆæˆï¼ˆæ— éœ€æ ‡ç­¾ï¼‰
equal = StatisticalCombiner('equal').fit([f1, f2, f3], y)
print("ç­‰æƒæƒé‡:", equal.weights_)      # [0.333, 0.333, 0.333]

# IC åŠ æƒï¼ˆé¢„æµ‹åŠ›å¼ºçš„å› å­æƒé‡æ›´é«˜ï¼‰
ic_w = StatisticalCombiner('ic_weighted').fit([f1, f2, f3], y)
print("ICåŠ æƒæƒé‡:", ic_w.weights_)    # ä¾‹ï¼š[0.45, 0.35, 0.20]

# æœ€å°æ–¹å·®åˆæˆï¼ˆå‡å°‘åˆæˆå› å­æ³¢åŠ¨ï¼‰
min_var = StatisticalCombiner('min_variance').fit([f1, f2, f3], y)
result = min_var.evaluate([f1, f2, f3], close, data.is_suspended, data.is_limit,
                          rebalance_freq=5, top_n=30)
result.print_summary()
```

---

#### 7.3 MLCombiner â€” æœºå™¨å­¦ä¹ èåˆ

**å¯¼å…¥è·¯å¾„ï¼š** `from quant_alpha_engine.fusion import MLCombiner`

ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹å­¦ä¹ å› å­ä¸æœªæ¥æ”¶ç›Šçš„å…³ç³»ï¼Œé€šè¿‡ **Expanding Window** æ–¹å¼ä¸¥æ ¼é˜²æ­¢æœªæ¥å‡½æ•°ã€‚

##### æ„é€ å‚æ•°

```python
MLCombiner(
    model_type         = 'ridge',   # æ¨¡å‹ç±»å‹
    min_train_periods  = 60,        # æœ€å°è®­ç»ƒæœŸï¼ˆå‰ N å¤©ä¸º NaNï¼Œä¸é¢„æµ‹ï¼‰
    refit_freq         = 20,        # æ¯éš” N å¤©é‡æ–°è®­ç»ƒä¸€æ¬¡
    ridge_alpha        = 1.0,       # Ridge æ­£åˆ™åŒ–å¼ºåº¦
    rf_n_estimators    = 100,       # RandomForest æ ‘çš„æ•°é‡
    rf_max_depth       = 5,         # RandomForest æœ€å¤§æ·±åº¦
    xgb_n_estimators   = 100,       # XGBoost æ ‘çš„æ•°é‡ï¼ˆéœ€å®‰è£… xgboostï¼‰
    xgb_max_depth      = 3,         # XGBoost æœ€å¤§æ·±åº¦
    xgb_learning_rate  = 0.1,       # XGBoost å­¦ä¹ ç‡
)
```

| `model_type` | è¯´æ˜ | ç‰¹å¾é‡è¦æ€§æ¥æº |
|-------------|------|--------------|
| `'linear'` | æ™®é€šçº¿æ€§å›å½’ | `\|coef_\|` å½’ä¸€åŒ– |
| `'ridge'` | Ridge å›å½’ï¼ˆL2 æ­£åˆ™åŒ–ï¼‰| `\|coef_\|` å½’ä¸€åŒ– |
| `'random_forest'` | éšæœºæ£®æ— | `feature_importances_` |
| `'xgboost'` | XGBoostï¼ˆéœ€é¢å¤–å®‰è£…ï¼‰| `feature_importances_`ï¼Œæœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§ä¸º `random_forest` |

##### Expanding Window é˜²æœªæ¥å‡½æ•°åŸåˆ™

```
è®­ç»ƒæœŸï¼ˆå‰ min_train_periods å¤©ï¼‰â†’ è¾“å‡ºå…¨ä¸º NaN

Day  0 ~ 59  â†’ ç§¯ç´¯æœŸï¼Œæ— é¢„æµ‹
Day 60 ~ 79  â†’ ç”¨ [0, 60) è®­ç»ƒ â†’ é¢„æµ‹ [60, 80)
Day 80 ~ 99  â†’ ç”¨ [0, 80) è®­ç»ƒ â†’ é¢„æµ‹ [80, 100)
Day 100~119  â†’ ç”¨ [0, 100) è®­ç»ƒ â†’ é¢„æµ‹ [100, 120)
...ï¼ˆè®­ç»ƒé›†æŒç»­æ‰©å¤§ï¼Œæ°¸ä¸ä½¿ç”¨æœªæ¥æ•°æ®ï¼‰
```

##### æ–¹æ³•

```python
ml = MLCombiner('ridge', min_train_periods=60, refit_freq=20)

# è®­ç»ƒ
ml.fit(factors=[f1, f2, f3], label=y)

# é¢„æµ‹ï¼ˆç”Ÿæˆåˆæˆå› å­ TÃ—Nï¼Œå‰ min_train_periods è¡Œä¸º NaNï¼‰
pred = ml.predict([f1, f2, f3])
assert pred.iloc[:60].isna().all().all()   # ä¸¥æ ¼éªŒè¯æ— æœªæ¥å‡½æ•°

# æŸ¥çœ‹å„å› å­é‡è¦æ€§
print(ml.feature_importances_)   # pd.Seriesï¼Œindex = ['f0', 'f1', 'f2']

# ä¸€é”®å›æµ‹è¯„ä¼°
result = ml.evaluate(
    [f1, f2, f3],
    close=close, is_suspended=data.is_suspended, is_limit=data.is_limit,
    rebalance_freq=5, top_n=30,
)
result.plot()

# æŒä¹…åŒ–ï¼ˆä¸¤ç§æ¨¡å¼ï¼‰
ml.save('ml_combiner.pkl')                            # å«é¢„æµ‹ç¼“å­˜ï¼ˆæ–‡ä»¶è¾ƒå¤§ï¼‰
ml.save('ml_combiner_lite.pkl', save_predictions=False)  # ä»…æ¨¡å‹æƒé‡ï¼ˆæ–‡ä»¶æ›´å°ï¼‰
loaded = MLCombiner.load('ml_combiner.pkl')
```

##### ä½¿ç”¨ç¤ºä¾‹

```python
from quant_alpha_engine.fusion import MLCombiner

# Ridge èåˆ
ml_ridge = MLCombiner('ridge', min_train_periods=60, refit_freq=20, ridge_alpha=1.0)
ml_ridge.fit([f1, f2, f3], y)

# éªŒè¯æ— æœªæ¥å‡½æ•°
pred = ml_ridge.predict([f1, f2, f3])
assert pred.iloc[:60].isna().all().all()
print(f"æœ‰æ•ˆé¢„æµ‹å¤©æ•°: {pred.dropna(how='all').shape[0]}")

# æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§
print(ml_ridge.feature_importances_)

# RandomForest èåˆï¼ˆæ•æ‰éçº¿æ€§å…³ç³»ï¼‰
ml_rf = MLCombiner('random_forest', min_train_periods=120, refit_freq=60,
                   rf_n_estimators=100, rf_max_depth=5)
ml_rf.fit([f1, f2, f3], y)
result_rf = ml_rf.evaluate(
    [f1, f2, f3],
    close=close, is_suspended=data.is_suspended, is_limit=data.is_limit,
    rebalance_freq=5, top_n=30,
)
result_rf.print_summary()
```

---

## æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | è®¡ç®—å…¬å¼ | å‚è€ƒèŒƒå›´ | å«ä¹‰ |
|------|----------|----------|------|
| å¹´åŒ–æ”¶ç›Šç‡ | `(nav_æœ«/nav_åˆ)^(252/T) - 1` | >5% | ç­–ç•¥å¹´åŒ–è¶…é¢æ”¶ç›Š |
| å¹´åŒ–æ³¢åŠ¨ç‡ | `std(æ—¥æ”¶ç›Š) Ã— âˆš252` | <20% | æ”¶ç›Šçš„ä¸ç¨³å®šç¨‹åº¦ |
| **Sharpe Ratio** | `å¹´åŒ–è¶…é¢æ”¶ç›Š / å¹´åŒ–æ³¢åŠ¨ç‡` | **>1.0** | é£é™©è°ƒæ•´åæ”¶ç›Šï¼Œè¶Šé«˜è¶Šå¥½ |
| Calmar Ratio | `å¹´åŒ–æ”¶ç›Šç‡ / \|æœ€å¤§å›æ’¤\|` | >0.5 | å•ä½å›æ’¤é£é™©çš„å¹´åŒ–æ”¶ç›Š |
| **æœ€å¤§å›æ’¤** | `min((nav_t - nav_é«˜ç‚¹) / nav_é«˜ç‚¹)` | **>-30%** | å†å²æœ€å¤§äºæŸå¹…åº¦ï¼Œè¶Šå°è¶Šå¥½ |
| **IC å‡å€¼** | æ¯æ—¥ Rank IC çš„å‡å€¼ | **>0.03** | å› å­é¢„æµ‹åŠ›ï¼Œè¶Šé«˜è¶Šå¥½ |
| IC æ ‡å‡†å·® | æ¯æ—¥ IC çš„æ ‡å‡†å·® | â€” | IC ç¨³å®šæ€§ï¼Œè¶Šä½è¶Šå¥½ |
| **ICIR** | `ICå‡å€¼ / ICæ ‡å‡†å·® Ã— âˆš252` | **>0.5** | IC ä¿¡æ¯æ¯”ç‡ï¼Œç»¼åˆè¡¡é‡ç¨³å®šé¢„æµ‹åŠ› |
| IC èƒœç‡ | IC > 0 çš„å¤©æ•°å æ¯” | >55% | å› å­æ–¹å‘æ­£ç¡®çš„æ¦‚ç‡ |
| IC t-stat | IC å‡å€¼çš„ t ç»Ÿè®¡é‡ | `\|t\|>2` | IC ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œ>2 è¡¨ç¤ºæ˜¾è‘— |
| æ—¥å‡æ¢æ‰‹ç‡ | `mean(Î£\|w_t - w_{t-1}\| / 2)` | <10% | æ¯æ—¥å¹³å‡æ¢æ‰‹æ¯”ä¾‹ï¼Œè¶Šä½æˆæœ¬è¶Šå° |
| å¹´åŒ–æ‰‹ç»­è´¹ | `æ—¥å‡äº¤æ˜“æˆæœ¬ Ã— 252` | â€” | æ¯å¹´å› äº¤æ˜“æŸè€—çš„æ”¶ç›Š |
| **Fitness** | `Sharpe Ã— âˆš(\|å¹´åŒ–æ”¶ç›Š\| / æ—¥å‡æ¢æ‰‹)` | **>1.0** | WorldQuant ç»¼åˆè¯„ä¼°æŒ‡æ ‡ |

---

## ä½¿ç”¨çœŸå®æ•°æ®

å°†æ¡†æ¶åº”ç”¨åˆ°çœŸå®æ•°æ®æ—¶ï¼Œåªéœ€å°†æ•°æ®ç»„ç»‡ä¸ºæ­£ç¡®æ ¼å¼çš„ DataFrameï¼š

### æ•°æ®æ ¼å¼è¦æ±‚

```python
# æ‰€æœ‰ DataFrame é¡»æ»¡è¶³ï¼š
# - index: pd.DatetimeIndexï¼Œæ—¶é—´å‡åº
# - columns: è‚¡ç¥¨ä»£ç ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œå‘½åä¸€è‡´

import pandas as pd

# ä»·æ ¼æ•°æ®ï¼ˆT Ã— Nï¼‰
close = pd.DataFrame(...)    # index=æ—¥æœŸ, columns=è‚¡ç¥¨ä»£ç 

# åœç‰ŒçŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œbool ç±»å‹
is_suspended = pd.DataFrame(...).astype(bool)

# æ¶¨è·ŒåœçŸ©é˜µï¼ˆT Ã— Nï¼‰ï¼Œbool ç±»å‹
# å¯ä»¥åˆå¹¶æ¶¨åœå’Œè·Œåœï¼šis_limit = is_limit_up | is_limit_down
is_limit = (is_limit_up | is_limit_down).astype(bool)

# è¡Œä¸šæ˜ å°„ï¼ˆé™æ€ï¼‰
# index=è‚¡ç¥¨ä»£ç , values=è¡Œä¸šåç§°å­—ç¬¦ä¸²
industry = pd.Series({
    '000001.SZ': 'é“¶è¡Œ',
    '000002.SZ': 'æˆ¿åœ°äº§',
    ...
})
```

### å®Œæ•´æ›¿æ¢æ¨¡æ¿

```python
import pandas as pd
from quant_alpha_engine.ops import AlphaOps as op
from quant_alpha_engine.backtest import VectorEngine

# â”€â”€ åŠ è½½æ‚¨çš„æ•°æ® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
close        = pd.read_csv('close.csv',        index_col=0, parse_dates=True)
volume       = pd.read_csv('volume.csv',       index_col=0, parse_dates=True)
is_suspended = pd.read_csv('suspended.csv',    index_col=0, parse_dates=True).astype(bool)
is_limit_up  = pd.read_csv('limit_up.csv',     index_col=0, parse_dates=True).astype(bool)
is_limit_dn  = pd.read_csv('limit_down.csv',   index_col=0, parse_dates=True).astype(bool)
is_limit     = is_limit_up | is_limit_dn

industry     = pd.read_csv('industry.csv', index_col=0).squeeze()  # Series

# â”€â”€ æ„é€ æ‚¨çš„å› å­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
factor = op.Neutralize(
    op.Rank(-op.Ts_Corr(volume, close, window=10)),
    industry
)

# â”€â”€ ä¸€è¡Œå›æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
result = VectorEngine(
    factor         = factor,
    close          = close,
    is_suspended   = is_suspended,
    is_limit       = is_limit,
    rebalance_freq = 5,
    top_n          = 50,
    weight_method  = 'equal',
    cost_rate      = 0.0015,
).run()

result.print_summary()
result.plot(save_path='my_factor_report.png')
```

---

## å› å­æ„é€ ç¤ºä¾‹é›†

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºå¸¸è§å› å­ç±»å‹çš„ç®—å­ç»„åˆæ–¹å¼ï¼Œå¯ç›´æ¥å¤ç”¨æˆ–å‚è€ƒä¿®æ”¹ï¼š

```python
from quant_alpha_engine.ops import AlphaOps as op

# â”€â”€ åè½¬ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# çŸ­æœŸåè½¬ï¼ˆ5æ—¥ï¼‰
factor_rev5 = op.Rank(-op.Ts_Delta(close, 5))

# ä¸­æœŸåè½¬ï¼ˆ20æ—¥ï¼‰+ è¡Œä¸šä¸­æ€§åŒ–
factor_rev20 = op.Neutralize(op.Rank(-op.Ts_Delta(close, 20)), industry)

# â”€â”€ åŠ¨é‡ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# æœˆåº¦åŠ¨é‡ï¼ˆè·³è¿‡æœ€è¿‘5å¤©ï¼Œé¿å…çŸ­æœŸåè½¬ï¼‰
momentum = close / op.Ts_Delay(close, 21) - close / op.Ts_Delay(close, 5)
factor_mom = op.Rank(momentum)

# çº¿æ€§è¡°å‡å¹³æ»‘çš„åŠ¨é‡
factor_decay_mom = op.Rank(op.Decay_Linear(op.Rank(op.Ts_Delta(close, 10)), d=5))

# ğŸ†• é£é™©è°ƒæ•´åŠ¨é‡ï¼ˆv2ï¼‰
factor_ram = op.Rank(op.RiskAdjMomentum(close, window=20, vol_window=20))

# ğŸ†• ä»·æ ¼è·¯å¾„è´¨é‡ï¼ˆv2ï¼‰â€” å•è°ƒçº¿æ€§è¶‹åŠ¿
factor_ppq = op.Rank(op.PricePathQuality(close, window=20))

# â”€â”€ é‡ä»·ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# é‡ä»·èƒŒç¦»ï¼ˆç¼©é‡ä¸Šæ¶¨ä¸ºæ­£ä¿¡å·ï¼‰
factor_vp = op.Neutralize(op.Rank(-op.Ts_Corr(volume, close, 10)), industry)

# æˆäº¤é‡æ—¶åºåˆ†ä½ï¼ˆè¿‘æœŸæˆäº¤é‡å¤„äºå†å²ä½ä½ï¼‰
factor_vol_rank = op.Rank(-op.Ts_Rank(volume, 20))

# æ”¾é‡åˆ›æ–°é«˜ï¼ˆä»·æ ¼åˆ›æ–°é«˜ + æˆäº¤é‡ä¹Ÿåˆ›é«˜ï¼‰
price_rank  = op.Ts_Rank(close, 60)
vol_rank    = op.Ts_Rank(volume, 20)
factor_breakout = op.Rank(price_rank + vol_rank)

# ğŸ†• VWAP åç¦»åº¦ï¼ˆv2ï¼‰
factor_pvdev = op.Rank(-op.PVDeviation(close, volume, window=10))

# ğŸ†• Amihud æµåŠ¨æ€§ï¼ˆv2ï¼‰â€” é«˜æµåŠ¨æ€§è‚¡ç¥¨
factor_liq = op.Rank(-op.Amihud(close, volume, window=20))

# â”€â”€ æ³¢åŠ¨ç‡ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ä½æ³¢åŠ¨å› å­ï¼ˆæ³¢åŠ¨ç‡è¶Šå°è¶Šå¥½ï¼‰
daily_ret = close.pct_change()
factor_lowvol = op.Rank(-op.Ts_Std(daily_ret, 20))

# ğŸ†• é«˜é˜¶çŸ©å› å­ï¼ˆv2ï¼‰â€” ä½è´Ÿååº¦ï¼ˆå°¾éƒ¨é£é™©å°ï¼‰
factor_skew = op.Rank(-op.Ts_Skew(daily_ret, 20))

# â”€â”€ æŠ€æœ¯æŒ‡æ ‡ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ğŸ†• RSI è¶…å–å› å­ï¼ˆv2ï¼‰
factor_rsi = op.Rank(100 - op.RSI(close, window=14))   # RSI è¶Šä½ â†’ è¶Šè¶…å–

# ğŸ†• MACD æŸ±çŠ¶å›¾ï¼ˆv2ï¼‰
factor_macd = op.Rank(op.MACD(close, fast=12, slow=26, signal=9))

# ğŸ†• KDJ è¶…å–ï¼ˆv2ï¼‰
factor_kdj = op.Rank(50 - op.KDJ(close, high, low, n=9))

# ğŸ†• åŒºé—´çªç ´ï¼ˆv2ï¼‰
factor_rng = op.Rank(op.RangeBreakout(close, high, low, window=20))

# â”€â”€ ä»·æ ¼ä½ç½®ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Williams %Rï¼ˆä»·æ ¼åœ¨è¿‘20æ—¥åŒºé—´å†…çš„ä½ç½®ï¼Œè¶Šä½è¶Šè¶…å–ï¼‰
high20 = op.Ts_Max(high, 20)
low20  = op.Ts_Min(low,  20)
wr     = (close - high20) / (high20 - low20 + 1e-8)
factor_wr = op.Rank(-wr)   # è¶…å–æ’åé å‰

# â”€â”€ å¤šå› å­åˆæˆï¼ˆæ‰‹åŠ¨ç­‰æƒï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ç­‰æƒåˆæˆï¼ˆå…ˆåˆ†åˆ« Rank æ¶ˆé™¤é‡çº²ï¼Œå†åŠ æƒï¼‰
alpha_combo = (
    0.4 * op.Rank(factor_rev5) +
    0.3 * op.Rank(factor_vp) +
    0.3 * op.Rank(factor_lowvol)
)

# â”€â”€ ğŸ†• å¤šå› å­èåˆï¼ˆfusion æ¨¡å—ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from quant_alpha_engine.fusion import Labeler, StatisticalCombiner, MLCombiner

label = Labeler().set_label(target='close', horizon=5, data={'close': close})

# IC åŠ æƒç»Ÿè®¡èåˆ
stat = StatisticalCombiner('ic_weighted').fit([factor_rev5, factor_vp, factor_rsi], label)
result = stat.evaluate([factor_rev5, factor_vp, factor_rsi],
                       close, data.is_suspended, data.is_limit,
                       rebalance_freq=5, top_n=30)
result.print_summary()

# Ridge ML èåˆ
ml = MLCombiner('ridge', min_train_periods=60, refit_freq=20)
ml.fit([factor_rev5, factor_vp, factor_rsi], label)
result2 = ml.evaluate([factor_rev5, factor_vp, factor_rsi],
                      close, data.is_suspended, data.is_limit,
                      rebalance_freq=5, top_n=30)
result2.plot()
```

---

## å¸¸è§é—®é¢˜

**Q: å›æµ‹æ—¶æç¤º `æ•°æ®è§„æ¨¡ï¼šN ä¸ªäº¤æ˜“æ—¥ Ã— M åªè‚¡ç¥¨`ï¼ŒM æ¯”é¢„æœŸå°‘ï¼Ÿ**

A: `VectorEngine` ä¼šè‡ªåŠ¨å– `factor`ã€`close`ã€`is_suspended`ã€`is_limit` å››ä¸ªè¾“å…¥çš„**å…±åŒè‚¡ç¥¨åˆ—äº¤é›†**ã€‚è¯·æ£€æŸ¥å„ DataFrame çš„ columns æ˜¯å¦å®Œå…¨ä¸€è‡´ï¼ˆå¤§å°å†™ã€æ ¼å¼éœ€ç›¸åŒï¼‰ã€‚

---

**Q: `Ts_Rank` è¿è¡Œå¾ˆæ…¢ï¼Ÿ**

A: `Ts_Rank` å†…éƒ¨ä½¿ç”¨ `rolling.apply`ï¼ˆPython å±‚å¾ªç¯ï¼‰ï¼Œå¯¹å¤§çŸ©é˜µæ€§èƒ½æœ‰é™ã€‚ä¼˜åŒ–å»ºè®®ï¼š
1. å‡å°‘è‚¡ç¥¨æ•°é‡æˆ–ç¼©çŸ­æ—¶é—´åºåˆ—
2. å°† `window` æ§åˆ¶åœ¨ 60 ä»¥å†…
3. è€ƒè™‘ç”¨ `Rank(df)` æ›¿ä»£ï¼ˆæˆªé¢æ’åé€Ÿåº¦æ›´å¿«ï¼‰

---

**Q: æƒ³å¯¹å› å­åš IC åˆ†æï¼Œä½†ä¸æƒ³èµ°å®Œæ•´å›æµ‹æµç¨‹ï¼Ÿ**

A: ç›´æ¥ä½¿ç”¨ `Performance` æ¨¡å—ï¼š

```python
from quant_alpha_engine.backtest.performance import Performance

# è®¡ç®—å‰å‘1æ—¥æ”¶ç›Šç‡
fwd_ret = close.shift(-1) / close - 1

# è®¡ç®— IC åºåˆ—
ic = Performance.calc_ic_series(my_factor, fwd_ret)
stats = Performance.calc_ic_stats(ic)
print(stats)
```

---

**Q: å¦‚ä½•ä¿å­˜å›æµ‹æŠ¥å‘Šå›¾ç‰‡ï¼Ÿ**

```python
result.plot(save_path='./reports/factor1_report.png')
# æˆ–
from quant_alpha_engine.visualization.report import Report
Report.plot(result, save_path='./reports/factor1_report.png')
```

---

**Q: `Neutralize` ä¸­æ€§åŒ–åå› å­å‡å€¼ä¸ä¸ºé›¶ï¼Ÿ**

A: æ­£å¸¸ç°è±¡ã€‚`Neutralize` ä½¿ç”¨ OLS æ®‹å·®ï¼Œæ®‹å·®åœ¨æ¯ä¸ªè¡Œä¸šå†…å‡å€¼ä¸ºé›¶ï¼Œä½†**è·¨è¡Œä¸šçš„æ•´ä½“å‡å€¼**ä¸ä¸€å®šä¸ºé›¶ã€‚è‹¥éœ€æ•´ä½“å‡å€¼ä¸ºé›¶ï¼Œå¯åœ¨ä¸­æ€§åŒ–åå†åšä¸€æ¬¡ `ZScore`ï¼š

```python
factor_neut = op.Neutralize(raw_factor, industry)
factor_final = op.ZScore(factor_neut)   # ç¡®ä¿æˆªé¢å‡å€¼=0
```

---

**Q: å¦‚ä½•æ¨¡æ‹Ÿä¸åŒå¸‚åœºç¯å¢ƒï¼ˆç‰›å¸‚/ç†Šå¸‚/éœ‡è¡ï¼‰ï¼Ÿ**

```python
# ç‰›å¸‚ï¼ˆé«˜æ¼‚ç§» + ä½æ³¢åŠ¨ï¼‰
bull = MockDataGenerator(mu=0.20, sigma=0.18, seed=1).generate()

# ç†Šå¸‚ï¼ˆè´Ÿæ¼‚ç§» + é«˜æ³¢åŠ¨ï¼‰
bear = MockDataGenerator(mu=-0.10, sigma=0.45, seed=2).generate()

# éœ‡è¡å¸‚ï¼ˆé›¶æ¼‚ç§» + ä¸­ç­‰æ³¢åŠ¨ï¼‰
flat = MockDataGenerator(mu=0.00, sigma=0.25, seed=3).generate()
```

---

**Q: å¦‚ä½•åœ¨ Jupyter Notebook ä¸­ä¿å­˜å›¾è¡¨è€Œä¸å¼¹çª—ï¼Ÿ**

```python
import matplotlib
matplotlib.use('Agg')   # åœ¨ import pyplot ä¹‹å‰è®¾ç½®éäº¤äº’åç«¯

result.plot(save_path='report.png')
```

æˆ–åœ¨ Notebook é¡¶éƒ¨ä½¿ç”¨ `%matplotlib inline` æ—¶ï¼Œç›´æ¥ç”¨ `save_path` å‚æ•°ä¿å­˜ã€‚

---

**Q: ğŸ†• `MLCombiner` é¢„æµ‹å‰å‡ è¡Œå…¨æ˜¯ NaNï¼Œè¿™æ˜¯æ­£å¸¸çš„å—ï¼Ÿ**

A: å®Œå…¨æ­£å¸¸ï¼Œè¿™æ˜¯**é˜²æœªæ¥å‡½æ•°**è®¾è®¡çš„æ ¸å¿ƒä¿è¯ã€‚å‰ `min_train_periods` è¡Œï¼ˆé»˜è®¤60å¤©ï¼‰æ²¡æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œå› æ­¤è¾“å‡º NaNã€‚`VectorEngine` ä¼šè‡ªåŠ¨é€šè¿‡ `ffill` å¡«å……ï¼Œå›æµ‹æœŸé—´æƒé‡ä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¢„æµ‹æ—¥å¼€å§‹å»ºç«‹ã€‚

```python
ml = MLCombiner('ridge', min_train_periods=60)
ml.fit([f1, f2, f3], y)
pred = ml.predict([f1, f2, f3])
# å‰ 60 è¡Œåº”å…¨ä¸º NaNï¼ˆä¸¥æ ¼éªŒè¯ï¼‰
assert pred.iloc[:60].isna().all().all()
# ç¬¬ 60 è¡Œä¹‹åæœ‰æœ‰æ•ˆé¢„æµ‹
print(f"ç§¯ç´¯æœŸï¼šå‰ {pred.isna().all(axis=1).sum()} è¡Œ")
```

---

**Q: ğŸ†• `StatisticalCombiner` å’Œ `MLCombiner` çš„ `evaluate()` éœ€è¦å“ªäº›å‚æ•°ï¼Ÿ**

A: ä¸ `VectorEngine` å®Œå…¨ä¸€è‡´ï¼ˆé™¤äº† `factor` å‚æ•°è¢« `factors` åˆ—è¡¨æ›¿ä»£ï¼‰ï¼š

```python
result = combiner.evaluate(
    factors        = [f1, f2, f3],    # å› å­åˆ—è¡¨
    close          = close_df,         # å¿…å¡«
    is_suspended   = susp_df,          # å¿…å¡«
    is_limit       = limit_df,         # å¿…å¡«
    rebalance_freq = 5,                # å¯é€‰ï¼Œé»˜è®¤ 1
    top_n          = 30,               # å¯é€‰ï¼Œé»˜è®¤ 50
    weight_method  = 'equal',          # å¯é€‰ï¼Œé»˜è®¤ 'equal'
    cost_rate      = 0.0015,           # å¯é€‰ï¼Œé»˜è®¤ 0.0015
)
```

---

**Q: ğŸ†• å¦‚ä½•ä¿å­˜å’ŒåŠ è½½è®­ç»ƒå¥½çš„èåˆæ¨¡å‹ï¼Ÿ**

```python
# ä¿å­˜
stat.save('my_combiner.pkl')
ml.save('my_ml_combiner.pkl')
ml.save('my_ml_light.pkl', save_predictions=False)  # ä¸å«é¢„æµ‹ç¼“å­˜ï¼Œæ–‡ä»¶æ›´å°

# åŠ è½½
from quant_alpha_engine.fusion import StatisticalCombiner, MLCombiner
stat2 = StatisticalCombiner.load('my_combiner.pkl')
ml2   = MLCombiner.load('my_ml_combiner.pkl')

# éªŒè¯åŠ è½½æˆåŠŸ
assert stat2._is_fitted
assert ml2._is_fitted
```

---

**Q: ğŸ†• æ–°ç®—å­ï¼ˆRSIã€MACDã€KDJ ç­‰ï¼‰çš„è¿”å›å€¼æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ**

A: æ‰€æœ‰æ–°ç®—å­å‡è¿”å› `pd.DataFrame`ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒï¼ˆT Ã— Nï¼ŒIndex=æ—¥æœŸï¼ŒColumns=è‚¡ç¥¨ä»£ç ï¼‰ï¼Œå¯ç›´æ¥ä½œä¸ºå› å­ä¼ å…¥ `VectorEngine` æˆ–èåˆæ¡†æ¶ã€‚ä¸éœ€è¦é€è‚¡ç¥¨å¾ªç¯è°ƒç”¨ã€‚

```python
from quant_alpha_engine.ops import AlphaOps as op

# æ‰¹é‡è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„ RSIï¼ˆT Ã— Nï¼‰
rsi = op.RSI(close, window=14)          # DataFrame
macd = op.MACD(close)                   # DataFrame
hurst = op.Ts_Hurst(close.pct_change(), window=30)  # DataFrame

# ç›´æ¥ç”¨äºå›æµ‹
factor = op.Rank(rsi)
result = VectorEngine(factor=factor, close=close, ...).run()
```
